{"type":"plugin::upload.file","id":179,"data":{"documentId":"rax0lv28u94ezys3tcs1emqs","name":"strapi_icon.svg","alternativeText":"Strapi Icon","caption":"Strapi Icon","width":800,"height":800,"formats":null,"hash":"strapi_icon_a451f3f272","ext":".svg","mime":"image/svg+xml","size":1.52,"url":"/uploads/strapi_icon_a451f3f272.svg","previewUrl":null,"provider":"local","provider_metadata":null,"folderPath":"/13","createdAt":"2025-10-17T12:02:05.131Z","updatedAt":"2025-10-17T12:02:14.286Z","publishedAt":"2025-10-17T12:02:05.131Z","locale":null}}
{"type":"plugin::upload.file","id":180,"data":{"documentId":"sdpitnmig7g1zl9gjrb5l6jp","name":"profile.png","alternativeText":null,"caption":null,"width":800,"height":800,"formats":{"small":{"ext":".png","url":"/uploads/small_profile_5905f63a57.png","hash":"small_profile_5905f63a57","mime":"image/png","name":"small_profile.png","path":null,"size":265.08,"width":500,"height":500,"sizeInBytes":265075},"medium":{"ext":".png","url":"/uploads/medium_profile_5905f63a57.png","hash":"medium_profile_5905f63a57","mime":"image/png","name":"medium_profile.png","path":null,"size":558.31,"width":750,"height":750,"sizeInBytes":558307},"thumbnail":{"ext":".png","url":"/uploads/thumbnail_profile_5905f63a57.png","hash":"thumbnail_profile_5905f63a57","mime":"image/png","name":"thumbnail_profile.png","path":null,"size":28.09,"width":156,"height":156,"sizeInBytes":28089}},"hash":"profile_5905f63a57","ext":".png","mime":"image/png","size":135.42,"url":"/uploads/profile_5905f63a57.png","previewUrl":null,"provider":"local","provider_metadata":null,"folderPath":"/1","createdAt":"2025-10-02T20:06:59.868Z","updatedAt":"2025-10-02T20:07:42.585Z","publishedAt":"2025-10-02T20:06:59.868Z","locale":null}}
{"type":"plugin::upload.file","id":181,"data":{"documentId":"te63gz0rldcz0l17r17zoeq9","name":"Link24_History.svg","alternativeText":"Link24 History","caption":"Link24 History","width":2000,"height":1100,"formats":null,"hash":"Link24_History_4e14c69bc6","ext":".svg","mime":"image/svg+xml","size":440.75,"url":"/uploads/Link24_History_4e14c69bc6.svg","previewUrl":null,"provider":"local","provider_metadata":null,"folderPath":"/2/6","createdAt":"2025-10-15T19:17:55.742Z","updatedAt":"2025-10-15T19:17:55.742Z","publishedAt":"2025-10-15T19:17:55.742Z","locale":null}}
{"type":"plugin::upload.file","id":182,"data":{"documentId":"to0gch6sj6q280zyagp3wcn0","name":"openai.svg","alternativeText":"OpenAI Icon","caption":"OpenAI Icon","width":56,"height":56,"formats":null,"hash":"openai_bd85ca97ca","ext":".svg","mime":"image/svg+xml","size":1.71,"url":"/uploads/openai_bd85ca97ca.svg","previewUrl":null,"provider":"local","provider_metadata":null,"folderPath":"/13","createdAt":"2025-10-16T22:33:32.847Z","updatedAt":"2025-10-16T22:37:12.134Z","publishedAt":"2025-10-16T22:33:32.847Z","locale":null}}
{"type":"plugin::upload.file","id":183,"data":{"documentId":"w1hjdda4l8xure1gk5pdnhry","name":"portfolio_home.svg","alternativeText":"Portfolio Website Landingpage","caption":"Portfolio Website Landingpage","width":2100,"height":1200,"formats":null,"hash":"portfolio_home_08cf1cb4ce","ext":".svg","mime":"image/svg+xml","size":370.86,"url":"/uploads/portfolio_home_08cf1cb4ce.svg","previewUrl":null,"provider":"local","provider_metadata":null,"folderPath":"/2/12","createdAt":"2025-10-15T19:49:08.256Z","updatedAt":"2025-10-15T19:49:08.256Z","publishedAt":"2025-10-15T19:49:08.257Z","locale":null}}
{"type":"plugin::upload.file","id":184,"data":{"documentId":"x1kqhupvgx797xjyzrkha0pz","name":"contact_diary_add.svg","alternativeText":"Corona Contact Diary New Encounter","caption":"Corona Contact Diary New Encounter","width":1080,"height":1920,"formats":null,"hash":"contact_diary_add_1a63a4f34a","ext":".svg","mime":"image/svg+xml","size":1036.42,"url":"/uploads/contact_diary_add_1a63a4f34a.svg","previewUrl":null,"provider":"local","provider_metadata":null,"folderPath":"/2/8","createdAt":"2025-10-15T19:13:55.198Z","updatedAt":"2025-10-15T19:13:55.198Z","publishedAt":"2025-10-15T19:13:55.199Z","locale":null}}
{"type":"plugin::upload.file","id":185,"data":{"documentId":"x2jr0e5k1cn4mv0vj8h2fbkj","name":"Terraform.svg","alternativeText":"HashiCorp Terraform Logo","caption":"HashiCorp Terraform Logo","width":102,"height":117,"formats":null,"hash":"Terraform_854616f693","ext":".svg","mime":"image/svg+xml","size":0.39,"url":"/uploads/Terraform_854616f693.svg","previewUrl":null,"provider":"local","provider_metadata":null,"folderPath":"/2/7","createdAt":"2025-10-15T19:06:13.448Z","updatedAt":"2025-10-15T19:06:55.345Z","publishedAt":"2025-10-15T19:06:13.448Z","locale":null}}
{"type":"plugin::upload.file","id":186,"data":{"documentId":"y7x8j4k133ugjo65q438lasz","name":"Link24_Home.svg","alternativeText":"Link24 Home","caption":"Link24 Home","width":2000,"height":1100,"formats":null,"hash":"Link24_Home_5a7275049f","ext":".svg","mime":"image/svg+xml","size":276.85,"url":"/uploads/Link24_Home_5a7275049f.svg","previewUrl":null,"provider":"local","provider_metadata":null,"folderPath":"/2/6","createdAt":"2025-10-15T19:17:56.133Z","updatedAt":"2025-10-15T19:17:56.133Z","publishedAt":"2025-10-15T19:17:56.134Z","locale":null}}
{"type":"plugin::upload.file","id":187,"data":{"documentId":"zdd2w6714oo3rwv92lsek6zd","name":"co2_tracker_scoreboard.svg","alternativeText":"CO2 Emission Tracker Scoreboard","caption":"CO2 Emission Tracker Scoreboard","width":1080,"height":1920,"formats":null,"hash":"co2_tracker_scoreboard_00aeaed202","ext":".svg","mime":"image/svg+xml","size":294.54,"url":"/uploads/co2_tracker_scoreboard_00aeaed202.svg","previewUrl":null,"provider":"local","provider_metadata":null,"folderPath":"/2/4","createdAt":"2025-10-15T19:08:15.972Z","updatedAt":"2025-10-15T19:09:42.963Z","publishedAt":"2025-10-15T19:08:15.973Z","locale":null}}
{"type":"plugin::upload.file","id":188,"data":{"documentId":"aop6q2rp6qizun61zds040on","name":"Kubernetes.svg","alternativeText":"Kubernetes Logo","caption":"Kubernetes Logo","width":122,"height":118,"formats":null,"hash":"Kubernetes_78a24c52cd","ext":".svg","mime":"image/svg+xml","size":3.9,"url":"/uploads/Kubernetes_78a24c52cd.svg","previewUrl":null,"provider":"local","provider_metadata":null,"folderPath":"/2/10","createdAt":"2025-10-15T19:19:47.268Z","updatedAt":"2025-10-15T19:23:16.350Z","publishedAt":"2025-10-15T19:19:47.268Z","locale":null}}
{"type":"plugin::upload.file","id":189,"data":{"documentId":"bomm067iodifuc94rnnlu77i","name":"co2_tracker_history.svg","alternativeText":"CO2 Emission Tracker History","caption":"CO2 Emission Tracker History","width":1080,"height":1920,"formats":null,"hash":"co2_tracker_history_4c733ec5da","ext":".svg","mime":"image/svg+xml","size":379.39,"url":"/uploads/co2_tracker_history_4c733ec5da.svg","previewUrl":null,"provider":"local","provider_metadata":null,"folderPath":"/2/4","createdAt":"2025-10-15T19:08:15.912Z","updatedAt":"2025-10-15T19:09:58.200Z","publishedAt":"2025-10-15T19:08:15.912Z","locale":null}}
{"type":"plugin::upload.file","id":190,"data":{"documentId":"egbdq066kimuqdwjpovrrzho","name":"Link24_SignUp.svg","alternativeText":"Link24 Sign up","caption":"Link24 Sign up","width":2000,"height":1100,"formats":null,"hash":"Link24_Sign_Up_9c5ff3ebe4","ext":".svg","mime":"image/svg+xml","size":412.85,"url":"/uploads/Link24_Sign_Up_9c5ff3ebe4.svg","previewUrl":null,"provider":"local","provider_metadata":null,"folderPath":"/2/6","createdAt":"2025-10-15T19:17:56.436Z","updatedAt":"2025-10-15T19:17:56.436Z","publishedAt":"2025-10-15T19:17:56.436Z","locale":null}}
{"type":"plugin::upload.file","id":191,"data":{"documentId":"gbjcrne46la8ce3k9461yh7e","name":"contact_diary_persons.svg","alternativeText":"Corona Contact Diary Persons","caption":"Corona Contact Diary Persons","width":1080,"height":1920,"formats":null,"hash":"contact_diary_persons_9808d22281","ext":".svg","mime":"image/svg+xml","size":236.58,"url":"/uploads/contact_diary_persons_9808d22281.svg","previewUrl":null,"provider":"local","provider_metadata":null,"folderPath":"/2/8","createdAt":"2025-10-15T19:13:54.244Z","updatedAt":"2025-10-15T19:13:54.244Z","publishedAt":"2025-10-15T19:13:54.245Z","locale":null}}
{"type":"plugin::upload.file","id":192,"data":{"documentId":"gzridg78convp8p6tbc0c3cd","name":"contact_diary_encounter.svg","alternativeText":"Corona Contact Diary Encounters","caption":"Corona Contact Diary Encounters","width":1080,"height":1920,"formats":null,"hash":"contact_diary_encounter_f19fb3178c","ext":".svg","mime":"image/svg+xml","size":239.62,"url":"/uploads/contact_diary_encounter_f19fb3178c.svg","previewUrl":null,"provider":"local","provider_metadata":null,"folderPath":"/2/8","createdAt":"2025-10-15T19:13:54.762Z","updatedAt":"2025-10-15T19:13:54.762Z","publishedAt":"2025-10-15T19:13:54.763Z","locale":null}}
{"type":"plugin::upload.file","id":193,"data":{"documentId":"h8o8y258mnbd0o01crw0je5y","name":"huggingface.svg","alternativeText":"HuggingFace Icon","caption":"HuggingFace Icon","width":56,"height":56,"formats":null,"hash":"huggingface_ab5d3ff500","ext":".svg","mime":"image/svg+xml","size":4.6,"url":"/uploads/huggingface_ab5d3ff500.svg","previewUrl":null,"provider":"local","provider_metadata":null,"folderPath":"/13","createdAt":"2025-10-16T22:33:32.843Z","updatedAt":"2025-10-16T22:37:20.510Z","publishedAt":"2025-10-16T22:33:32.843Z","locale":null}}
{"type":"plugin::upload.file","id":194,"data":{"documentId":"hqo8acdnxen8ywwgcpc54otp","name":"Kotlin.svg","alternativeText":"Kotlin Logo","caption":"Kotlin Logo","width":97,"height":97,"formats":null,"hash":"Kotlin_52e20d2ae6","ext":".svg","mime":"image/svg+xml","size":0.51,"url":"/uploads/Kotlin_52e20d2ae6.svg","previewUrl":null,"provider":"local","provider_metadata":null,"folderPath":"/2/5","createdAt":"2025-10-15T19:20:41.808Z","updatedAt":"2025-10-15T19:20:41.808Z","publishedAt":"2025-10-15T19:20:41.809Z","locale":null}}
{"type":"plugin::upload.file","id":195,"data":{"documentId":"ihpkew1tn651ztlf9tsli9z8","name":"Python.svg","alternativeText":"Python Logo","caption":"Python Logo","width":102,"height":114,"formats":null,"hash":"Python_ea17c6b157","ext":".svg","mime":"image/svg+xml","size":2.31,"url":"/uploads/Python_ea17c6b157.svg","previewUrl":null,"provider":"local","provider_metadata":null,"folderPath":"/2/11","createdAt":"2025-10-15T19:24:51.694Z","updatedAt":"2025-10-15T19:24:51.694Z","publishedAt":"2025-10-15T19:24:51.694Z","locale":null}}
{"type":"plugin::upload.file","id":196,"data":{"documentId":"jgqak49sbutfv5s3ih0oe5se","name":"co2_tracker_history_detail.svg","alternativeText":"CO2 Emission Tracker History Details","caption":"CO2 Emission Tracker History Details","width":1080,"height":1920,"formats":null,"hash":"co2_tracker_history_detail_7f27881ad2","ext":".svg","mime":"image/svg+xml","size":1062.6,"url":"/uploads/co2_tracker_history_detail_7f27881ad2.svg","previewUrl":null,"provider":"local","provider_metadata":null,"folderPath":"/2/4","createdAt":"2025-10-15T19:08:16.066Z","updatedAt":"2025-10-15T19:09:29.875Z","publishedAt":"2025-10-15T19:08:16.067Z","locale":null}}
{"type":"plugin::upload.file","id":197,"data":{"documentId":"k10mmt82bau3lric3ij333bn","name":"Laravel.svg","alternativeText":"Laravel Logo","caption":"Laravel Logo","width":127,"height":131,"formats":null,"hash":"Laravel_0f62c2c80a","ext":".svg","mime":"image/svg+xml","size":4.97,"url":"/uploads/Laravel_0f62c2c80a.svg","previewUrl":null,"provider":"local","provider_metadata":null,"folderPath":"/2/9","createdAt":"2025-10-15T19:16:14.852Z","updatedAt":"2025-10-15T19:16:14.852Z","publishedAt":"2025-10-15T19:16:14.852Z","locale":null}}
{"type":"plugin::upload.file","id":198,"data":{"documentId":"odk0h2kd1b15863dbolnr541","name":"co2_tracker_challenge.svg","alternativeText":"CO2 Emission Tracker Challenges","caption":"CO2 Emission Tracker Challenges","width":1080,"height":1920,"formats":null,"hash":"co2_tracker_challenge_50106476fa","ext":".svg","mime":"image/svg+xml","size":518.24,"url":"/uploads/co2_tracker_challenge_50106476fa.svg","previewUrl":null,"provider":"local","provider_metadata":null,"folderPath":"/2/4","createdAt":"2025-10-15T19:08:16.120Z","updatedAt":"2025-10-15T19:09:16.251Z","publishedAt":"2025-10-15T19:08:16.120Z","locale":null}}
{"type":"plugin::upload.file","id":199,"data":{"documentId":"p8mv0705ddozmy61t1nm0lw0","name":"contact_diary_locations.svg","alternativeText":"Corona Contact Diary Locations","caption":"Corona Contact Diary Locations","width":1080,"height":1920,"formats":null,"hash":"contact_diary_locations_dacc1fb520","ext":".svg","mime":"image/svg+xml","size":238.79,"url":"/uploads/contact_diary_locations_dacc1fb520.svg","previewUrl":null,"provider":"local","provider_metadata":null,"folderPath":"/2/8","createdAt":"2025-10-15T19:13:53.974Z","updatedAt":"2025-10-15T19:13:53.974Z","publishedAt":"2025-10-15T19:13:53.974Z","locale":null}}
{"type":"plugin::upload.file","id":200,"data":{"documentId":"qad1vn4nxduyfv4z984ro9sl","name":"GraphQL.svg","alternativeText":"GraphQL Logo","caption":"GraphQL Logo","width":112,"height":125,"formats":null,"hash":"Graph_QL_fd3155ccac","ext":".svg","mime":"image/svg+xml","size":1.56,"url":"/uploads/Graph_QL_fd3155ccac.svg","previewUrl":null,"provider":"local","provider_metadata":null,"folderPath":"/2/3","createdAt":"2025-10-15T19:22:03.412Z","updatedAt":"2025-10-15T19:22:20.367Z","publishedAt":"2025-10-15T19:22:03.412Z","locale":null}}
{"type":"plugin::upload.file","id":201,"data":{"documentId":"qsb0yuqdg0fjnco4nrepte0b","name":"co2_tracker_home.svg","alternativeText":"CO2 Emission Tracker Homescreen","caption":"CO2 Emission Tracker Homescreen","width":1080,"height":1920,"formats":null,"hash":"co2_tracker_home_513bbafe34","ext":".svg","mime":"image/svg+xml","size":424.01,"url":"/uploads/co2_tracker_home_513bbafe34.svg","previewUrl":null,"provider":"local","provider_metadata":null,"folderPath":"/2/4","createdAt":"2025-10-15T19:08:15.667Z","updatedAt":"2025-10-15T19:08:54.395Z","publishedAt":"2025-10-15T19:08:15.667Z","locale":null}}
{"type":"plugin::upload.file","id":202,"data":{"documentId":"qv1t0rwivyyaf1uyoojuanj3","name":"Spacy.svg","alternativeText":"spaCy Icon","caption":"spaCy Icon","width":24,"height":24,"formats":null,"hash":"Spacy_1b571bcdfb","ext":".svg","mime":"image/svg+xml","size":2.17,"url":"/uploads/Spacy_1b571bcdfb.svg","previewUrl":null,"provider":"local","provider_metadata":null,"folderPath":"/13","createdAt":"2025-10-16T22:33:32.850Z","updatedAt":"2025-10-16T22:37:02.843Z","publishedAt":"2025-10-16T22:33:32.850Z","locale":null}}
{"type":"plugin::upload.folder","id":59,"data":{"documentId":"annhzmf8qzf28wd335indal7","name":"MyFavLocation","pathId":5,"path":"/2/5","createdAt":"2025-10-14T16:08:29.892Z","updatedAt":"2025-10-14T16:08:29.892Z","publishedAt":"2025-10-14T16:08:29.893Z","locale":null}}
{"type":"plugin::upload.folder","id":60,"data":{"documentId":"b8qzrgcfbo5bp02xss7yjas3","name":"Skill Icons","pathId":13,"path":"/13","createdAt":"2025-10-16T22:33:17.619Z","updatedAt":"2025-10-16T22:33:17.619Z","publishedAt":"2025-10-16T22:33:17.619Z","locale":null}}
{"type":"plugin::upload.folder","id":61,"data":{"documentId":"egw6mhuspkhro2yua5y12u8g","name":"Kubernetes URL Shortener","pathId":10,"path":"/2/10","createdAt":"2025-10-14T19:53:03.216Z","updatedAt":"2025-10-14T19:53:03.216Z","publishedAt":"2025-10-14T19:53:03.216Z","locale":null}}
{"type":"plugin::upload.folder","id":62,"data":{"documentId":"eiv5cvb66ilz4kodx93xrrbz","name":"LLM Fact Auditor","pathId":11,"path":"/2/11","createdAt":"2025-10-14T20:28:59.476Z","updatedAt":"2025-10-14T20:28:59.476Z","publishedAt":"2025-10-14T20:28:59.476Z","locale":null}}
{"type":"plugin::upload.folder","id":63,"data":{"documentId":"fn6ro82abb93q9tmjdzv0i2x","name":"Link24","pathId":6,"path":"/2/6","createdAt":"2025-10-14T17:33:11.499Z","updatedAt":"2025-10-14T17:33:11.499Z","publishedAt":"2025-10-14T17:33:11.499Z","locale":null}}
{"type":"plugin::upload.folder","id":64,"data":{"documentId":"hc2kr08v5ii9v8ehie0csddp","name":"Contact Log","pathId":8,"path":"/2/8","createdAt":"2025-10-14T18:17:22.562Z","updatedAt":"2025-10-14T18:17:22.562Z","publishedAt":"2025-10-14T18:17:22.563Z","locale":null}}
{"type":"plugin::upload.folder","id":65,"data":{"documentId":"ii3pp62rp27z0rvyoawm6h0s","name":"Portfolio Website","pathId":12,"path":"/2/12","createdAt":"2025-10-15T00:01:51.313Z","updatedAt":"2025-10-15T00:01:51.313Z","publishedAt":"2025-10-15T00:01:51.313Z","locale":null}}
{"type":"plugin::upload.folder","id":66,"data":{"documentId":"llpy4ge23guylz5u413xku5m","name":"Laravel Blog","pathId":9,"path":"/2/9","createdAt":"2025-10-14T18:39:01.057Z","updatedAt":"2025-10-14T18:39:01.057Z","publishedAt":"2025-10-14T18:39:01.057Z","locale":null}}
{"type":"plugin::upload.folder","id":67,"data":{"documentId":"noca8tf49x39044ju5oijvis","name":"Bachelor Thesis","pathId":7,"path":"/2/7","createdAt":"2025-10-14T17:54:15.263Z","updatedAt":"2025-10-14T17:54:15.263Z","publishedAt":"2025-10-14T17:54:15.264Z","locale":null}}
{"type":"plugin::upload.folder","id":68,"data":{"documentId":"q8wtfliao2710yill1ershln","name":"Software Projects","pathId":2,"path":"/2","createdAt":"2025-10-10T16:02:32.200Z","updatedAt":"2025-10-10T16:02:32.200Z","publishedAt":"2025-10-10T16:02:32.200Z","locale":null}}
{"type":"plugin::upload.folder","id":69,"data":{"documentId":"sk153d0eybi08jxxv273pao5","name":"Competition Web App","pathId":3,"path":"/2/3","createdAt":"2025-10-14T14:47:00.705Z","updatedAt":"2025-10-14T14:47:00.705Z","publishedAt":"2025-10-14T14:47:00.705Z","locale":null}}
{"type":"plugin::upload.folder","id":70,"data":{"documentId":"x8u6el0nnf3y4xj7rx0yuq6c","name":"CO2_Tracker","pathId":4,"path":"/2/4","createdAt":"2025-10-14T15:20:31.849Z","updatedAt":"2025-10-14T15:20:31.849Z","publishedAt":"2025-10-14T15:20:31.849Z","locale":null}}
{"type":"plugin::upload.folder","id":71,"data":{"documentId":"ypraficw2dt2935lzgzmqmyi","name":"Testimonials","pathId":1,"path":"/1","createdAt":"2025-10-02T20:06:28.408Z","updatedAt":"2025-10-02T20:06:28.408Z","publishedAt":"2025-10-02T20:06:28.408Z","locale":null}}
{"type":"plugin::upload.folder","id":72,"data":{"documentId":"v0xuhqe8a4agehsqfxltdqsh","name":"Albums","pathId":14,"path":"/14","createdAt":"2025-10-20T21:38:25.182Z","updatedAt":"2025-10-20T21:38:25.182Z","publishedAt":"2025-10-20T21:38:25.185Z","locale":null}}
{"type":"plugin::upload.folder","id":73,"data":{"documentId":"booguvg582lfozwks5szr899","name":"John & Karen Wedding","pathId":15,"path":"/14/15","createdAt":"2025-10-20T21:38:37.558Z","updatedAt":"2025-10-20T21:38:37.558Z","publishedAt":"2025-10-20T21:38:37.559Z","locale":null}}
{"type":"plugin::i18n.locale","id":9,"data":{"documentId":"ct6bvgtxq26cr398rz0aphqs","name":"German (de)","code":"de","createdAt":"2025-10-02T20:05:56.422Z","updatedAt":"2025-10-02T20:06:01.975Z","publishedAt":"2025-10-02T20:05:56.422Z","locale":null}}
{"type":"plugin::i18n.locale","id":10,"data":{"documentId":"u70qwwbqv37d7ifuhheeo0yz","name":"English (en)","code":"en","createdAt":"2025-09-29T16:33:21.653Z","updatedAt":"2025-09-29T16:33:21.653Z","publishedAt":"2025-09-29T16:33:21.656Z","locale":null}}
{"type":"plugin::users-permissions.permission","id":102,"data":{"documentId":"ctgpjq3dn5tpfu0vmb762s7g","action":"plugin::users-permissions.auth.forgotPassword","createdAt":"2025-09-29T16:33:22.053Z","updatedAt":"2025-09-29T16:33:22.053Z","publishedAt":"2025-09-29T16:33:22.054Z","locale":null}}
{"type":"plugin::users-permissions.permission","id":103,"data":{"documentId":"d8456xeq7yu9d3wc3dj78rph","action":"api::skill.skill.findOne","createdAt":"2025-09-29T23:38:57.122Z","updatedAt":"2025-09-29T23:38:57.122Z","publishedAt":"2025-09-29T23:38:57.133Z","locale":null}}
{"type":"plugin::users-permissions.permission","id":104,"data":{"documentId":"ezax5pv9hr8wrhcm1jdfpyb7","action":"api::software-project.software-project.find","createdAt":"2025-09-29T23:38:57.122Z","updatedAt":"2025-09-29T23:38:57.122Z","publishedAt":"2025-09-29T23:38:57.138Z","locale":null}}
{"type":"plugin::users-permissions.permission","id":105,"data":{"documentId":"f1g6okqyewz7ce39z3a3y4yz","action":"plugin::users-permissions.auth.callback","createdAt":"2025-09-29T16:33:22.053Z","updatedAt":"2025-09-29T16:33:22.053Z","publishedAt":"2025-09-29T16:33:22.053Z","locale":null}}
{"type":"plugin::users-permissions.permission","id":106,"data":{"documentId":"gseablb1f6euoktvqemt13ov","action":"plugin::users-permissions.auth.emailConfirmation","createdAt":"2025-09-29T16:33:22.053Z","updatedAt":"2025-09-29T16:33:22.053Z","publishedAt":"2025-09-29T16:33:22.054Z","locale":null}}
{"type":"plugin::users-permissions.permission","id":107,"data":{"documentId":"haimm1nw61n5luu1irkx53cy","action":"plugin::upload.content-api.upload","createdAt":"2025-09-29T23:38:57.122Z","updatedAt":"2025-09-29T23:38:57.122Z","publishedAt":"2025-09-29T23:38:57.143Z","locale":null}}
{"type":"plugin::users-permissions.permission","id":108,"data":{"documentId":"hdvl54qk3kpj5bhnds4wz529","action":"api::software-project.software-project.findOne","createdAt":"2025-09-29T23:38:57.122Z","updatedAt":"2025-09-29T23:38:57.122Z","publishedAt":"2025-09-29T23:38:57.138Z","locale":null}}
{"type":"plugin::users-permissions.permission","id":109,"data":{"documentId":"hh5hp4wvcbwys6anuestg8fl","action":"plugin::upload.content-api.find","createdAt":"2025-09-29T23:38:57.122Z","updatedAt":"2025-09-29T23:38:57.122Z","publishedAt":"2025-09-29T23:38:57.141Z","locale":null}}
{"type":"plugin::users-permissions.permission","id":110,"data":{"documentId":"i69fkzy3u3i7d4xi9z2jp3s1","action":"api::skill-category.skill-category.find","createdAt":"2025-09-29T23:38:57.122Z","updatedAt":"2025-09-29T23:38:57.122Z","publishedAt":"2025-09-29T23:38:57.136Z","locale":null}}
{"type":"plugin::users-permissions.permission","id":111,"data":{"documentId":"k20fpw2m78y57lz3clyo2u2e","action":"api::album.album.findOne","createdAt":"2025-09-29T23:38:57.122Z","updatedAt":"2025-09-29T23:38:57.122Z","publishedAt":"2025-09-29T23:38:57.128Z","locale":null}}
{"type":"plugin::users-permissions.permission","id":112,"data":{"documentId":"ka1rti5x2yv7a30ldgl519rt","action":"plugin::users-permissions.auth.changePassword","createdAt":"2025-09-29T16:33:21.958Z","updatedAt":"2025-09-29T16:33:21.958Z","publishedAt":"2025-09-29T16:33:21.960Z","locale":null}}
{"type":"plugin::users-permissions.permission","id":113,"data":{"documentId":"l6a53mw2497s5zd4ymu17z1k","action":"api::testimonial.testimonial.find","createdAt":"2025-09-29T23:38:57.122Z","updatedAt":"2025-09-29T23:38:57.122Z","publishedAt":"2025-09-29T23:38:57.139Z","locale":null}}
{"type":"plugin::users-permissions.permission","id":114,"data":{"documentId":"l6tnyg5cnsnavwj5mka4p281","action":"plugin::users-permissions.auth.sendEmailConfirmation","createdAt":"2025-09-29T16:33:22.053Z","updatedAt":"2025-09-29T16:33:22.053Z","publishedAt":"2025-09-29T16:33:22.055Z","locale":null}}
{"type":"plugin::users-permissions.permission","id":115,"data":{"documentId":"mhlojkr7ud6xkxxqx3uqgevc","action":"api::album.album.find","createdAt":"2025-09-29T23:38:57.122Z","updatedAt":"2025-09-29T23:38:57.122Z","publishedAt":"2025-09-29T23:38:57.125Z","locale":null}}
{"type":"plugin::users-permissions.permission","id":116,"data":{"documentId":"o4v07sgg1armpnv4m7liaqh7","action":"plugin::users-permissions.auth.register","createdAt":"2025-09-29T16:33:22.053Z","updatedAt":"2025-09-29T16:33:22.053Z","publishedAt":"2025-09-29T16:33:22.054Z","locale":null}}
{"type":"plugin::users-permissions.permission","id":117,"data":{"documentId":"ovinwfuy0ums2noq3ly8nvap","action":"api::testimonial.testimonial.findOne","createdAt":"2025-09-29T23:38:57.122Z","updatedAt":"2025-09-29T23:38:57.122Z","publishedAt":"2025-09-29T23:38:57.140Z","locale":null}}
{"type":"plugin::users-permissions.permission","id":118,"data":{"documentId":"sohkkvgd15y40azll21iuy4c","action":"api::testimonial.testimonial.create","createdAt":"2025-09-29T23:38:57.122Z","updatedAt":"2025-09-29T23:38:57.122Z","publishedAt":"2025-09-29T23:38:57.140Z","locale":null}}
{"type":"plugin::users-permissions.permission","id":119,"data":{"documentId":"tb5s8uoq2jnoo6zasftimx57","action":"api::skill.skill.find","createdAt":"2025-09-29T23:38:57.122Z","updatedAt":"2025-09-29T23:38:57.122Z","publishedAt":"2025-09-29T23:38:57.131Z","locale":null}}
{"type":"plugin::users-permissions.permission","id":120,"data":{"documentId":"tqffsuit94wacbh6r2fpa9vh","action":"plugin::upload.content-api.findOne","createdAt":"2025-09-29T23:38:57.122Z","updatedAt":"2025-09-29T23:38:57.122Z","publishedAt":"2025-09-29T23:38:57.142Z","locale":null}}
{"type":"plugin::users-permissions.permission","id":121,"data":{"documentId":"uadl1dbctygjen80z9tr5eis","action":"api::skill-category.skill-category.findOne","createdAt":"2025-09-29T23:38:57.122Z","updatedAt":"2025-09-29T23:38:57.122Z","publishedAt":"2025-09-29T23:38:57.137Z","locale":null}}
{"type":"plugin::users-permissions.permission","id":122,"data":{"documentId":"uvszovdhtvpvpmg3s025aj7y","action":"plugin::users-permissions.auth.connect","createdAt":"2025-09-29T16:33:22.053Z","updatedAt":"2025-09-29T16:33:22.053Z","publishedAt":"2025-09-29T16:33:22.053Z","locale":null}}
{"type":"plugin::users-permissions.permission","id":123,"data":{"documentId":"wdwndbcaofdluidal436tr2p","action":"plugin::users-permissions.user.me","createdAt":"2025-09-29T16:33:21.958Z","updatedAt":"2025-09-29T16:33:21.958Z","publishedAt":"2025-09-29T16:33:21.960Z","locale":null}}
{"type":"plugin::users-permissions.permission","id":124,"data":{"documentId":"y84a2flpgcxzr2rbxb7ijq6q","action":"plugin::users-permissions.auth.resetPassword","createdAt":"2025-09-29T16:33:22.053Z","updatedAt":"2025-09-29T16:33:22.053Z","publishedAt":"2025-09-29T16:33:22.054Z","locale":null}}
{"type":"plugin::users-permissions.role","id":10,"data":{"documentId":"gbnhf7aoom0b8z8fq8dy3czk","name":"Authenticated","description":"Default role given to authenticated user.","type":"authenticated","createdAt":"2025-09-29T16:33:21.808Z","updatedAt":"2025-09-29T16:33:21.808Z","publishedAt":"2025-09-29T16:33:21.842Z","locale":null}}
{"type":"plugin::users-permissions.role","id":11,"data":{"documentId":"vmrlbvs3185g15aisv5c6qcr","name":"Public","description":"Default role given to unauthenticated user.","type":"public","createdAt":"2025-09-29T16:33:21.885Z","updatedAt":"2025-09-29T23:38:57.115Z","publishedAt":"2025-09-29T16:33:21.885Z","locale":null}}
{"type":"api::skill.skill","id":160,"data":{"documentId":"maojys27s1fbqb7dqedlj0ma","name":"Strapi","iconClassName":null,"level":2,"url":"https://strapi.io/","createdAt":"2025-10-12T23:06:34.184Z","updatedAt":"2025-10-17T12:02:24.682Z","publishedAt":"2025-10-17T12:02:24.575Z","locale":"en"}}
{"type":"api::skill.skill","id":161,"data":{"documentId":"maojys27s1fbqb7dqedlj0ma","name":"Strapi","iconClassName":null,"level":2,"url":"https://strapi.io/","createdAt":"2025-10-12T23:06:19.989Z","updatedAt":"2025-10-17T12:02:24.766Z","publishedAt":"2025-10-17T12:02:16.121Z","locale":"de"}}
{"type":"api::skill.skill","id":162,"data":{"documentId":"arhfvb69ru9xvkz12vnikz9u","name":"Docker","iconClassName":"devicon-docker-plain","level":4,"url":"https://www.docker.com/","createdAt":"2025-10-16T21:03:35.499Z","updatedAt":"2025-10-16T21:03:35.499Z","publishedAt":"2025-10-16T21:03:35.486Z","locale":"de"}}
{"type":"api::skill.skill","id":163,"data":{"documentId":"arhfvb69ru9xvkz12vnikz9u","name":"Docker","iconClassName":"devicon-docker-plain","level":4,"url":"https://www.docker.com/","createdAt":"2025-10-16T21:03:55.467Z","updatedAt":"2025-10-16T21:03:55.467Z","publishedAt":"2025-10-16T21:03:55.455Z","locale":"en"}}
{"type":"api::skill.skill","id":164,"data":{"documentId":"f1ynza5o7msy2y1iagyg7wd1","name":"GraphQL","iconClassName":"devicon-graphql-plain","level":3,"url":"https://graphql.org/","createdAt":"2025-10-16T20:52:29.574Z","updatedAt":"2025-10-16T20:52:29.574Z","publishedAt":"2025-10-16T20:52:29.520Z","locale":"de"}}
{"type":"api::skill.skill","id":165,"data":{"documentId":"f1ynza5o7msy2y1iagyg7wd1","name":"GraphQL","iconClassName":"devicon-graphql-plain","level":3,"url":"https://graphql.org/","createdAt":"2025-10-16T20:51:58.583Z","updatedAt":"2025-10-16T20:51:58.583Z","publishedAt":"2025-10-16T20:51:58.540Z","locale":"en"}}
{"type":"api::skill.skill","id":166,"data":{"documentId":"fwuzu7ogekrs1575g7fx0gib","name":"GitLab CI/CD","iconClassName":"devicon-gitlab-plain","level":3,"url":"https://docs.gitlab.com/ee/ci/","createdAt":"2025-10-16T21:12:24.152Z","updatedAt":"2025-10-16T21:12:24.152Z","publishedAt":"2025-10-16T21:12:24.133Z","locale":"de"}}
{"type":"api::skill.skill","id":167,"data":{"documentId":"fwuzu7ogekrs1575g7fx0gib","name":"GitLab CI/CD","iconClassName":"devicon-gitlab-plain","level":3,"url":"https://docs.gitlab.com/ee/ci/","createdAt":"2025-10-16T21:12:04.465Z","updatedAt":"2025-10-16T21:12:04.465Z","publishedAt":"2025-10-16T21:12:04.450Z","locale":"en"}}
{"type":"api::skill.skill","id":168,"data":{"documentId":"g3sks95inoawkp230p38h4t9","name":"Next.js","iconClassName":"devicon-nextjs-plain","level":4,"url":"https://nextjs.org/","createdAt":"2025-10-12T23:26:53.174Z","updatedAt":"2025-10-16T20:49:58.916Z","publishedAt":"2025-10-16T20:49:58.891Z","locale":"de"}}
{"type":"api::skill.skill","id":169,"data":{"documentId":"g3sks95inoawkp230p38h4t9","name":"Next.js","iconClassName":"devicon-nextjs-plain","level":4,"url":"https://nextjs.org/","createdAt":"2025-10-12T22:18:23.950Z","updatedAt":"2025-10-16T20:50:04.179Z","publishedAt":"2025-10-16T20:50:04.127Z","locale":"en"}}
{"type":"api::skill.skill","id":170,"data":{"documentId":"gigkn1ylaoos0hwl84p9n4vc","name":"Kubernetes","iconClassName":"devicon-kubernetes-plain","level":2,"url":"https://kubernetes.io/","createdAt":"2025-10-16T21:09:24.707Z","updatedAt":"2025-10-16T21:09:24.707Z","publishedAt":"2025-10-16T21:09:24.698Z","locale":"de"}}
{"type":"api::skill.skill","id":171,"data":{"documentId":"gigkn1ylaoos0hwl84p9n4vc","name":"Kubernetes","iconClassName":"devicon-kubernetes-plain","level":2,"url":"https://kubernetes.io/","createdAt":"2025-10-16T21:09:40.994Z","updatedAt":"2025-10-16T21:09:40.994Z","publishedAt":"2025-10-16T21:09:40.964Z","locale":"en"}}
{"type":"api::skill.skill","id":172,"data":{"documentId":"hwcdjfu30nx4j0s5899f2r57","name":"PHP","iconClassName":"devicon-php-plain","level":2,"url":"https://www.php.net/","createdAt":"2025-10-16T20:56:57.555Z","updatedAt":"2025-10-16T20:56:57.555Z","publishedAt":"2025-10-16T20:56:57.513Z","locale":"de"}}
{"type":"api::skill.skill","id":173,"data":{"documentId":"hwcdjfu30nx4j0s5899f2r57","name":"PHP","iconClassName":"devicon-php-plain","level":2,"url":"https://www.php.net/","createdAt":"2025-10-16T20:56:34.914Z","updatedAt":"2025-10-16T20:56:34.914Z","publishedAt":"2025-10-16T20:56:34.903Z","locale":"en"}}
{"type":"api::skill.skill","id":174,"data":{"documentId":"ixkpyfei2e2vw9m9xis9xjkf","name":"Room DB","iconClassName":"devicon-sqlite-plain","level":1,"url":"https://developer.android.com/training/data-storage/room","createdAt":"2025-10-16T21:18:38.888Z","updatedAt":"2025-10-16T21:18:38.888Z","publishedAt":"2025-10-16T21:18:38.860Z","locale":"de"}}
{"type":"api::skill.skill","id":175,"data":{"documentId":"ixkpyfei2e2vw9m9xis9xjkf","name":"Room DB","iconClassName":"devicon-sqlite-plain","level":1,"url":"https://developer.android.com/training/data-storage/room","createdAt":"2025-10-16T21:18:25.684Z","updatedAt":"2025-10-16T21:18:25.684Z","publishedAt":"2025-10-16T21:18:25.672Z","locale":"en"}}
{"type":"api::skill.skill","id":176,"data":{"documentId":"ja1ucveiez7c9dh1maswonoc","name":"Microsoft Azure","iconClassName":"devicon-azure-plain","level":2,"url":"https://azure.microsoft.com/","createdAt":"2025-10-16T21:11:02.684Z","updatedAt":"2025-10-16T21:11:02.684Z","publishedAt":"2025-10-16T21:11:02.676Z","locale":"de"}}
{"type":"api::skill.skill","id":177,"data":{"documentId":"ja1ucveiez7c9dh1maswonoc","name":"Microsoft Azure","iconClassName":"devicon-azure-plain","level":2,"url":"https://azure.microsoft.com/","createdAt":"2025-10-16T21:11:29.254Z","updatedAt":"2025-10-16T21:11:29.254Z","publishedAt":"2025-10-16T21:11:29.237Z","locale":"en"}}
{"type":"api::skill.skill","id":178,"data":{"documentId":"jfz784cledjtrof3tuvx69oq","name":"Tailwind CSS","iconClassName":"devicon-tailwindcss-plain","level":2,"url":"https://tailwindcss.com/","createdAt":"2025-10-12T23:28:55.415Z","updatedAt":"2025-10-12T23:28:55.415Z","publishedAt":"2025-10-12T23:28:55.387Z","locale":"de"}}
{"type":"api::skill.skill","id":179,"data":{"documentId":"jfz784cledjtrof3tuvx69oq","name":"Tailwind CSS","iconClassName":"devicon-tailwindcss-plain","level":2,"url":"https://tailwindcss.com/","createdAt":"2025-10-12T23:28:43.249Z","updatedAt":"2025-10-12T23:28:43.249Z","publishedAt":"2025-10-12T23:28:43.239Z","locale":"en"}}
{"type":"api::skill.skill","id":180,"data":{"documentId":"kcxnv3t2v8nh53zggkq4hzhz","name":"spaCy","iconClassName":null,"level":1,"url":"https://spacy.io/","createdAt":"2025-10-16T21:02:09.496Z","updatedAt":"2025-10-16T22:34:40.692Z","publishedAt":"2025-10-16T22:34:40.688Z","locale":"de"}}
{"type":"api::skill.skill","id":181,"data":{"documentId":"kcxnv3t2v8nh53zggkq4hzhz","name":"spaCy","iconClassName":null,"level":1,"url":"https://spacy.io/","createdAt":"2025-10-16T21:02:23.640Z","updatedAt":"2025-10-16T22:34:40.697Z","publishedAt":"2025-10-16T21:21:20.083Z","locale":"en"}}
{"type":"api::skill.skill","id":182,"data":{"documentId":"kzkdwsotymjditjcw7xkro3a","name":"Core Data","iconClassName":"devicon-apple-original","level":2,"url":"https://developer.apple.com/documentation/coredata","createdAt":"2025-10-16T21:17:14.477Z","updatedAt":"2025-10-16T21:17:14.477Z","publishedAt":"2025-10-16T21:17:14.467Z","locale":"de"}}
{"type":"api::skill.skill","id":183,"data":{"documentId":"kzkdwsotymjditjcw7xkro3a","name":"Core Data","iconClassName":"devicon-apple-original","level":2,"url":"https://developer.apple.com/documentation/coredata","createdAt":"2025-10-16T21:17:30.840Z","updatedAt":"2025-10-16T21:17:30.840Z","publishedAt":"2025-10-16T21:17:30.822Z","locale":"en"}}
{"type":"api::skill.skill","id":184,"data":{"documentId":"nj35xf54kjx9ax5ys2ahjer5","name":"Node.js","iconClassName":"devicon-nodejs-plain","level":2,"url":"https://nodejs.org/","createdAt":"2025-10-16T20:53:04.526Z","updatedAt":"2025-10-16T20:53:04.526Z","publishedAt":"2025-10-16T20:53:04.517Z","locale":"de"}}
{"type":"api::skill.skill","id":185,"data":{"documentId":"nj35xf54kjx9ax5ys2ahjer5","name":"Node.js","iconClassName":"devicon-nodejs-plain","level":2,"url":"https://nodejs.org/","createdAt":"2025-10-16T20:53:22.280Z","updatedAt":"2025-10-16T20:53:22.280Z","publishedAt":"2025-10-16T20:53:22.155Z","locale":"en"}}
{"type":"api::skill.skill","id":186,"data":{"documentId":"nruyuxpm8am50etehr20iktn","name":"Kotlin","iconClassName":"devicon-kotlin-plain","level":2,"url":"https://kotlinlang.org/","createdAt":"2025-10-16T21:14:46.956Z","updatedAt":"2025-10-16T21:14:46.956Z","publishedAt":"2025-10-16T21:14:46.945Z","locale":"de"}}
{"type":"api::skill.skill","id":187,"data":{"documentId":"nruyuxpm8am50etehr20iktn","name":"Kotlin","iconClassName":"devicon-kotlin-plain","level":2,"url":"https://kotlinlang.org/","createdAt":"2025-10-16T21:15:05.058Z","updatedAt":"2025-10-16T21:15:05.058Z","publishedAt":"2025-10-16T21:15:05.041Z","locale":"en"}}
{"type":"api::skill.skill","id":188,"data":{"documentId":"o42kh3qpipfiajahecnszito","name":"MongoDB","iconClassName":"devicon-mongodb-plain","level":2,"url":"https://www.mongodb.com/","createdAt":"2025-10-16T20:55:51.796Z","updatedAt":"2025-10-16T20:55:51.796Z","publishedAt":"2025-10-16T20:55:51.782Z","locale":"de"}}
{"type":"api::skill.skill","id":189,"data":{"documentId":"o42kh3qpipfiajahecnszito","name":"MongoDB","iconClassName":"devicon-mongodb-plain","level":2,"url":"https://www.mongodb.com/","createdAt":"2025-10-16T20:56:07.356Z","updatedAt":"2025-10-16T20:56:07.356Z","publishedAt":"2025-10-16T20:56:07.326Z","locale":"en"}}
{"type":"api::skill.skill","id":190,"data":{"documentId":"oc9j6pnwdk5zyl1lo4j1cnik","name":"NGINX","iconClassName":"devicon-nginx-original","level":3,"url":"https://www.nginx.com/","createdAt":"2025-10-16T21:12:47.816Z","updatedAt":"2025-10-16T21:13:18.738Z","publishedAt":"2025-10-16T21:13:18.689Z","locale":"de"}}
{"type":"api::skill.skill","id":191,"data":{"documentId":"oc9j6pnwdk5zyl1lo4j1cnik","name":"NGINX","iconClassName":"devicon-nginx-original","level":3,"url":"https://www.nginx.com/","createdAt":"2025-10-16T21:13:13.257Z","updatedAt":"2025-10-16T21:13:13.257Z","publishedAt":"2025-10-16T21:13:13.237Z","locale":"en"}}
{"type":"api::skill.skill","id":192,"data":{"documentId":"oukhfiylm8gsi5g8kp17jfqi","name":"LLM","iconClassName":null,"level":2,"url":"https://en.wikipedia.org/wiki/Large_language_model","createdAt":"2025-10-16T21:03:07.094Z","updatedAt":"2025-10-16T22:34:25.598Z","publishedAt":"2025-10-16T21:21:39.014Z","locale":"de"}}
{"type":"api::skill.skill","id":193,"data":{"documentId":"oukhfiylm8gsi5g8kp17jfqi","name":"LLM","iconClassName":null,"level":2,"url":"https://en.wikipedia.org/wiki/Large_language_model","createdAt":"2025-10-16T21:02:48.391Z","updatedAt":"2025-10-16T22:34:25.593Z","publishedAt":"2025-10-16T22:34:25.589Z","locale":"en"}}
{"type":"api::skill.skill","id":194,"data":{"documentId":"pc04vw8tkoov8e0ukqy71ts2","name":"TypeScript","iconClassName":"devicon-typescript-plain","level":3,"url":"https://www.typescriptlang.org/","createdAt":"2025-10-12T23:27:41.492Z","updatedAt":"2025-10-12T23:27:41.492Z","publishedAt":"2025-10-12T23:27:41.438Z","locale":"de"}}
{"type":"api::skill.skill","id":195,"data":{"documentId":"pc04vw8tkoov8e0ukqy71ts2","name":"TypeScript","iconClassName":"devicon-typescript-plain","level":2,"url":"https://www.typescriptlang.org/","createdAt":"2025-10-12T23:23:58.884Z","updatedAt":"2025-10-12T23:23:58.884Z","publishedAt":"2025-10-12T23:23:58.874Z","locale":"en"}}
{"type":"api::skill.skill","id":196,"data":{"documentId":"q5awztxuwx0oefy8torha0vn","name":"Terraform","iconClassName":"devicon-terraform-plain","level":4,"url":"https://www.terraform.io/","createdAt":"2025-10-16T21:10:30.694Z","updatedAt":"2025-10-16T21:10:30.694Z","publishedAt":"2025-10-16T21:10:30.675Z","locale":"de"}}
{"type":"api::skill.skill","id":197,"data":{"documentId":"q5awztxuwx0oefy8torha0vn","name":"Terraform","iconClassName":"devicon-terraform-plain","level":4,"url":"https://www.terraform.io/","createdAt":"2025-10-16T21:10:10.819Z","updatedAt":"2025-10-16T21:10:10.819Z","publishedAt":"2025-10-16T21:10:10.808Z","locale":"en"}}
{"type":"api::skill.skill","id":198,"data":{"documentId":"tbrzxo2g0dqkfuhi11et68d5","name":"Framer Motion","iconClassName":"devicon-framermotion-original","level":1,"url":"https://motion.dev/","createdAt":"2025-10-12T23:30:12.880Z","updatedAt":"2025-10-16T20:50:50.082Z","publishedAt":"2025-10-16T20:50:49.902Z","locale":"de"}}
{"type":"api::skill.skill","id":199,"data":{"documentId":"tbrzxo2g0dqkfuhi11et68d5","name":"Framer Motion","iconClassName":"devicon-framermotion-original","level":1,"url":"https://motion.dev/","createdAt":"2025-10-12T23:29:59.385Z","updatedAt":"2025-10-16T20:50:55.821Z","publishedAt":"2025-10-16T20:50:55.803Z","locale":"en"}}
{"type":"api::skill.skill","id":200,"data":{"documentId":"ti6zbczbv41ok0vq1ywcxyoo","name":"Python","iconClassName":"devicon-python-plain","level":2,"url":"https://www.python.org/","createdAt":"2025-10-16T20:54:14.296Z","updatedAt":"2025-10-16T20:54:14.296Z","publishedAt":"2025-10-16T20:54:14.222Z","locale":"de"}}
{"type":"api::skill.skill","id":201,"data":{"documentId":"ti6zbczbv41ok0vq1ywcxyoo","name":"Python","iconClassName":"devicon-python-plain","level":2,"url":"https://www.python.org/","createdAt":"2025-10-16T20:53:54.362Z","updatedAt":"2025-10-16T20:53:54.362Z","publishedAt":"2025-10-16T20:53:54.351Z","locale":"en"}}
{"type":"api::skill.skill","id":202,"data":{"documentId":"tkmd15429jm6yvqbvswypv7m","name":"Android Jetpack","iconClassName":"devicon-android-plain","level":2,"url":"https://developer.android.com/jetpack","createdAt":"2025-10-16T21:16:43.692Z","updatedAt":"2025-10-16T21:16:43.692Z","publishedAt":"2025-10-16T21:16:43.613Z","locale":"de"}}
{"type":"api::skill.skill","id":203,"data":{"documentId":"tkmd15429jm6yvqbvswypv7m","name":"Android Jetpack","iconClassName":"devicon-android-plain","level":2,"url":"https://developer.android.com/jetpack","createdAt":"2025-10-16T21:16:23.951Z","updatedAt":"2025-10-16T21:16:23.951Z","publishedAt":"2025-10-16T21:16:23.942Z","locale":"en"}}
{"type":"api::skill.skill","id":204,"data":{"documentId":"u1zm1mv5jlvfy0r727bsl47a","name":"next-intl","iconClassName":"devicon-json-plain","level":2,"url":"https://next-intl.dev/","createdAt":"2025-10-13T15:25:39.780Z","updatedAt":"2025-10-13T15:25:39.780Z","publishedAt":"2025-10-13T15:25:39.765Z","locale":"de"}}
{"type":"api::skill.skill","id":205,"data":{"documentId":"u1zm1mv5jlvfy0r727bsl47a","name":"next-intl","iconClassName":"devicon-json-plain","level":2,"url":"https://next-intl.dev/","createdAt":"2025-10-13T15:25:25.275Z","updatedAt":"2025-10-13T15:25:25.275Z","publishedAt":"2025-10-13T15:25:25.269Z","locale":"en"}}
{"type":"api::skill.skill","id":206,"data":{"documentId":"ujtsq9me3ehekd21aredaowd","name":"Transformers","iconClassName":null,"level":1,"url":"https://huggingface.co/docs/transformers/index","createdAt":"2025-10-16T21:00:10.948Z","updatedAt":"2025-10-16T22:34:09.740Z","publishedAt":"2025-10-16T22:34:09.733Z","locale":"de"}}
{"type":"api::skill.skill","id":207,"data":{"documentId":"ujtsq9me3ehekd21aredaowd","name":"Transformers","iconClassName":null,"level":1,"url":"https://huggingface.co/docs/transformers/index","createdAt":"2025-10-16T21:00:33.716Z","updatedAt":"2025-10-16T22:34:09.745Z","publishedAt":"2025-10-16T21:20:57.407Z","locale":"en"}}
{"type":"api::skill.skill","id":208,"data":{"documentId":"v0cq6twyzbzp4m0p8s4o2rw7","name":"React","iconClassName":"devicon-react-plain","level":3,"url":"https://react.dev/","createdAt":"2025-10-12T23:27:10.798Z","updatedAt":"2025-10-12T23:27:15.092Z","publishedAt":"2025-10-12T23:27:14.658Z","locale":"de"}}
{"type":"api::skill.skill","id":209,"data":{"documentId":"v0cq6twyzbzp4m0p8s4o2rw7","name":"React","iconClassName":"devicon-react-plain","level":3,"url":"https://react.dev/","createdAt":"2025-10-12T23:03:48.893Z","updatedAt":"2025-10-12T23:03:48.893Z","publishedAt":"2025-10-12T23:03:48.884Z","locale":"en"}}
{"type":"api::skill.skill","id":210,"data":{"documentId":"vm72ab9mb0496kqe0vzra7ik","name":"Swift","iconClassName":"devicon-swift-plain","level":4,"url":"https://developer.apple.com/swift/","createdAt":"2025-10-16T21:14:25.017Z","updatedAt":"2025-10-16T21:14:25.017Z","publishedAt":"2025-10-16T21:14:24.999Z","locale":"de"}}
{"type":"api::skill.skill","id":211,"data":{"documentId":"vm72ab9mb0496kqe0vzra7ik","name":"Swift","iconClassName":"devicon-swift-plain","level":4,"url":"https://developer.apple.com/swift/","createdAt":"2025-10-16T21:14:08.276Z","updatedAt":"2025-10-16T21:14:08.276Z","publishedAt":"2025-10-16T21:14:08.227Z","locale":"en"}}
{"type":"api::skill.skill","id":212,"data":{"documentId":"yircxj57j2iry1bv8fspp04o","name":"Express.js","iconClassName":"devicon-express-original","level":3,"url":"https://expressjs.com/","createdAt":"2025-10-16T20:55:21.644Z","updatedAt":"2025-10-16T20:55:21.644Z","publishedAt":"2025-10-16T20:55:21.627Z","locale":"de"}}
{"type":"api::skill.skill","id":213,"data":{"documentId":"yircxj57j2iry1bv8fspp04o","name":"Express.js","iconClassName":"devicon-express-original","level":3,"url":"https://expressjs.com/","createdAt":"2025-10-16T20:55:00.855Z","updatedAt":"2025-10-16T20:55:00.855Z","publishedAt":"2025-10-16T20:55:00.844Z","locale":"en"}}
{"type":"api::skill.skill","id":214,"data":{"documentId":"yura3elffm08sijro7el9aif","name":"PyTorch","iconClassName":"devicon-pytorch-original","level":1,"url":"https://pytorch.org/","createdAt":"2025-10-16T20:57:59.506Z","updatedAt":"2025-10-16T20:57:59.506Z","publishedAt":"2025-10-16T20:57:59.495Z","locale":"de"}}
{"type":"api::skill.skill","id":215,"data":{"documentId":"yura3elffm08sijro7el9aif","name":"PyTorch","iconClassName":"devicon-pytorch-original","level":1,"url":"https://pytorch.org/","createdAt":"2025-10-16T20:58:29.481Z","updatedAt":"2025-10-16T20:58:29.481Z","publishedAt":"2025-10-16T20:58:29.390Z","locale":"en"}}
{"type":"api::skill-category.skill-category","id":33,"data":{"documentId":"dnk6s6ytvuujkkd46mn0940k","name":"Backend","order":2,"createdAt":"2025-10-12T22:16:46.084Z","updatedAt":"2025-10-16T21:07:26.041Z","publishedAt":"2025-10-16T21:07:26.028Z","locale":"de"}}
{"type":"api::skill-category.skill-category","id":34,"data":{"documentId":"dnk6s6ytvuujkkd46mn0940k","name":"Backend","order":2,"createdAt":"2025-10-16T21:07:19.764Z","updatedAt":"2025-10-16T21:07:19.764Z","publishedAt":"2025-10-16T21:07:19.734Z","locale":"en"}}
{"type":"api::skill-category.skill-category","id":35,"data":{"documentId":"e3fszrhr39vfa4u2ojwuwbu2","name":"AI","order":3,"createdAt":"2025-10-16T20:57:50.283Z","updatedAt":"2025-10-16T21:23:36.597Z","publishedAt":"2025-10-16T21:23:36.578Z","locale":"de"}}
{"type":"api::skill-category.skill-category","id":36,"data":{"documentId":"e3fszrhr39vfa4u2ojwuwbu2","name":"AI ","order":3,"createdAt":"2025-10-16T20:58:53.286Z","updatedAt":"2025-10-16T21:23:40.905Z","publishedAt":"2025-10-16T21:23:40.890Z","locale":"en"}}
{"type":"api::skill-category.skill-category","id":37,"data":{"documentId":"se5orxvf26i703wnucpw577v","name":"Mobile","order":5,"createdAt":"2025-10-16T21:13:32.235Z","updatedAt":"2025-10-16T21:23:52.117Z","publishedAt":"2025-10-16T21:23:51.883Z","locale":"de"}}
{"type":"api::skill-category.skill-category","id":38,"data":{"documentId":"se5orxvf26i703wnucpw577v","name":"Mobile","order":5,"createdAt":"2025-10-16T21:13:44.287Z","updatedAt":"2025-10-16T21:23:47.875Z","publishedAt":"2025-10-16T21:23:47.799Z","locale":"en"}}
{"type":"api::skill-category.skill-category","id":39,"data":{"documentId":"v63ao7tcinpzr6jg54kv8g4w","name":"Frontend","order":1,"createdAt":"2025-10-16T21:06:40.539Z","updatedAt":"2025-10-16T21:06:40.539Z","publishedAt":"2025-10-16T21:06:40.507Z","locale":"de"}}
{"type":"api::skill-category.skill-category","id":40,"data":{"documentId":"v63ao7tcinpzr6jg54kv8g4w","name":"Frontend","order":1,"createdAt":"2025-10-12T22:17:20.596Z","updatedAt":"2025-10-16T21:08:32.191Z","publishedAt":"2025-10-16T21:08:32.103Z","locale":"en"}}
{"type":"api::skill-category.skill-category","id":41,"data":{"documentId":"wv99w4ntkwqvj0ylkllhs90r","name":"DevOps","order":4,"createdAt":"2025-10-12T22:17:05.620Z","updatedAt":"2025-10-16T21:23:59.077Z","publishedAt":"2025-10-16T21:23:59.049Z","locale":"de"}}
{"type":"api::skill-category.skill-category","id":42,"data":{"documentId":"wv99w4ntkwqvj0ylkllhs90r","name":"DevOps","order":4,"createdAt":"2025-10-16T20:59:26.050Z","updatedAt":"2025-10-16T21:24:04.060Z","publishedAt":"2025-10-16T21:24:04.029Z","locale":"en"}}
{"type":"api::software-project.software-project","id":155,"data":{"documentId":"ws6tkh7iwt99vl26obky3c1p","title":"Dynamische Dual-Portfolio Webseite","slug":"dynamische-dual-portfolio-webseite","description":"Eine Portfolio-Plattform als Monorepo, die über separate Domains Bereiche für Software und Fotografie bereitstellt. Alle Inhalte werden dynamisch von einem Headless-CMS (Strapi) verwaltet.","longDescription":"### Projektübersicht\n\nDieses Projekt ist das Portfolio, das Sie gerade ansehen. Es wurde als \"Hub-and-Spoke\"-Plattform konzipiert, um zwei unterschiedliche Fachgebiete – Softwareentwicklung und Fotografie – professionell unter einer einheitlichen Marke zu präsentieren. Die Architektur besteht aus einem modernen Monorepo, das ein headless Strapi-Backend und ein Multi-Domain Next.js-Frontend umfasst.\n\n### Kernfunktionen\n\n*   **Multi-Domain-Routing:** Die Anwendung liefert je nach Domainnamen (`codeby.joeldettinger.de` für Software, `photosby.joeldettinger.de` für Fotografie) unterschiedliche Inhalte aus, was über Next.js Middleware realisiert wird.\n*   **Headless CMS-Integration:** Alle Projektdetails, Skills, Fotoalben und Testimonials werden dynamisch von einem selbst gehosteten Strapi CMS abgerufen. Dies ermöglicht einfache Inhaltsaktualisierungen ohne Code-Änderungen.\n*   **Vollständige Internationalisierung (i18n):** Die gesamte Benutzeroberfläche, einschließlich aller Inhalte aus dem CMS, ist auf Englisch und Deutsch verfügbar. Die Sprache wird basierend auf den Browsereinstellungen erkannt und kann manuell umgeschaltet werden.\n*   **Benutzerdefinierte Strapi-Controller:** Das Backend verwendet benutzerdefinierte Controller, z. B. für das Formular zur Einreichung von Testimonials. Dieser integriert Google reCAPTCHA zum Schutz vor Spam und eine spezielle Logik, um Datei-Uploads in dedizierten Ordnern der Medienbibliothek zu organisieren.\n*   **Dynamisches Theming:** Ein \"Paper-like\"-Design mit vollständiger Unterstützung für System-, Light- und Dark-Modus, umgesetzt mit Tailwind CSS und `next-themes`.\n\n### Technische Herausforderungen & Lösungen\n\nEine der größten Herausforderungen war die Schaffung einer nahtlosen lokalen Entwicklungsumgebung, die die Multi-Domain-Produktionsumgebung exakt simulieren kann. Dies wurde durch die Implementierung einer `DEV_FORCE_DOMAIN`-Umgebungsvariable gelöst, die die Next.js-Middleware anweist, `localhost`-Anfragen so zu behandeln, als kämen sie von einer bestimmten Subdomain.\n\nEine weitere Herausforderung war die Verarbeitung von Datei-Uploads über ein öffentliches Formular. Dies erforderte eine sorgfältige Konfiguration der Benutzerrollen in Strapi, der Berechtigungen für das Upload-Plugin sowie einen benutzerdefinierten Controller, der die Anfrage validiert, bevor die Datei an den Upload-Service von Strapi übergeben wird.","projectType":"Full-Stack Web Application","developedAt":"2025-10-10","liveUrl":"https://joeldettinger.de/","repoUrl":"https://github.com/dettinjo/portfolio-landing","tags":["Next.js","React","Strapi","TypeScript","Tailwind CSS","next-intl","Framer Motion"],"createdAt":"2025-10-10T16:10:59.606Z","updatedAt":"2025-11-18T12:51:51.926Z","publishedAt":null,"locale":"de"}}
{"type":"api::software-project.software-project","id":156,"data":{"documentId":"ws6tkh7iwt99vl26obky3c1p","title":"Dynamic Dual-Portfolio Website","slug":"dynamic-dual-portfolio-website","description":"A complete portfolio platform built as a monorepo. It features distinct, multi-domain sites for software and photography, with all content dynamically managed by a headless Strapi CMS.","longDescription":"### Project Overview\n\nThis project is the very portfolio you are browsing now. It was conceived as a \"hub-and-spoke\" platform to professionally showcase two distinct skill sets—software development and photography—under a single, cohesive brand. The architecture is a modern monorepo containing a headless Strapi backend and a multi-domain Next.js frontend.\n\n### Core Features\n\n*   **Multi-Domain Routing:** The application intelligently serves different content based on the domain name (`codeby.joeldettinger.de` for software, `photosby.joeldettinger.de` for photography) using Next.js Middleware.\n*   **Headless CMS Integration:** All project details, skill listings, photo albums, and testimonials are dynamically fetched from a self-hosted Strapi CMS, allowing for easy content updates without code changes.\n*   **Full Internationalization (i18n):** The entire user interface, including all content from the CMS, is available in both English and German, with locale detection based on browser settings and a manual language switcher.\n*   **Custom Strapi Controllers:** The backend features custom controllers, such as for the testimonial submission form, which integrates Google reCAPTCHA for spam protection and custom logic for organizing file uploads into specific media library folders.\n*   **Dynamic Theming:** A \"Paper-like\" design with full support for system, light, and dark modes, built with Tailwind CSS and `next-themes`.\n\n### Technical Challenges & Solutions\n\nOne of the main challenges was creating a seamless local development experience that could accurately simulate the multi-domain production environment. This was solved by implementing a `DEV_FORCE_DOMAIN` environment variable that instructs the Next.js Middleware to route `localhost` traffic as if it were coming from a specific subdomain.\n\nAnother challenge was handling file uploads from a public-facing form. This required careful configuration of Strapi's user roles, permissions for the upload plugin, and a custom controller to validate the request before passing the file to Strapi's upload service.","projectType":"Full-Stack Web Application","developedAt":"2025-10-10","liveUrl":"https://joeldettinger.de","repoUrl":"https://github.com/dettinjo/portfolio-landing","tags":["Next.js","React","Strapi","TypeScript","Tailwind CSS","next-intl","Framer Motion"],"createdAt":"2025-10-10T16:12:12.511Z","updatedAt":"2025-11-18T12:51:59.396Z","publishedAt":"2025-11-18T12:51:59.465Z","locale":"en"}}
{"type":"api::software-project.software-project","id":157,"data":{"documentId":"ws6tkh7iwt99vl26obky3c1p","title":"Dynamische Dual-Portfolio Webseite","slug":"dynamische-dual-portfolio-webseite","description":"Eine Portfolio-Plattform als Monorepo, die über separate Domains Bereiche für Software und Fotografie bereitstellt. Alle Inhalte werden dynamisch von einem Headless-CMS (Strapi) verwaltet.","longDescription":"### Projektübersicht\n\nDieses Projekt ist das Portfolio, das Sie gerade ansehen. Es wurde als \"Hub-and-Spoke\"-Plattform konzipiert, um zwei unterschiedliche Fachgebiete – Softwareentwicklung und Fotografie – professionell unter einer einheitlichen Marke zu präsentieren. Die Architektur besteht aus einem modernen Monorepo, das ein headless Strapi-Backend und ein Multi-Domain Next.js-Frontend umfasst.\n\n### Kernfunktionen\n\n*   **Multi-Domain-Routing:** Die Anwendung liefert je nach Domainnamen (`codeby.joeldettinger.de` für Software, `photosby.joeldettinger.de` für Fotografie) unterschiedliche Inhalte aus, was über Next.js Middleware realisiert wird.\n*   **Headless CMS-Integration:** Alle Projektdetails, Skills, Fotoalben und Testimonials werden dynamisch von einem selbst gehosteten Strapi CMS abgerufen. Dies ermöglicht einfache Inhaltsaktualisierungen ohne Code-Änderungen.\n*   **Vollständige Internationalisierung (i18n):** Die gesamte Benutzeroberfläche, einschließlich aller Inhalte aus dem CMS, ist auf Englisch und Deutsch verfügbar. Die Sprache wird basierend auf den Browsereinstellungen erkannt und kann manuell umgeschaltet werden.\n*   **Benutzerdefinierte Strapi-Controller:** Das Backend verwendet benutzerdefinierte Controller, z. B. für das Formular zur Einreichung von Testimonials. Dieser integriert Google reCAPTCHA zum Schutz vor Spam und eine spezielle Logik, um Datei-Uploads in dedizierten Ordnern der Medienbibliothek zu organisieren.\n*   **Dynamisches Theming:** Ein \"Paper-like\"-Design mit vollständiger Unterstützung für System-, Light- und Dark-Modus, umgesetzt mit Tailwind CSS und `next-themes`.\n\n### Technische Herausforderungen & Lösungen\n\nEine der größten Herausforderungen war die Schaffung einer nahtlosen lokalen Entwicklungsumgebung, die die Multi-Domain-Produktionsumgebung exakt simulieren kann. Dies wurde durch die Implementierung einer `DEV_FORCE_DOMAIN`-Umgebungsvariable gelöst, die die Next.js-Middleware anweist, `localhost`-Anfragen so zu behandeln, als kämen sie von einer bestimmten Subdomain.\n\nEine weitere Herausforderung war die Verarbeitung von Datei-Uploads über ein öffentliches Formular. Dies erforderte eine sorgfältige Konfiguration der Benutzerrollen in Strapi, der Berechtigungen für das Upload-Plugin sowie einen benutzerdefinierten Controller, der die Anfrage validiert, bevor die Datei an den Upload-Service von Strapi übergeben wird.","projectType":"Full-Stack Web Application","developedAt":"2025-10-10","liveUrl":"https://joeldettinger.de/","repoUrl":"https://github.com/dettinjo/portfolio-landing","tags":["Next.js","React","Strapi","TypeScript","Tailwind CSS","next-intl","Framer Motion"],"createdAt":"2025-10-10T16:10:59.606Z","updatedAt":"2025-11-18T12:51:51.926Z","publishedAt":"2025-11-18T12:51:51.985Z","locale":"de"}}
{"type":"api::software-project.software-project","id":158,"data":{"documentId":"cwiul80y8heifqqzfa5dbajk","title":"Corona-Kontakttagebuch iOS App","slug":"corona-kontakttagebuch-i-os-app","description":"Eine native iOS-App zur privaten Protokollierung von Kontakten und Orten zur Kontaktverfolgung, mit automatischer Datenlöschung nach 14 Tagen.","longDescription":"### Projektübersicht\nDas Corona-Kontakttagebuch ist eine iOS-Anwendung, die als Antwort auf die Notwendigkeit einer effektiven Kontaktverfolgung während der Pandemie entwickelt wurde. Sie bietet den Nutzern eine sichere und private Möglichkeit, ihre täglichen Begegnungen mit Personen und Besuche an Orten zu protokollieren. Alle Daten werden lokal auf dem Gerät des Nutzers gespeichert und nach 14 Tagen automatisch gelöscht, um die Privatsphäre zu gewährleisten. Die App wurde als praktisches Werkzeug konzipiert, das den Nutzern hilft, ihre jüngsten Aktivitäten bei Bedarf aus gesundheitlichen Gründen schnell nachzuvollziehen.\n\n### Die Herausforderung\nDie primäre Herausforderung bestand darin, eine robuste, benutzerfreundliche mobile Anwendung zu entwickeln, die verantwortungsvoll mit sensiblen persönlichen Daten umgeht. Dies umfasste die Entwicklung eines sicheren lokalen Speichersystems mit Core Data, das die 14-tägige Datenaufbewahrungsrichtlinie durchsetzt. Die nahtlose Integration mehrerer iOS-Frameworks – wie Core Data für die Persistenz, MapKit für die Standortvisualisierung und das Contacts-Framework für die einfache Eingabe – bei gleichzeitiger Aufrechterhaltung einer reibungslosen Benutzererfahrung war eine wesentliche technische Hürde. Eine weitere Herausforderung war die Implementierung sauberer API-Aufrufe an die Google Maps-Dienste zur Standortsuche und Geokodierung, ohne die Leistung der App zu beeinträchtigen.\n\n### Hauptfunktionen\n*   **Begegnungsprotokollierung:** Erstellen Sie detaillierte Einträge für jede Begegnung, einschließlich Datum, Uhrzeit, Dauer und ob eine Maske getragen wurde.\n*   **Kontaktverwaltung:** Fügen Sie Personen zu Begegnungen hinzu, entweder manuell oder durch direkten Import aus der Kontaktliste des Geräts.\n*   **Standortdienste:** Bestimmen Sie den Ort von Begegnungen mithilfe der aktuellen GPS-Koordinaten des Geräts oder durch die Suche nach einer bestimmten Adresse über die Google Maps API.\n*   **Datenschutz:** Alle Daten werden lokal auf dem Gerät gespeichert, und Einträge, die älter als 14 Tage sind, werden beim Start der App automatisch gelöscht.\n*   **Verlaufsansicht:** Überprüfen Sie vergangene Begegnungen, gespeicherte Personen und besuchte Orte einfach über dedizierte Tabs.\n*   **Interaktive Karten:** Zeigen Sie den genauen Standort jeder Begegnung auf einer integrierten Karte im Detailbildschirm der Begegnung an.\n\n### Technischer Einblick\nDie Anwendung wurde nativ für iOS unter Verwendung der MVC-Architektur (Model-View-Controller) entwickelt.\n\n*   **Frontend:** Die Benutzeroberfläche wurde mit Swift und UIKit erstellt, wobei Storyboards und XIB-Dateien für klare, wiederverwendbare UI-Komponenten verwendet wurden. Es wurden benutzerdefinierte `UITableViewCell`s erstellt, um Informationen für Personen, Orte und Begegnungen konsistent darzustellen. Die App integriert das MapKit-Framework von Apple zur Anzeige interaktiver Karten und CoreLocation zum Abrufen der aktuellen geografischen Koordinaten des Nutzers.\n\n*   **Backend (On-Device):** Die Persistenzschicht der Anwendung wird durch Core Data realisiert, das die lokale SQLite-Datenbank verwaltet. Das Datenmodell ist mit drei Hauptentitäten konzipiert: `EncounterCD`, `PersonCD` und `LocationCD`, wobei Beziehungen definiert sind, um Personen und Orte mit bestimmten Begegnungen zu verknüpfen. Alle Datenoperationen, einschließlich der 14-tägigen automatischen Löschlogik, werden innerhalb der App abgewickelt. Das Networking wird über `URLSession` verwaltet, um asynchrone REST-API-Aufrufe an die Geocoding- und Places-APIs von Google zu tätigen und die JSON-Antworten zur Abfrage von Standortdaten zu parsen.\n\n*   **DevOps/Deployment:** Das Projekt wurde vollständig in Xcode entwickelt und verwaltet. Eine Reihe von Unit-Tests wurde mit dem XCTest-Framework geschrieben, um die Zuverlässigkeit der Schlüsselfunktionen wie die Berechnung der Begegnungszeit und die Datenverarbeitungslogik sicherzustellen.\n\n### Persönliche Lernerfolge\nDieses Projekt war eine umfassende Übung im Aufbau einer voll funktionsfähigen iOS-Anwendung von Grund auf. Ich habe bedeutende praktische Erfahrungen mit entscheidenden iOS-Frameworks wie Core Data, MapKit und CoreLocation gesammelt. Die Implementierung der Netzwerkschicht zur Kommunikation mit Drittanbieter-APIs und die Handhabung asynchroner Datenflüsse waren ein wesentlicher Lernpunkt. Darüber hinaus habe ich gelernt, die Privatsphäre der Nutzer zu priorisieren, indem ich ein System mit ausschließlich lokaler Datenspeicherung und einer strengen Datenaufbewahrungsrichtlinie entworfen habe – entscheidende Aspekte in der modernen Anwendungsentwicklung.","projectType":"iOS Application","developedAt":"2021-02-01","liveUrl":null,"repoUrl":"https://github.com/dettinjo/Contact_Log?tab=readme-ov-file","tags":["Swift","UIKit","iOS","Core Data","MapKit","CoreLocation","REST API","XCTest","MVC","Mobile App"],"createdAt":"2025-10-14T18:18:56.696Z","updatedAt":"2025-10-15T19:14:16.378Z","publishedAt":null,"locale":"de"}}
{"type":"api::software-project.software-project","id":159,"data":{"documentId":"cwiul80y8heifqqzfa5dbajk","title":"Corona-Kontakttagebuch iOS App","slug":"corona-kontakttagebuch-i-os-app","description":"Eine native iOS-App zur privaten Protokollierung von Kontakten und Orten zur Kontaktverfolgung, mit automatischer Datenlöschung nach 14 Tagen.","longDescription":"### Projektübersicht\nDas Corona-Kontakttagebuch ist eine iOS-Anwendung, die als Antwort auf die Notwendigkeit einer effektiven Kontaktverfolgung während der Pandemie entwickelt wurde. Sie bietet den Nutzern eine sichere und private Möglichkeit, ihre täglichen Begegnungen mit Personen und Besuche an Orten zu protokollieren. Alle Daten werden lokal auf dem Gerät des Nutzers gespeichert und nach 14 Tagen automatisch gelöscht, um die Privatsphäre zu gewährleisten. Die App wurde als praktisches Werkzeug konzipiert, das den Nutzern hilft, ihre jüngsten Aktivitäten bei Bedarf aus gesundheitlichen Gründen schnell nachzuvollziehen.\n\n### Die Herausforderung\nDie primäre Herausforderung bestand darin, eine robuste, benutzerfreundliche mobile Anwendung zu entwickeln, die verantwortungsvoll mit sensiblen persönlichen Daten umgeht. Dies umfasste die Entwicklung eines sicheren lokalen Speichersystems mit Core Data, das die 14-tägige Datenaufbewahrungsrichtlinie durchsetzt. Die nahtlose Integration mehrerer iOS-Frameworks – wie Core Data für die Persistenz, MapKit für die Standortvisualisierung und das Contacts-Framework für die einfache Eingabe – bei gleichzeitiger Aufrechterhaltung einer reibungslosen Benutzererfahrung war eine wesentliche technische Hürde. Eine weitere Herausforderung war die Implementierung sauberer API-Aufrufe an die Google Maps-Dienste zur Standortsuche und Geokodierung, ohne die Leistung der App zu beeinträchtigen.\n\n### Hauptfunktionen\n*   **Begegnungsprotokollierung:** Erstellen Sie detaillierte Einträge für jede Begegnung, einschließlich Datum, Uhrzeit, Dauer und ob eine Maske getragen wurde.\n*   **Kontaktverwaltung:** Fügen Sie Personen zu Begegnungen hinzu, entweder manuell oder durch direkten Import aus der Kontaktliste des Geräts.\n*   **Standortdienste:** Bestimmen Sie den Ort von Begegnungen mithilfe der aktuellen GPS-Koordinaten des Geräts oder durch die Suche nach einer bestimmten Adresse über die Google Maps API.\n*   **Datenschutz:** Alle Daten werden lokal auf dem Gerät gespeichert, und Einträge, die älter als 14 Tage sind, werden beim Start der App automatisch gelöscht.\n*   **Verlaufsansicht:** Überprüfen Sie vergangene Begegnungen, gespeicherte Personen und besuchte Orte einfach über dedizierte Tabs.\n*   **Interaktive Karten:** Zeigen Sie den genauen Standort jeder Begegnung auf einer integrierten Karte im Detailbildschirm der Begegnung an.\n\n### Technischer Einblick\nDie Anwendung wurde nativ für iOS unter Verwendung der MVC-Architektur (Model-View-Controller) entwickelt.\n\n*   **Frontend:** Die Benutzeroberfläche wurde mit Swift und UIKit erstellt, wobei Storyboards und XIB-Dateien für klare, wiederverwendbare UI-Komponenten verwendet wurden. Es wurden benutzerdefinierte `UITableViewCell`s erstellt, um Informationen für Personen, Orte und Begegnungen konsistent darzustellen. Die App integriert das MapKit-Framework von Apple zur Anzeige interaktiver Karten und CoreLocation zum Abrufen der aktuellen geografischen Koordinaten des Nutzers.\n\n*   **Backend (On-Device):** Die Persistenzschicht der Anwendung wird durch Core Data realisiert, das die lokale SQLite-Datenbank verwaltet. Das Datenmodell ist mit drei Hauptentitäten konzipiert: `EncounterCD`, `PersonCD` und `LocationCD`, wobei Beziehungen definiert sind, um Personen und Orte mit bestimmten Begegnungen zu verknüpfen. Alle Datenoperationen, einschließlich der 14-tägigen automatischen Löschlogik, werden innerhalb der App abgewickelt. Das Networking wird über `URLSession` verwaltet, um asynchrone REST-API-Aufrufe an die Geocoding- und Places-APIs von Google zu tätigen und die JSON-Antworten zur Abfrage von Standortdaten zu parsen.\n\n*   **DevOps/Deployment:** Das Projekt wurde vollständig in Xcode entwickelt und verwaltet. Eine Reihe von Unit-Tests wurde mit dem XCTest-Framework geschrieben, um die Zuverlässigkeit der Schlüsselfunktionen wie die Berechnung der Begegnungszeit und die Datenverarbeitungslogik sicherzustellen.\n\n### Persönliche Lernerfolge\nDieses Projekt war eine umfassende Übung im Aufbau einer voll funktionsfähigen iOS-Anwendung von Grund auf. Ich habe bedeutende praktische Erfahrungen mit entscheidenden iOS-Frameworks wie Core Data, MapKit und CoreLocation gesammelt. Die Implementierung der Netzwerkschicht zur Kommunikation mit Drittanbieter-APIs und die Handhabung asynchroner Datenflüsse waren ein wesentlicher Lernpunkt. Darüber hinaus habe ich gelernt, die Privatsphäre der Nutzer zu priorisieren, indem ich ein System mit ausschließlich lokaler Datenspeicherung und einer strengen Datenaufbewahrungsrichtlinie entworfen habe – entscheidende Aspekte in der modernen Anwendungsentwicklung.","projectType":"iOS Application","developedAt":"2021-02-01","liveUrl":null,"repoUrl":"https://github.com/dettinjo/Contact_Log?tab=readme-ov-file","tags":["Swift","UIKit","iOS","Core Data","MapKit","CoreLocation","REST API","XCTest","MVC","Mobile App"],"createdAt":"2025-10-14T18:18:56.696Z","updatedAt":"2025-10-15T19:14:16.378Z","publishedAt":"2025-10-15T19:14:16.416Z","locale":"de"}}
{"type":"api::software-project.software-project","id":160,"data":{"documentId":"cwiul80y8heifqqzfa5dbajk","title":"Corona Contact Diary iOS App","slug":"corona-contact-diary-i-os-app","description":"A native iOS app for privately logging contacts and locations to aid in contact tracing, with automatic data deletion after 14 days for privacy.","longDescription":"### Project Overview\nThe Corona Contact Diary is an iOS application developed as a response to the need for effective contact tracing during the pandemic. It provides users with a secure and private way to log their daily encounters with people and visits to locations. All data is stored locally on the user's device and is automatically deleted after 14 days to ensure privacy. The app was built to be a practical tool, helping users quickly recall their recent activities if necessary for health-related reasons.\n\n### The Challenge\nThe primary challenge was to build a robust, user-friendly mobile application that handles sensitive personal data responsibly. This involved designing a secure local storage system with Core Data that enforced the 14-day data retention policy. Integrating multiple iOS frameworks—such as Core Data for persistence, MapKit for location visualization, and the Contacts framework for easy entry—while maintaining a smooth user experience was a key technical hurdle. Another challenge was implementing clean API calls to the Google Maps services for location searching and geocoding without compromising app performance.\n\n### Key Features\n*   **Encounter Logging:** Create detailed entries for each encounter, including date, time, duration, and whether a mask was worn.\n*   **Contact Management:** Add people to encounters either manually or by importing them directly from the device's contacts list.\n*   **Location Services:** Pinpoint encounter locations using the device's current GPS coordinates or by searching for a specific address via the Google Maps API.\n*   **Data Privacy:** All data is stored locally on the device, and entries older than 14 days are automatically deleted on app launch.\n*   **History View:** Easily review past encounters, saved persons, and visited locations through dedicated tabs.\n*   **Interactive Maps:** View the precise location of any encounter on an integrated map within the encounter details screen.\n\n### Technical Deep Dive\nThe application is built natively for iOS using the MVC (Model-View-Controller) architecture.\n\n*   **Frontend:** The user interface was constructed using Swift and UIKit, leveraging Storyboards and XIB files for clear, reusable UI components. Custom `UITableViewCell`s were created to display information for persons, locations, and encounters consistently. The app integrates Apple's MapKit framework to display interactive maps and CoreLocation to fetch the user's current geographic coordinates.\n\n*   **Backend (On-Device):** The application's persistence layer is powered by Core Data, which manages the local SQLite database. The data model is designed with three main entities: `EncounterCD`, `PersonCD`, and `LocationCD`, with relationships defined to link people and locations to specific encounters. All data operations, including the 14-day automatic deletion logic, are handled within the app. Networking is managed via `URLSession` to make asynchronous REST API calls to Google's Geocoding and Places APIs, parsing the JSON responses to retrieve location data.\n\n*   **DevOps/Deployment:** The project was developed and managed entirely within Xcode. A suite of unit tests was written using the XCTest framework to ensure the reliability of key functionalities, such as encounter time calculations and data handling logic.\n\n### Personal Learnings\nThis project was a comprehensive exercise in building a full-featured iOS application from the ground up. I gained significant hands-on experience with crucial iOS frameworks like Core Data, MapKit, and CoreLocation. Implementing the networking layer to communicate with third-party APIs and handling asynchronous data flows was a major learning point. Furthermore, I learned to prioritize user privacy by designing a system with local-only data storage and a strict data retention policy, which are critical considerations in modern application development.","projectType":"iOS Application","developedAt":"2021-02-01","liveUrl":null,"repoUrl":"https://github.com/dettinjo/Contact_Log","tags":["Swift","UIKit","iOS","Core Data","MapKit","CoreLocation","REST API","XCTest","MVC","Mobile App"],"createdAt":"2025-10-14T18:17:57.225Z","updatedAt":"2025-10-15T19:14:32.137Z","publishedAt":null,"locale":"en"}}
{"type":"api::software-project.software-project","id":161,"data":{"documentId":"cwiul80y8heifqqzfa5dbajk","title":"Corona Contact Diary iOS App","slug":"corona-contact-diary-i-os-app","description":"A native iOS app for privately logging contacts and locations to aid in contact tracing, with automatic data deletion after 14 days for privacy.","longDescription":"### Project Overview\nThe Corona Contact Diary is an iOS application developed as a response to the need for effective contact tracing during the pandemic. It provides users with a secure and private way to log their daily encounters with people and visits to locations. All data is stored locally on the user's device and is automatically deleted after 14 days to ensure privacy. The app was built to be a practical tool, helping users quickly recall their recent activities if necessary for health-related reasons.\n\n### The Challenge\nThe primary challenge was to build a robust, user-friendly mobile application that handles sensitive personal data responsibly. This involved designing a secure local storage system with Core Data that enforced the 14-day data retention policy. Integrating multiple iOS frameworks—such as Core Data for persistence, MapKit for location visualization, and the Contacts framework for easy entry—while maintaining a smooth user experience was a key technical hurdle. Another challenge was implementing clean API calls to the Google Maps services for location searching and geocoding without compromising app performance.\n\n### Key Features\n*   **Encounter Logging:** Create detailed entries for each encounter, including date, time, duration, and whether a mask was worn.\n*   **Contact Management:** Add people to encounters either manually or by importing them directly from the device's contacts list.\n*   **Location Services:** Pinpoint encounter locations using the device's current GPS coordinates or by searching for a specific address via the Google Maps API.\n*   **Data Privacy:** All data is stored locally on the device, and entries older than 14 days are automatically deleted on app launch.\n*   **History View:** Easily review past encounters, saved persons, and visited locations through dedicated tabs.\n*   **Interactive Maps:** View the precise location of any encounter on an integrated map within the encounter details screen.\n\n### Technical Deep Dive\nThe application is built natively for iOS using the MVC (Model-View-Controller) architecture.\n\n*   **Frontend:** The user interface was constructed using Swift and UIKit, leveraging Storyboards and XIB files for clear, reusable UI components. Custom `UITableViewCell`s were created to display information for persons, locations, and encounters consistently. The app integrates Apple's MapKit framework to display interactive maps and CoreLocation to fetch the user's current geographic coordinates.\n\n*   **Backend (On-Device):** The application's persistence layer is powered by Core Data, which manages the local SQLite database. The data model is designed with three main entities: `EncounterCD`, `PersonCD`, and `LocationCD`, with relationships defined to link people and locations to specific encounters. All data operations, including the 14-day automatic deletion logic, are handled within the app. Networking is managed via `URLSession` to make asynchronous REST API calls to Google's Geocoding and Places APIs, parsing the JSON responses to retrieve location data.\n\n*   **DevOps/Deployment:** The project was developed and managed entirely within Xcode. A suite of unit tests was written using the XCTest framework to ensure the reliability of key functionalities, such as encounter time calculations and data handling logic.\n\n### Personal Learnings\nThis project was a comprehensive exercise in building a full-featured iOS application from the ground up. I gained significant hands-on experience with crucial iOS frameworks like Core Data, MapKit, and CoreLocation. Implementing the networking layer to communicate with third-party APIs and handling asynchronous data flows was a major learning point. Furthermore, I learned to prioritize user privacy by designing a system with local-only data storage and a strict data retention policy, which are critical considerations in modern application development.","projectType":"iOS Application","developedAt":"2021-02-01","liveUrl":null,"repoUrl":"https://github.com/dettinjo/Contact_Log","tags":["Swift","UIKit","iOS","Core Data","MapKit","CoreLocation","REST API","XCTest","MVC","Mobile App"],"createdAt":"2025-10-14T18:17:57.225Z","updatedAt":"2025-10-15T19:14:32.137Z","publishedAt":"2025-10-15T19:14:32.201Z","locale":"en"}}
{"type":"api::software-project.software-project","id":162,"data":{"documentId":"enzu0hohcbiberpf7qrbxu0w","title":"Laravel Blog-Plattform","slug":"laravel-blog-plattform","description":"Eine voll funktionsfähige Blog-Plattform mit Laravel, inklusive sicherer Benutzerauthentifizierung, CRUD-Beitragsverwaltung und Admin-Backend.","longDescription":"### Projektübersicht\nDieses Projekt ist ein voll funktionsfähiger Blog, der mit Laravel erstellt und als Projekt für den Kurs „10015 Server Side Systems“ an der University of the West of Scotland entwickelt wurde. Es dient als praktische Demonstration für die Erstellung einer modernen Full-Stack-Webanwendung von Grund auf, die Schlüsselfunktionen wie Benutzerauthentifizierung, Inhaltsverwaltung und eine dynamische, filterbare Benutzeroberfläche integriert.\n\n### Die Herausforderung\nDie primäre Herausforderung bestand darin, serverseitige Entwicklungsprinzipien anzuwenden, um eine vollständige, datenbankgesteuerte Webanwendung mit einem modernen Framework zu erstellen. Dies umfasste den Entwurf eines logischen Datenbankschemas, die Implementierung einer robusten Model-View-Controller (MVC)-Architektur, die Absicherung der Anwendung durch Benutzerauthentifizierung und -autorisierung sowie die Schaffung einer sauberen, interaktiven Benutzeroberfläche für Leser und Administratoren.\n\n### Hauptmerkmale\n*   **Benutzerauthentifizierung:** Sichere Registrierungs-, Anmelde- und Abmeldefunktionalität für Benutzer.\n*   **Beitragsverwaltung:** Vollständige Create-, Read-, Update- und Delete (CRUD)-Funktionalität für Blog-Beiträge, verwaltet über ein dediziertes Admin-Panel.\n*   **Dynamische Filterung:** Beiträge können einfach nach Kategorie, Autor oder einer textbasierten Suchanfrage gefiltert werden.\n*   **Kommentarsystem:** Authentifizierte Benutzer können durch das Hinterlassen von Kommentaren mit Beiträgen interagieren.\n*   **Admin-Dashboard:** Ein geschützter Bereich, der durch ein Gate gesichert ist, für Administratoren zur Verwaltung aller Blog-Inhalte.\n*   **Komponentenbasierte Benutzeroberfläche:** Das Frontend ist mit wiederverwendbaren Laravel Blade-Komponenten aufgebaut, was eine saubere, modulare und wartbare Struktur gewährleistet.\n\n### Technischer Einblick\n**Backend:**\nDie Anwendung basiert auf dem Laravel 8 Framework und folgt dem MVC-Muster. Die Datenpersistenz wird durch das Eloquent ORM mit Migrationen für die Versionierung des Datenbankschemas verwaltet, das mit einer MySQL-Datenbank verbunden ist. Die Benutzerautorisierung wird über Laravel Gates gehandhabt, was ein einfaches, aber effektives rollenbasiertes Zugriffskontrollsystem für das Admin-Dashboard bietet.\n\n**Frontend:**\nDie Benutzeroberfläche ist mit Tailwind CSS gestaltet, einem Utility-First-CSS-Framework, das ein schnelles und responsives Design ermöglicht. Die JavaScript-Interaktivität für UI-Elemente wie Dropdowns und Flash-Nachrichten wird von Alpine.js gesteuert, das eine leichtgewichtige Lösung ohne den Overhead eines größeren Frameworks bietet. Alle Ansichten werden mit der Blade-Templating-Engine von Laravel gerendert, wobei ein starker Schwerpunkt auf wiederverwendbaren Komponenten liegt.\n\n**DevOps/Deployment:**\nDas Projekt ist für eine standardmäßige PHP-Entwicklungsumgebung konfiguriert. Das Bündeln von Assets wird von Laravel Mix übernommen. Das Setup beinhaltet die Konfiguration zur Verknüpfung des öffentlichen Speicher-Disks (`php artisan storage:link`), um von Benutzern hochgeladene Assets wie Beitrags-Thumbnails korrekt auszuliefern.\n\n### Persönliche Lernerfolge\nDieses Projekt war eine umfassende Übung im Erstellen einer Full-Stack-Anwendung von der Konzeption bis zur Fertigstellung. Es hat mein Verständnis des MVC-Musters, des Datenbankdesigns mit Migrationen und der Bedeutung einer gut strukturierten und wartbaren Codebasis gefestigt. Die Implementierung eines robusten Authentifizierungs- und Autorisierungssystems lieferte wertvolle Einblicke in die Sicherheit von Webanwendungen, während die Erstellung eines komponentengesteuerten Frontends mit Tailwind CSS und Alpine.js eine ausgezeichnete Erfahrung in modernen Frontend-Entwicklungsworkflows war.","projectType":"Full-Stack Web Application","developedAt":"2021-12-06","liveUrl":null,"repoUrl":"https://github.com/dettinjo/laravel-blog","tags":["Laravel","PHP","MySQL","Blade","Tailwind CSS","Alpine.js","MVC","Eloquent ORM"],"createdAt":"2025-10-14T18:39:20.760Z","updatedAt":"2025-10-15T19:16:26.526Z","publishedAt":null,"locale":"de"}}
{"type":"api::software-project.software-project","id":163,"data":{"documentId":"enzu0hohcbiberpf7qrbxu0w","title":"Laravel Blog-Plattform","slug":"laravel-blog-plattform","description":"Eine voll funktionsfähige Blog-Plattform mit Laravel, inklusive sicherer Benutzerauthentifizierung, CRUD-Beitragsverwaltung und Admin-Backend.","longDescription":"### Projektübersicht\nDieses Projekt ist ein voll funktionsfähiger Blog, der mit Laravel erstellt und als Projekt für den Kurs „10015 Server Side Systems“ an der University of the West of Scotland entwickelt wurde. Es dient als praktische Demonstration für die Erstellung einer modernen Full-Stack-Webanwendung von Grund auf, die Schlüsselfunktionen wie Benutzerauthentifizierung, Inhaltsverwaltung und eine dynamische, filterbare Benutzeroberfläche integriert.\n\n### Die Herausforderung\nDie primäre Herausforderung bestand darin, serverseitige Entwicklungsprinzipien anzuwenden, um eine vollständige, datenbankgesteuerte Webanwendung mit einem modernen Framework zu erstellen. Dies umfasste den Entwurf eines logischen Datenbankschemas, die Implementierung einer robusten Model-View-Controller (MVC)-Architektur, die Absicherung der Anwendung durch Benutzerauthentifizierung und -autorisierung sowie die Schaffung einer sauberen, interaktiven Benutzeroberfläche für Leser und Administratoren.\n\n### Hauptmerkmale\n*   **Benutzerauthentifizierung:** Sichere Registrierungs-, Anmelde- und Abmeldefunktionalität für Benutzer.\n*   **Beitragsverwaltung:** Vollständige Create-, Read-, Update- und Delete (CRUD)-Funktionalität für Blog-Beiträge, verwaltet über ein dediziertes Admin-Panel.\n*   **Dynamische Filterung:** Beiträge können einfach nach Kategorie, Autor oder einer textbasierten Suchanfrage gefiltert werden.\n*   **Kommentarsystem:** Authentifizierte Benutzer können durch das Hinterlassen von Kommentaren mit Beiträgen interagieren.\n*   **Admin-Dashboard:** Ein geschützter Bereich, der durch ein Gate gesichert ist, für Administratoren zur Verwaltung aller Blog-Inhalte.\n*   **Komponentenbasierte Benutzeroberfläche:** Das Frontend ist mit wiederverwendbaren Laravel Blade-Komponenten aufgebaut, was eine saubere, modulare und wartbare Struktur gewährleistet.\n\n### Technischer Einblick\n**Backend:**\nDie Anwendung basiert auf dem Laravel 8 Framework und folgt dem MVC-Muster. Die Datenpersistenz wird durch das Eloquent ORM mit Migrationen für die Versionierung des Datenbankschemas verwaltet, das mit einer MySQL-Datenbank verbunden ist. Die Benutzerautorisierung wird über Laravel Gates gehandhabt, was ein einfaches, aber effektives rollenbasiertes Zugriffskontrollsystem für das Admin-Dashboard bietet.\n\n**Frontend:**\nDie Benutzeroberfläche ist mit Tailwind CSS gestaltet, einem Utility-First-CSS-Framework, das ein schnelles und responsives Design ermöglicht. Die JavaScript-Interaktivität für UI-Elemente wie Dropdowns und Flash-Nachrichten wird von Alpine.js gesteuert, das eine leichtgewichtige Lösung ohne den Overhead eines größeren Frameworks bietet. Alle Ansichten werden mit der Blade-Templating-Engine von Laravel gerendert, wobei ein starker Schwerpunkt auf wiederverwendbaren Komponenten liegt.\n\n**DevOps/Deployment:**\nDas Projekt ist für eine standardmäßige PHP-Entwicklungsumgebung konfiguriert. Das Bündeln von Assets wird von Laravel Mix übernommen. Das Setup beinhaltet die Konfiguration zur Verknüpfung des öffentlichen Speicher-Disks (`php artisan storage:link`), um von Benutzern hochgeladene Assets wie Beitrags-Thumbnails korrekt auszuliefern.\n\n### Persönliche Lernerfolge\nDieses Projekt war eine umfassende Übung im Erstellen einer Full-Stack-Anwendung von der Konzeption bis zur Fertigstellung. Es hat mein Verständnis des MVC-Musters, des Datenbankdesigns mit Migrationen und der Bedeutung einer gut strukturierten und wartbaren Codebasis gefestigt. Die Implementierung eines robusten Authentifizierungs- und Autorisierungssystems lieferte wertvolle Einblicke in die Sicherheit von Webanwendungen, während die Erstellung eines komponentengesteuerten Frontends mit Tailwind CSS und Alpine.js eine ausgezeichnete Erfahrung in modernen Frontend-Entwicklungsworkflows war.","projectType":"Full-Stack Web Application","developedAt":"2021-12-06","liveUrl":null,"repoUrl":"https://github.com/dettinjo/laravel-blog","tags":["Laravel","PHP","MySQL","Blade","Tailwind CSS","Alpine.js","MVC","Eloquent ORM"],"createdAt":"2025-10-14T18:39:20.760Z","updatedAt":"2025-10-15T19:16:26.526Z","publishedAt":"2025-10-15T19:16:26.564Z","locale":"de"}}
{"type":"api::software-project.software-project","id":164,"data":{"documentId":"enzu0hohcbiberpf7qrbxu0w","title":"Laravel Blog Platform","slug":"laravel-blog-platform","description":"A full-featured blog platform built with Laravel, including secure user authentication, CRUD post management, and a dedicated admin backend.","longDescription":"### Project Overview\nThis project is a fully functional blog created with Laravel, developed as a project for the course \"10015 Server Side Systems\" at the University of the West of Scotland. It serves as a practical demonstration of building a modern, full-stack web application from the ground up, incorporating key features like user authentication, content management, and a dynamic, filterable frontend.\n\n### The Challenge\nThe primary challenge was to apply server-side development principles to build a complete, database-driven web application using a modern framework. This involved designing a logical database schema, implementing a robust Model-View-Controller (MVC) architecture, securing the application with user authentication and authorization, and creating a clean, interactive user interface for both readers and administrators.\n\n### Key Features\n*   **User Authentication:** Secure registration, login, and logout functionality for users.\n*   **Post Management:** Full Create, Read, Update, and Delete (CRUD) functionality for blog posts, managed through a dedicated admin panel.\n*   **Dynamic Filtering:** Posts can be easily filtered by category, author, or a text-based search query.\n*   **Commenting System:** Authenticated users can engage with posts by leaving comments.\n*   **Admin Dashboard:** A restricted area, protected by a Gate, for administrators to manage all blog content.\n*   **Component-Based UI:** The frontend is built with reusable Laravel Blade components for a clean, modular, and maintainable structure.\n\n### Technical Deep Dive\n**Backend:**\nThe application is built on the Laravel 8 framework, adhering to the MVC pattern. Data persistence is managed through the Eloquent ORM with migrations for database schema versioning, connecting to a MySQL database. User authorization is handled via Laravel Gates, providing a simple yet effective role-based access control system for the admin dashboard.\n\n**Frontend:**\nThe user interface is styled with Tailwind CSS, a utility-first CSS framework that allows for rapid and responsive design. JavaScript interactivity for UI elements like dropdowns and flash messages is powered by Alpine.js, providing a lightweight solution without the overhead of a larger framework. All views are rendered using Laravel's Blade templating engine, with a heavy emphasis on reusable components.\n\n**DevOps/Deployment:**\nThe project is configured for a standard PHP development environment. Asset bundling is handled by Laravel Mix. The setup includes configuration for linking the public storage disk (`php artisan storage:link`) to serve user-uploaded assets like post thumbnails correctly.\n\n### Personal Learnings\nThis project was a comprehensive exercise in building a full-stack application from concept to completion. It solidified my understanding of the MVC pattern, database design with migrations, and the importance of a well-structured and maintainable codebase. Implementing a robust authentication and authorization system provided valuable insights into web application security, while building a component-driven frontend with Tailwind CSS and Alpine.js was an excellent experience in modern frontend development workflows.","projectType":"Full-Stack Web Application","developedAt":"2021-12-06","liveUrl":null,"repoUrl":"https://github.com/dettinjo/laravel-blog","tags":["Laravel","PHP","MySQL","Blade","Tailwind CSS","Alpine.js","MVC","Eloquent ORM"],"createdAt":"2025-10-14T18:29:20.406Z","updatedAt":"2025-10-15T19:16:41.186Z","publishedAt":null,"locale":"en"}}
{"type":"api::software-project.software-project","id":165,"data":{"documentId":"enzu0hohcbiberpf7qrbxu0w","title":"Laravel Blog Platform","slug":"laravel-blog-platform","description":"A full-featured blog platform built with Laravel, including secure user authentication, CRUD post management, and a dedicated admin backend.","longDescription":"### Project Overview\nThis project is a fully functional blog created with Laravel, developed as a project for the course \"10015 Server Side Systems\" at the University of the West of Scotland. It serves as a practical demonstration of building a modern, full-stack web application from the ground up, incorporating key features like user authentication, content management, and a dynamic, filterable frontend.\n\n### The Challenge\nThe primary challenge was to apply server-side development principles to build a complete, database-driven web application using a modern framework. This involved designing a logical database schema, implementing a robust Model-View-Controller (MVC) architecture, securing the application with user authentication and authorization, and creating a clean, interactive user interface for both readers and administrators.\n\n### Key Features\n*   **User Authentication:** Secure registration, login, and logout functionality for users.\n*   **Post Management:** Full Create, Read, Update, and Delete (CRUD) functionality for blog posts, managed through a dedicated admin panel.\n*   **Dynamic Filtering:** Posts can be easily filtered by category, author, or a text-based search query.\n*   **Commenting System:** Authenticated users can engage with posts by leaving comments.\n*   **Admin Dashboard:** A restricted area, protected by a Gate, for administrators to manage all blog content.\n*   **Component-Based UI:** The frontend is built with reusable Laravel Blade components for a clean, modular, and maintainable structure.\n\n### Technical Deep Dive\n**Backend:**\nThe application is built on the Laravel 8 framework, adhering to the MVC pattern. Data persistence is managed through the Eloquent ORM with migrations for database schema versioning, connecting to a MySQL database. User authorization is handled via Laravel Gates, providing a simple yet effective role-based access control system for the admin dashboard.\n\n**Frontend:**\nThe user interface is styled with Tailwind CSS, a utility-first CSS framework that allows for rapid and responsive design. JavaScript interactivity for UI elements like dropdowns and flash messages is powered by Alpine.js, providing a lightweight solution without the overhead of a larger framework. All views are rendered using Laravel's Blade templating engine, with a heavy emphasis on reusable components.\n\n**DevOps/Deployment:**\nThe project is configured for a standard PHP development environment. Asset bundling is handled by Laravel Mix. The setup includes configuration for linking the public storage disk (`php artisan storage:link`) to serve user-uploaded assets like post thumbnails correctly.\n\n### Personal Learnings\nThis project was a comprehensive exercise in building a full-stack application from concept to completion. It solidified my understanding of the MVC pattern, database design with migrations, and the importance of a well-structured and maintainable codebase. Implementing a robust authentication and authorization system provided valuable insights into web application security, while building a component-driven frontend with Tailwind CSS and Alpine.js was an excellent experience in modern frontend development workflows.","projectType":"Full-Stack Web Application","developedAt":"2021-12-06","liveUrl":null,"repoUrl":"https://github.com/dettinjo/laravel-blog","tags":["Laravel","PHP","MySQL","Blade","Tailwind CSS","Alpine.js","MVC","Eloquent ORM"],"createdAt":"2025-10-14T18:29:20.406Z","updatedAt":"2025-10-15T19:16:41.186Z","publishedAt":"2025-10-15T19:16:41.227Z","locale":"en"}}
{"type":"api::software-project.software-project","id":166,"data":{"documentId":"guqjyp7safjdpgqy3ka8bwni","title":"Microservices-basierter RESTful URL Shortener auf Kubernetes","slug":"microservices-basierter-res-tful-url-shortener-auf-kubernetes","description":"Skalierbarer URL-Shortener auf Basis einer Python/Flask-Microservices-Architektur, mit JWT-Authentifizierung und Deployment auf Kubernetes.","longDescription":"### Projektübersicht\nDieses Projekt ist ein vollständig containerisierter, verteilter URL-Verkürzungsdienst, der nach einer Microservices-Architektur konzipiert ist. Es besteht aus zwei unabhängigen, aber miteinander verbundenen Flask-Anwendungen: einem Authentifizierungsdienst, der für die Benutzerverwaltung und die Ausstellung von JWT-Tokens zuständig ist, und einem URL-Shortener-Dienst, der die Kernlogik zum Erstellen, Verwalten und Umleiten von Kurzlinks übernimmt. Das gesamte System ist auf hohe Verfügbarkeit und Skalierbarkeit ausgelegt und wird auf einem Kubernetes-Cluster mit automatisiertem TLS-Zertifikatsmanagement und persistentem Datenspeicher bereitgestellt.\n\n### Die Herausforderung\nDas Hauptziel bestand darin, über eine monolithische Anwendung hinauszugehen und ein robustes, produktionsreifes verteiltes System zu entwickeln. Dies umfasste mehrere zentrale Herausforderungen: die Gestaltung einer klaren Trennung der Zuständigkeiten zwischen Authentifizierung und Kerngeschäftslogik, die Implementierung eines sicheren Kommunikationsprotokolls (JWT) zwischen den Diensten und die Beherrschung der Komplexität des Cloud-nativen Deployments. Das Projekt erforderte einen tiefen Einblick in die Containerisierung mit Docker und die Orchestrierung mit Kubernetes, einschließlich der Konfiguration des Netzwerks mit Ingress, der Verwaltung des persistenten Zustands mit NFS-gestützten Volumes und der Automatisierung der Sicherheit mit cert-manager für SSL.\n\n### Hauptmerkmale\n*   **Entkoppelte Microservices:** Ein unabhängiger Authentifizierungsdienst übernimmt die Benutzerregistrierung, das Login und sichere Passwort-Updates, während sich der URL-Shortener-Dienst auf die Link-Verwaltung konzentriert.\n*   **JWT-basierte Sicherheit:** Der Zugriff der Benutzer auf den URL-Shortener wird über JSON Web Tokens gesichert, die vom Auth-Dienst ausgestellt und vom Shortener-Dienst bei jeder geschützten Anfrage überprüft werden.\n*   **Vollständige CRUD-Funktionalität:** Benutzer können ihre eigenen URL-Mappings erstellen, abrufen, aktualisieren und löschen.\n*   **Persistenter & widerstandsfähiger Speicher:** Beide Dienste verwenden SQLite-Datenbanken, die von Kubernetes Persistent Volumes (über NFS) unterstützt werden, um die Datenintegrität und Persistenz über Pod-Neustarts hinweg zu gewährleisten.\n*   **Benutzerdefinierte & zufällige Kurz-IDs:** Benutzer haben die Flexibilität, entweder einen benutzerdefinierten Alias für ihre Kurzlinks anzugeben oder das System eine eindeutige, zufällige ID generieren zu lassen.\n*   **Nutzungsanalyse:** Das System verfolgt und stellt Zugriffsstatistiken bereit, die zählen, wie oft jeder Kurzlink angeklickt wurde.\n*   **Automatisiertes Kubernetes-Deployment:** Der gesamte Anwendungsstack, einschließlich Diensten, Ingress und persistentem Speicher, ist in Kubernetes-YAML-Manifesten für wiederholbare, automatisierte Deployments definiert.\n*   **Automatisiertes SSL/TLS:** Integriert mit `cert-manager` und Let's Encrypt zur automatischen Bereitstellung und Erneuerung von SSL-Zertifikaten, um sicherzustellen, dass der gesamte Datenverkehr über HTTPS abgewickelt wird.\n\n### Technischer Einblick\n**Backend:**\n*   Das Backend ist als zwei separate Microservices mit **Python** und dem **Flask**-Framework aufgebaut, was eine leichtgewichtige und effiziente Grundlage für die REST-APIs bietet.\n*   **SQLite** wurde aufgrund seiner Einfachheit und dateibasierten Natur gewählt, was es ideal macht, um persistente Speicherkonzepte in Kubernetes mit Persistent Volumes zu demonstrieren.\n*   Der Authentifizierungsdienst implementiert die JWT-Token-Generierung von Grund auf mit dem **HMAC-SHA256**-Algorithmus, was ein grundlegendes Verständnis der Authentifizierungsmechanismen zeigt.\n*   Die Kommunikation zwischen den Diensten erfolgt über direkte REST-API-Aufrufe innerhalb des Kubernetes-Clusters unter Verwendung der integrierten Service Discovery von Kubernetes.\n\n**DevOps/Deployment:**\n*   Beide Dienste sind vollständig mit mehrstufigen **Dockerfiles** für optimierte, leichtgewichtige Images containerisiert. **Docker Compose** wird für eine optimierte lokale Entwicklung bereitgestellt.\n*   Die Anwendung wird mit **Kubernetes** orchestriert, mit detaillierten Manifesten, die Deployments, Services, ConfigMaps und Secrets definieren.\n*   Ein **NGINX Ingress Controller** wird verwendet, um den externen Zugriff zu verwalten und den Datenverkehr basierend auf URL-Pfaden (`/auth` oder `/shortener`) an den entsprechenden Dienst weiterzuleiten.\n*   Sicherer HTTPS-Verkehr wird standardmäßig mit **cert-manager** aktiviert, der den gesamten Lebenszyklus von SSL/TLS-Zertifikaten von Let's Encrypt automatisiert.\n*   Ein umfassendes **Bash-Skript (`setup.sh`)** wurde entwickelt, um die Bereitstellung eines Multi-Node-Kubernetes-Clusters von Grund auf zu automatisieren, was starke Fähigkeiten in der Infrastrukturautomatisierung zeigt.\n\n### Persönliche Lernerfahrungen\nDieses Projekt war ein entscheidender Schritt, um von theoretischem Wissen zur praktischen Anwendung verteilter Systeme und DevOps-Prinzipien überzugehen. Ich sammelte unschätzbare praktische Erfahrungen bei der Konzeption und Implementierung einer Microservices-Architektur, einschließlich der Feinheiten der dienstübergreifenden Kommunikation und Sicherheit mit JWTs. Die größte Lernkurve lag im Bereitstellungsprozess; ich entwickelte ein tiefes Verständnis für Kubernetes-Konzepte wie Pods, Deployments, Services, Persistent Volumes und Ingress. Die Konfiguration von `cert-manager` für automatisches SSL war ein Highlight, da sie den Prozess der Absicherung einer Webanwendung in einer produktionsähnlichen Umgebung entmystifizierte.","projectType":"Backend & DevOps","developedAt":"2024-05-01","liveUrl":null,"repoUrl":"https://github.com/dettinjo/kube-url-shortener","tags":["Python","Flask","REST API","Microservices","JWT","SQLite","Docker","Docker Compose","Kubernetes","DevOps","NGINX","Ingress","cert-manager","SSL/TLS","NFS","Bash Scripting","Unit Testing"],"createdAt":"2025-10-14T19:03:35.911Z","updatedAt":"2025-10-15T19:20:11.751Z","publishedAt":null,"locale":"de"}}
{"type":"api::software-project.software-project","id":167,"data":{"documentId":"guqjyp7safjdpgqy3ka8bwni","title":"Microservices-basierter RESTful URL Shortener auf Kubernetes","slug":"microservices-basierter-res-tful-url-shortener-auf-kubernetes","description":"Skalierbarer URL-Shortener auf Basis einer Python/Flask-Microservices-Architektur, mit JWT-Authentifizierung und Deployment auf Kubernetes.","longDescription":"### Projektübersicht\nDieses Projekt ist ein vollständig containerisierter, verteilter URL-Verkürzungsdienst, der nach einer Microservices-Architektur konzipiert ist. Es besteht aus zwei unabhängigen, aber miteinander verbundenen Flask-Anwendungen: einem Authentifizierungsdienst, der für die Benutzerverwaltung und die Ausstellung von JWT-Tokens zuständig ist, und einem URL-Shortener-Dienst, der die Kernlogik zum Erstellen, Verwalten und Umleiten von Kurzlinks übernimmt. Das gesamte System ist auf hohe Verfügbarkeit und Skalierbarkeit ausgelegt und wird auf einem Kubernetes-Cluster mit automatisiertem TLS-Zertifikatsmanagement und persistentem Datenspeicher bereitgestellt.\n\n### Die Herausforderung\nDas Hauptziel bestand darin, über eine monolithische Anwendung hinauszugehen und ein robustes, produktionsreifes verteiltes System zu entwickeln. Dies umfasste mehrere zentrale Herausforderungen: die Gestaltung einer klaren Trennung der Zuständigkeiten zwischen Authentifizierung und Kerngeschäftslogik, die Implementierung eines sicheren Kommunikationsprotokolls (JWT) zwischen den Diensten und die Beherrschung der Komplexität des Cloud-nativen Deployments. Das Projekt erforderte einen tiefen Einblick in die Containerisierung mit Docker und die Orchestrierung mit Kubernetes, einschließlich der Konfiguration des Netzwerks mit Ingress, der Verwaltung des persistenten Zustands mit NFS-gestützten Volumes und der Automatisierung der Sicherheit mit cert-manager für SSL.\n\n### Hauptmerkmale\n*   **Entkoppelte Microservices:** Ein unabhängiger Authentifizierungsdienst übernimmt die Benutzerregistrierung, das Login und sichere Passwort-Updates, während sich der URL-Shortener-Dienst auf die Link-Verwaltung konzentriert.\n*   **JWT-basierte Sicherheit:** Der Zugriff der Benutzer auf den URL-Shortener wird über JSON Web Tokens gesichert, die vom Auth-Dienst ausgestellt und vom Shortener-Dienst bei jeder geschützten Anfrage überprüft werden.\n*   **Vollständige CRUD-Funktionalität:** Benutzer können ihre eigenen URL-Mappings erstellen, abrufen, aktualisieren und löschen.\n*   **Persistenter & widerstandsfähiger Speicher:** Beide Dienste verwenden SQLite-Datenbanken, die von Kubernetes Persistent Volumes (über NFS) unterstützt werden, um die Datenintegrität und Persistenz über Pod-Neustarts hinweg zu gewährleisten.\n*   **Benutzerdefinierte & zufällige Kurz-IDs:** Benutzer haben die Flexibilität, entweder einen benutzerdefinierten Alias für ihre Kurzlinks anzugeben oder das System eine eindeutige, zufällige ID generieren zu lassen.\n*   **Nutzungsanalyse:** Das System verfolgt und stellt Zugriffsstatistiken bereit, die zählen, wie oft jeder Kurzlink angeklickt wurde.\n*   **Automatisiertes Kubernetes-Deployment:** Der gesamte Anwendungsstack, einschließlich Diensten, Ingress und persistentem Speicher, ist in Kubernetes-YAML-Manifesten für wiederholbare, automatisierte Deployments definiert.\n*   **Automatisiertes SSL/TLS:** Integriert mit `cert-manager` und Let's Encrypt zur automatischen Bereitstellung und Erneuerung von SSL-Zertifikaten, um sicherzustellen, dass der gesamte Datenverkehr über HTTPS abgewickelt wird.\n\n### Technischer Einblick\n**Backend:**\n*   Das Backend ist als zwei separate Microservices mit **Python** und dem **Flask**-Framework aufgebaut, was eine leichtgewichtige und effiziente Grundlage für die REST-APIs bietet.\n*   **SQLite** wurde aufgrund seiner Einfachheit und dateibasierten Natur gewählt, was es ideal macht, um persistente Speicherkonzepte in Kubernetes mit Persistent Volumes zu demonstrieren.\n*   Der Authentifizierungsdienst implementiert die JWT-Token-Generierung von Grund auf mit dem **HMAC-SHA256**-Algorithmus, was ein grundlegendes Verständnis der Authentifizierungsmechanismen zeigt.\n*   Die Kommunikation zwischen den Diensten erfolgt über direkte REST-API-Aufrufe innerhalb des Kubernetes-Clusters unter Verwendung der integrierten Service Discovery von Kubernetes.\n\n**DevOps/Deployment:**\n*   Beide Dienste sind vollständig mit mehrstufigen **Dockerfiles** für optimierte, leichtgewichtige Images containerisiert. **Docker Compose** wird für eine optimierte lokale Entwicklung bereitgestellt.\n*   Die Anwendung wird mit **Kubernetes** orchestriert, mit detaillierten Manifesten, die Deployments, Services, ConfigMaps und Secrets definieren.\n*   Ein **NGINX Ingress Controller** wird verwendet, um den externen Zugriff zu verwalten und den Datenverkehr basierend auf URL-Pfaden (`/auth` oder `/shortener`) an den entsprechenden Dienst weiterzuleiten.\n*   Sicherer HTTPS-Verkehr wird standardmäßig mit **cert-manager** aktiviert, der den gesamten Lebenszyklus von SSL/TLS-Zertifikaten von Let's Encrypt automatisiert.\n*   Ein umfassendes **Bash-Skript (`setup.sh`)** wurde entwickelt, um die Bereitstellung eines Multi-Node-Kubernetes-Clusters von Grund auf zu automatisieren, was starke Fähigkeiten in der Infrastrukturautomatisierung zeigt.\n\n### Persönliche Lernerfahrungen\nDieses Projekt war ein entscheidender Schritt, um von theoretischem Wissen zur praktischen Anwendung verteilter Systeme und DevOps-Prinzipien überzugehen. Ich sammelte unschätzbare praktische Erfahrungen bei der Konzeption und Implementierung einer Microservices-Architektur, einschließlich der Feinheiten der dienstübergreifenden Kommunikation und Sicherheit mit JWTs. Die größte Lernkurve lag im Bereitstellungsprozess; ich entwickelte ein tiefes Verständnis für Kubernetes-Konzepte wie Pods, Deployments, Services, Persistent Volumes und Ingress. Die Konfiguration von `cert-manager` für automatisches SSL war ein Highlight, da sie den Prozess der Absicherung einer Webanwendung in einer produktionsähnlichen Umgebung entmystifizierte.","projectType":"Backend & DevOps","developedAt":"2024-05-01","liveUrl":null,"repoUrl":"https://github.com/dettinjo/kube-url-shortener","tags":["Python","Flask","REST API","Microservices","JWT","SQLite","Docker","Docker Compose","Kubernetes","DevOps","NGINX","Ingress","cert-manager","SSL/TLS","NFS","Bash Scripting","Unit Testing"],"createdAt":"2025-10-14T19:03:35.911Z","updatedAt":"2025-10-15T19:20:11.751Z","publishedAt":"2025-10-15T19:20:11.789Z","locale":"de"}}
{"type":"api::software-project.software-project","id":168,"data":{"documentId":"guqjyp7safjdpgqy3ka8bwni","title":"Microservices-Based RESTful URL Shortener on Kubernetes","slug":"microservices-based-res-tful-url-shortener-on-kubernetes","description":"A scalable URL shortener using a Python/Flask microservices architecture, featuring JWT authentication and deployed on Kubernetes.","longDescription":"### Project Overview\nThis project is a fully containerized, distributed URL shortening service designed according to a microservices architecture. It consists of two independent yet interconnected Flask applications: an Authentication Service responsible for user management and JWT token issuance, and a URL Shortener Service that handles the core logic of creating, managing, and redirecting short links. The entire system is designed for high availability and scalability, deployed on a Kubernetes cluster with automated TLS certificate management and persistent data storage.\n\n### The Challenge\nThe main goal was to move beyond a monolithic application and build a robust, production-ready distributed system. This involved several key challenges: designing a clean separation of concerns between authentication and core business logic, implementing a secure communication protocol (JWT) between services, and mastering the complexities of cloud-native deployment. The project required a deep dive into containerization with Docker and orchestration with Kubernetes, including configuring networking with Ingress, managing persistent state with NFS-backed volumes, and automating security with cert-manager for SSL.\n\n### Key Features\n*   **Decoupled Microservices:** An independent Authentication Service handles user registration, login, and secure password updates, while the URL Shortener Service focuses on link management.\n*   **JWT-Based Security:** User access to the URL Shortener is secured via JSON Web Tokens, which are issued by the Auth service and verified by the Shortener service on each protected request.\n*   **Full CRUD Functionality:** Users can create, retrieve, update, and delete their own URL mappings.\n*   **Persistent & Resilient Storage:** Both services use SQLite databases backed by Kubernetes Persistent Volumes (via NFS) to ensure data integrity and persistence across pod restarts.\n*   **Custom & Random Short IDs:** Users have the flexibility to either specify a custom alias for their short links or let the system generate a unique, random ID.\n*   **Usage Analytics:** The system tracks and provides access statistics, counting the number of times each short link is clicked.\n*   **Automated Kubernetes Deployment:** The entire application stack, including services, ingress, and persistent storage, is defined in Kubernetes YAML manifests for repeatable, automated deployments.\n*   **Automated SSL/TLS:** Integrated with `cert-manager` and Let's Encrypt to automatically provision and renew SSL certificates, ensuring all traffic is served over HTTPS.\n\n### Technical Deep Dive\n**Backend:**\n*   The backend is built as two distinct microservices using **Python** and the **Flask** framework, providing a lightweight and efficient foundation for the REST APIs.\n*   **SQLite** was chosen for its simplicity and file-based nature, making it ideal for demonstrating persistent storage concepts in Kubernetes using Persistent Volumes.\n*   The Authentication service implements JWT token generation from scratch using the **HMAC-SHA256** algorithm, demonstrating a core understanding of authentication mechanics.\n*   Inter-service communication is handled via direct REST API calls within the Kubernetes cluster, utilizing Kubernetes' built-in service discovery.\n\n**DevOps/Deployment:**\n*   Both services are fully containerized using multi-stage **Dockerfiles** for optimized, lightweight images. **Docker Compose** is provided for streamlined local development.\n*   The application is orchestrated with **Kubernetes**, with detailed manifests defining Deployments, Services, ConfigMaps, and Secrets.\n*   An **NGINX Ingress Controller** is used to manage external access, routing traffic to the appropriate service based on URL paths (`/auth` or `/shortener`).\n*   Secure HTTPS traffic is enabled out-of-the-box using **cert-manager**, which automates the entire lifecycle of SSL/TLS certificates from Let's Encrypt.\n*   A comprehensive **Bash script (`setup.sh`)** was developed to automate the provisioning of a multi-node Kubernetes cluster from scratch, showcasing strong infrastructure automation skills.\n\n### Personal Learnings\nThis project was a significant step in transitioning from theoretical knowledge to practical application of distributed systems and DevOps principles. I gained invaluable hands-on experience in designing and implementing a microservices architecture, including the nuances of inter-service communication and security with JWTs. The biggest learning curve was in the deployment process; I developed a deep understanding of Kubernetes concepts such as Pods, Deployments, Services, Persistent Volumes, and Ingress. Configuring `cert-manager` for automated SSL was a highlight, as it demystified the process of securing a web application in a production-like environment.","projectType":"Backend & DevOps","developedAt":"2023-12-15","liveUrl":null,"repoUrl":"https://github.com/dettinjo/kube-url-shortener","tags":["Python","Flask","REST API","Microservices","JWT","SQLite","Docker","Docker Compose","Kubernetes","DevOps","NGINX","Ingress","cert-manager","SSL/TLS","NFS","Bash Scripting","Unit Testing"],"createdAt":"2025-10-14T18:58:46.399Z","updatedAt":"2025-10-15T19:23:20.750Z","publishedAt":null,"locale":"en"}}
{"type":"api::software-project.software-project","id":169,"data":{"documentId":"guqjyp7safjdpgqy3ka8bwni","title":"Microservices-Based RESTful URL Shortener on Kubernetes","slug":"microservices-based-res-tful-url-shortener-on-kubernetes","description":"A scalable URL shortener using a Python/Flask microservices architecture, featuring JWT authentication and deployed on Kubernetes.","longDescription":"### Project Overview\nThis project is a fully containerized, distributed URL shortening service designed according to a microservices architecture. It consists of two independent yet interconnected Flask applications: an Authentication Service responsible for user management and JWT token issuance, and a URL Shortener Service that handles the core logic of creating, managing, and redirecting short links. The entire system is designed for high availability and scalability, deployed on a Kubernetes cluster with automated TLS certificate management and persistent data storage.\n\n### The Challenge\nThe main goal was to move beyond a monolithic application and build a robust, production-ready distributed system. This involved several key challenges: designing a clean separation of concerns between authentication and core business logic, implementing a secure communication protocol (JWT) between services, and mastering the complexities of cloud-native deployment. The project required a deep dive into containerization with Docker and orchestration with Kubernetes, including configuring networking with Ingress, managing persistent state with NFS-backed volumes, and automating security with cert-manager for SSL.\n\n### Key Features\n*   **Decoupled Microservices:** An independent Authentication Service handles user registration, login, and secure password updates, while the URL Shortener Service focuses on link management.\n*   **JWT-Based Security:** User access to the URL Shortener is secured via JSON Web Tokens, which are issued by the Auth service and verified by the Shortener service on each protected request.\n*   **Full CRUD Functionality:** Users can create, retrieve, update, and delete their own URL mappings.\n*   **Persistent & Resilient Storage:** Both services use SQLite databases backed by Kubernetes Persistent Volumes (via NFS) to ensure data integrity and persistence across pod restarts.\n*   **Custom & Random Short IDs:** Users have the flexibility to either specify a custom alias for their short links or let the system generate a unique, random ID.\n*   **Usage Analytics:** The system tracks and provides access statistics, counting the number of times each short link is clicked.\n*   **Automated Kubernetes Deployment:** The entire application stack, including services, ingress, and persistent storage, is defined in Kubernetes YAML manifests for repeatable, automated deployments.\n*   **Automated SSL/TLS:** Integrated with `cert-manager` and Let's Encrypt to automatically provision and renew SSL certificates, ensuring all traffic is served over HTTPS.\n\n### Technical Deep Dive\n**Backend:**\n*   The backend is built as two distinct microservices using **Python** and the **Flask** framework, providing a lightweight and efficient foundation for the REST APIs.\n*   **SQLite** was chosen for its simplicity and file-based nature, making it ideal for demonstrating persistent storage concepts in Kubernetes using Persistent Volumes.\n*   The Authentication service implements JWT token generation from scratch using the **HMAC-SHA256** algorithm, demonstrating a core understanding of authentication mechanics.\n*   Inter-service communication is handled via direct REST API calls within the Kubernetes cluster, utilizing Kubernetes' built-in service discovery.\n\n**DevOps/Deployment:**\n*   Both services are fully containerized using multi-stage **Dockerfiles** for optimized, lightweight images. **Docker Compose** is provided for streamlined local development.\n*   The application is orchestrated with **Kubernetes**, with detailed manifests defining Deployments, Services, ConfigMaps, and Secrets.\n*   An **NGINX Ingress Controller** is used to manage external access, routing traffic to the appropriate service based on URL paths (`/auth` or `/shortener`).\n*   Secure HTTPS traffic is enabled out-of-the-box using **cert-manager**, which automates the entire lifecycle of SSL/TLS certificates from Let's Encrypt.\n*   A comprehensive **Bash script (`setup.sh`)** was developed to automate the provisioning of a multi-node Kubernetes cluster from scratch, showcasing strong infrastructure automation skills.\n\n### Personal Learnings\nThis project was a significant step in transitioning from theoretical knowledge to practical application of distributed systems and DevOps principles. I gained invaluable hands-on experience in designing and implementing a microservices architecture, including the nuances of inter-service communication and security with JWTs. The biggest learning curve was in the deployment process; I developed a deep understanding of Kubernetes concepts such as Pods, Deployments, Services, Persistent Volumes, and Ingress. Configuring `cert-manager` for automated SSL was a highlight, as it demystified the process of securing a web application in a production-like environment.","projectType":"Backend & DevOps","developedAt":"2023-12-15","liveUrl":null,"repoUrl":"https://github.com/dettinjo/kube-url-shortener","tags":["Python","Flask","REST API","Microservices","JWT","SQLite","Docker","Docker Compose","Kubernetes","DevOps","NGINX","Ingress","cert-manager","SSL/TLS","NFS","Bash Scripting","Unit Testing"],"createdAt":"2025-10-14T18:58:46.399Z","updatedAt":"2025-10-15T19:23:20.750Z","publishedAt":"2025-10-15T19:23:20.789Z","locale":"en"}}
{"type":"api::software-project.software-project","id":170,"data":{"documentId":"jvdypture9g13gj84pdmxycx","title":"MyFavLocation - Android-App zur Ortserkundung","slug":"my-fav-location-android-app-zur-ortserkundung","description":"Eine Android-App zum Entdecken, Speichern und Erstellen von Lieblingsorten. Basiert auf der Google Places API und einer sauberen MVVM-Architektur mit Kotlin.","longDescription":"### Projektübersicht\nMyFavLocation ist eine mobile Anwendung für Android, die entwickelt wurde, um Benutzern bei der Erkundung ihrer Umgebung zu helfen. Sie ruft interessante Orte in der Nähe über die Google Places API ab und zeigt sie in einer benutzerfreundlichen Liste an. Benutzer können diese Orte als Favoriten speichern, detaillierte Informationen anzeigen oder ihre eigenen benutzerdefinierten Orte mit Namen, Beschreibung, Foto und Bewertung erstellen, die dann lokal auf dem Gerät gespeichert werden.\n\n### Die Herausforderung\nDie primäre Herausforderung bestand darin, eine skalierbare und wartbare Android-Anwendung von Grund auf zu entwerfen. Dies umfasste die Implementierung des MVVM (Model-View-ViewModel)-Architekturmusters zur Trennung von UI- und Geschäftslogik, die Verwaltung asynchroner Operationen für Netzwerkanfragen und Datenbankzugriffe sowie den Umgang mit dem Laufzeit-Berechtigungssystem von Android für Funktionen wie GPS und Kamerazugriff. Ein weiteres wichtiges Ziel war es, eine reibungslose Benutzererfahrung durch das Caching von Daten zu gewährleisten, um API-Aufrufe und Datenverbrauch zu minimieren.\n\n### Hauptmerkmale\n*   **Orte in der Nähe entdecken:** Ruft automatisch eine Liste von Orten in der Nähe innerhalb eines 200-Meter-Radius ab und zeigt sie an.\n*   **Lieblingsorte:** Speichern Sie jeden Ort aus der Google Places API oder einen selbst erstellten Ort in einer lokalen Favoritenliste.\n*   **Eigene Orte erstellen:** Erstellen Sie neue Orte, indem Sie ein Foto aufnehmen, einen Namen, eine Beschreibung, eine Kategorie und eine Bewertung angeben und diese mit den aktuellen GPS-Koordinaten speichern.\n*   **Ortssuche:** Suchen Sie nach bestimmten Orten mithilfe von Textabfragen, die sowohl die Google Places API als auch die lokale Datenbank durchsuchen.\n*   **Detailansichten:** Zeigen Sie detaillierte Informationen für jeden Ort an, einschließlich eines statischen Kartenbildes, einer Bewertung und benutzerdefinierter Details.\n*   **Datenpersistenz:** Vom Benutzer erstellte und favorisierte Orte werden lokal mithilfe der Room Persistence Library gespeichert.\n\n### Technischer Einblick\n*   **Architektur**: Die Anwendung basiert auf dem **MVVM (Model-View-ViewModel)**-Muster, das eine saubere Trennung der Zuständigkeiten gewährleistet. Dies wird durch `ViewModel`- und `LiveData`-Komponenten aus Android Jetpack unterstützt, um eine reaktive Benutzeroberfläche zu schaffen, die unabhängig vom Lebenszyklus der Anwendung ist.\n*   **Frontend**: Die Benutzeroberfläche wurde mit nativen Android-Komponenten (Activities und Fragments) und Kotlin erstellt. Die **Android Navigation Component** wird zur Verwaltung der Navigation zwischen den Bildschirmen verwendet. **Glide** wird für das effiziente Laden und Zwischenspeichern von Bildern von URLs und lokalen Dateipfaden genutzt.\n*   **Backend**: Die Backend-Logik ist in Repositories gekapselt. **Retrofit** übernimmt die asynchronen API-Aufrufe an die Google Places API. Die lokale Datenspeicherung wird von der **Room Persistence Library** verwaltet, die eine Abstraktionsschicht über SQLite bietet. GPS-Koordinaten werden über die nativen Standortdienste von Android abgerufen.\n*   **Abhängigkeitsmanagement**: Eine benutzerdefinierte `InjectorUtils`-Klasse wird verwendet, um die Abhängigkeiten zwischen ViewModels und Repositories zu verwalten, was die Erstellung von Objekten zentralisiert und die Architektur leichter testbar und modifizierbar macht.\n\n### Persönliche Lernerfolge\nDieses Projekt war ein tiefer Einblick in moderne Android-Entwicklungspraktiken. Ich habe bedeutende Erfahrungen bei der Implementierung der MVVM-Architektur gesammelt, was für die Erstellung einer skalierbaren und testbaren App entscheidend war. Ich lernte, asynchrone Operationen effektiv mit Callbacks für API- und Datenbankinteraktionen zu handhaben, obwohl das Projekt auch die Komplexität aufzeigte, die zu modernen Lösungen wie Kotlin Coroutines führt. Die Verwaltung des Lebenszyklus von Android-Komponenten, der Umgang mit Laufzeit-Berechtigungen und die Implementierung einer robusten Datenschicht mit Room und Retrofit waren wichtige Erkenntnisse, die mein Verständnis für die Erstellung funktionsreicher mobiler Anwendungen gefestigt haben.","projectType":"Android Projekt","developedAt":"2020-07-14","liveUrl":null,"repoUrl":"https://github.com/dettinjo/myfavlocation","tags":["Kotlin","Android","MVVM","Room DB","Retrofit","Google Places API","Android Jetpack","Glide","SQLite","REST API"],"createdAt":"2025-10-14T16:06:49.262Z","updatedAt":"2025-10-15T19:20:55.216Z","publishedAt":null,"locale":"de"}}
{"type":"api::software-project.software-project","id":171,"data":{"documentId":"jvdypture9g13gj84pdmxycx","title":"MyFavLocation - Android-App zur Ortserkundung","slug":"my-fav-location-android-app-zur-ortserkundung","description":"Eine Android-App zum Entdecken, Speichern und Erstellen von Lieblingsorten. Basiert auf der Google Places API und einer sauberen MVVM-Architektur mit Kotlin.","longDescription":"### Projektübersicht\nMyFavLocation ist eine mobile Anwendung für Android, die entwickelt wurde, um Benutzern bei der Erkundung ihrer Umgebung zu helfen. Sie ruft interessante Orte in der Nähe über die Google Places API ab und zeigt sie in einer benutzerfreundlichen Liste an. Benutzer können diese Orte als Favoriten speichern, detaillierte Informationen anzeigen oder ihre eigenen benutzerdefinierten Orte mit Namen, Beschreibung, Foto und Bewertung erstellen, die dann lokal auf dem Gerät gespeichert werden.\n\n### Die Herausforderung\nDie primäre Herausforderung bestand darin, eine skalierbare und wartbare Android-Anwendung von Grund auf zu entwerfen. Dies umfasste die Implementierung des MVVM (Model-View-ViewModel)-Architekturmusters zur Trennung von UI- und Geschäftslogik, die Verwaltung asynchroner Operationen für Netzwerkanfragen und Datenbankzugriffe sowie den Umgang mit dem Laufzeit-Berechtigungssystem von Android für Funktionen wie GPS und Kamerazugriff. Ein weiteres wichtiges Ziel war es, eine reibungslose Benutzererfahrung durch das Caching von Daten zu gewährleisten, um API-Aufrufe und Datenverbrauch zu minimieren.\n\n### Hauptmerkmale\n*   **Orte in der Nähe entdecken:** Ruft automatisch eine Liste von Orten in der Nähe innerhalb eines 200-Meter-Radius ab und zeigt sie an.\n*   **Lieblingsorte:** Speichern Sie jeden Ort aus der Google Places API oder einen selbst erstellten Ort in einer lokalen Favoritenliste.\n*   **Eigene Orte erstellen:** Erstellen Sie neue Orte, indem Sie ein Foto aufnehmen, einen Namen, eine Beschreibung, eine Kategorie und eine Bewertung angeben und diese mit den aktuellen GPS-Koordinaten speichern.\n*   **Ortssuche:** Suchen Sie nach bestimmten Orten mithilfe von Textabfragen, die sowohl die Google Places API als auch die lokale Datenbank durchsuchen.\n*   **Detailansichten:** Zeigen Sie detaillierte Informationen für jeden Ort an, einschließlich eines statischen Kartenbildes, einer Bewertung und benutzerdefinierter Details.\n*   **Datenpersistenz:** Vom Benutzer erstellte und favorisierte Orte werden lokal mithilfe der Room Persistence Library gespeichert.\n\n### Technischer Einblick\n*   **Architektur**: Die Anwendung basiert auf dem **MVVM (Model-View-ViewModel)**-Muster, das eine saubere Trennung der Zuständigkeiten gewährleistet. Dies wird durch `ViewModel`- und `LiveData`-Komponenten aus Android Jetpack unterstützt, um eine reaktive Benutzeroberfläche zu schaffen, die unabhängig vom Lebenszyklus der Anwendung ist.\n*   **Frontend**: Die Benutzeroberfläche wurde mit nativen Android-Komponenten (Activities und Fragments) und Kotlin erstellt. Die **Android Navigation Component** wird zur Verwaltung der Navigation zwischen den Bildschirmen verwendet. **Glide** wird für das effiziente Laden und Zwischenspeichern von Bildern von URLs und lokalen Dateipfaden genutzt.\n*   **Backend**: Die Backend-Logik ist in Repositories gekapselt. **Retrofit** übernimmt die asynchronen API-Aufrufe an die Google Places API. Die lokale Datenspeicherung wird von der **Room Persistence Library** verwaltet, die eine Abstraktionsschicht über SQLite bietet. GPS-Koordinaten werden über die nativen Standortdienste von Android abgerufen.\n*   **Abhängigkeitsmanagement**: Eine benutzerdefinierte `InjectorUtils`-Klasse wird verwendet, um die Abhängigkeiten zwischen ViewModels und Repositories zu verwalten, was die Erstellung von Objekten zentralisiert und die Architektur leichter testbar und modifizierbar macht.\n\n### Persönliche Lernerfolge\nDieses Projekt war ein tiefer Einblick in moderne Android-Entwicklungspraktiken. Ich habe bedeutende Erfahrungen bei der Implementierung der MVVM-Architektur gesammelt, was für die Erstellung einer skalierbaren und testbaren App entscheidend war. Ich lernte, asynchrone Operationen effektiv mit Callbacks für API- und Datenbankinteraktionen zu handhaben, obwohl das Projekt auch die Komplexität aufzeigte, die zu modernen Lösungen wie Kotlin Coroutines führt. Die Verwaltung des Lebenszyklus von Android-Komponenten, der Umgang mit Laufzeit-Berechtigungen und die Implementierung einer robusten Datenschicht mit Room und Retrofit waren wichtige Erkenntnisse, die mein Verständnis für die Erstellung funktionsreicher mobiler Anwendungen gefestigt haben.","projectType":"Android Projekt","developedAt":"2020-07-14","liveUrl":null,"repoUrl":"https://github.com/dettinjo/myfavlocation","tags":["Kotlin","Android","MVVM","Room DB","Retrofit","Google Places API","Android Jetpack","Glide","SQLite","REST API"],"createdAt":"2025-10-14T16:06:49.262Z","updatedAt":"2025-10-15T19:20:55.216Z","publishedAt":"2025-10-15T19:20:55.291Z","locale":"de"}}
{"type":"api::software-project.software-project","id":172,"data":{"documentId":"jvdypture9g13gj84pdmxycx","title":"MyFavLocation - Android Location Discovery App","slug":"my-fav-location-android-location-discovery-app","description":"An Android app to discover, save, and create favorite locations. Powered by the Google Places API and built on a clean MVVM architecture with Kotlin.","longDescription":"### Project Overview\nMyFavLocation is a mobile application for Android designed to help users explore their surroundings. It fetches nearby points of interest from the Google Places API and displays them in a user-friendly list. Users can save these locations as favorites, view detailed information, or create their own custom locations complete with a name, description, photo, and rating, which are then stored locally on the device.\n\n### The Challenge\nThe primary challenge was to design a scalable and maintainable Android application from the ground up. This involved implementing the MVVM (Model-View-ViewModel) architectural pattern to separate UI logic from business logic, managing asynchronous operations for network requests and database access, and handling Android's runtime permission system for features like GPS and camera access. Another key goal was to ensure a smooth user experience by caching data to minimize API calls and data consumption.\n\n### Key Features\n*   **Nearby Location Discovery:** Automatically fetches and displays a list of nearby locations within a 200-meter radius.\n*   **Favorite Locations:** Save any location from the Google Places API or a custom-created one to a local favorites list.\n*   **Custom Location Creation:** Create new locations by taking a picture, providing a name, description, category, and rating, and saving it with the current GPS coordinates.\n*   **Location Search:** Search for specific locations using text queries, which queries both the Google Places API and the local database.\n*   **Detailed Views:** View detailed information for each location, including a static map image, rating, and user-provided details.\n*   **Data Persistence:** User-created and favorite locations are stored locally using the Room persistence library.\n\n### Technical Deep Dive\n*   **Architecture**: The application is built using the **MVVM (Model-View-ViewModel)** pattern, ensuring a clean separation of concerns. This is supported by `ViewModel` and `LiveData` components from Android Jetpack to create a reactive UI that is independent of the application's lifecycle.\n*   **Frontend**: The UI is built with native Android components (Activities and Fragments) and Kotlin. The **Android Navigation Component** is used to manage navigation between screens. **Glide** is leveraged for efficient loading and caching of images from URLs and local file paths.\n*   **Backend**: The backend logic is encapsulated within Repositories. **Retrofit** handles asynchronous API calls to the Google Places API. Local data storage is managed by the **Room Persistence Library**, providing an abstraction layer over SQLite. GPS coordinates are fetched using Android's native location services.\n*   **Dependency Management**: A custom `InjectorUtils` class is used to manage dependencies between ViewModels and Repositories, centralizing the creation of objects and making the architecture easier to test and modify.\n\n### Personal Learnings\nThis project was a deep dive into modern Android development practices. I gained significant experience in implementing the MVVM architecture, which was crucial for building a scalable and testable app. I learned to handle asynchronous operations effectively using callbacks for API and database interactions, although the project also highlighted the complexities that lead to modern solutions like Kotlin Coroutines. Managing the Android component lifecycle, handling runtime permissions, and implementing a robust data layer with Room and Retrofit were key takeaways that solidified my understanding of building feature-rich mobile applications.\n","projectType":"Android Project","developedAt":"2020-07-14","liveUrl":null,"repoUrl":"https://github.com/dettinjo/myfavlocation","tags":["Kotlin","Android","MVVM","Room DB","Retrofit","Google Places API","Android Jetpack","Glide","SQLite","REST API"],"createdAt":"2025-10-14T16:04:45.774Z","updatedAt":"2025-10-15T19:21:11.212Z","publishedAt":null,"locale":"en"}}
{"type":"api::software-project.software-project","id":173,"data":{"documentId":"jvdypture9g13gj84pdmxycx","title":"MyFavLocation - Android Location Discovery App","slug":"my-fav-location-android-location-discovery-app","description":"An Android app to discover, save, and create favorite locations. Powered by the Google Places API and built on a clean MVVM architecture with Kotlin.","longDescription":"### Project Overview\nMyFavLocation is a mobile application for Android designed to help users explore their surroundings. It fetches nearby points of interest from the Google Places API and displays them in a user-friendly list. Users can save these locations as favorites, view detailed information, or create their own custom locations complete with a name, description, photo, and rating, which are then stored locally on the device.\n\n### The Challenge\nThe primary challenge was to design a scalable and maintainable Android application from the ground up. This involved implementing the MVVM (Model-View-ViewModel) architectural pattern to separate UI logic from business logic, managing asynchronous operations for network requests and database access, and handling Android's runtime permission system for features like GPS and camera access. Another key goal was to ensure a smooth user experience by caching data to minimize API calls and data consumption.\n\n### Key Features\n*   **Nearby Location Discovery:** Automatically fetches and displays a list of nearby locations within a 200-meter radius.\n*   **Favorite Locations:** Save any location from the Google Places API or a custom-created one to a local favorites list.\n*   **Custom Location Creation:** Create new locations by taking a picture, providing a name, description, category, and rating, and saving it with the current GPS coordinates.\n*   **Location Search:** Search for specific locations using text queries, which queries both the Google Places API and the local database.\n*   **Detailed Views:** View detailed information for each location, including a static map image, rating, and user-provided details.\n*   **Data Persistence:** User-created and favorite locations are stored locally using the Room persistence library.\n\n### Technical Deep Dive\n*   **Architecture**: The application is built using the **MVVM (Model-View-ViewModel)** pattern, ensuring a clean separation of concerns. This is supported by `ViewModel` and `LiveData` components from Android Jetpack to create a reactive UI that is independent of the application's lifecycle.\n*   **Frontend**: The UI is built with native Android components (Activities and Fragments) and Kotlin. The **Android Navigation Component** is used to manage navigation between screens. **Glide** is leveraged for efficient loading and caching of images from URLs and local file paths.\n*   **Backend**: The backend logic is encapsulated within Repositories. **Retrofit** handles asynchronous API calls to the Google Places API. Local data storage is managed by the **Room Persistence Library**, providing an abstraction layer over SQLite. GPS coordinates are fetched using Android's native location services.\n*   **Dependency Management**: A custom `InjectorUtils` class is used to manage dependencies between ViewModels and Repositories, centralizing the creation of objects and making the architecture easier to test and modify.\n\n### Personal Learnings\nThis project was a deep dive into modern Android development practices. I gained significant experience in implementing the MVVM architecture, which was crucial for building a scalable and testable app. I learned to handle asynchronous operations effectively using callbacks for API and database interactions, although the project also highlighted the complexities that lead to modern solutions like Kotlin Coroutines. Managing the Android component lifecycle, handling runtime permissions, and implementing a robust data layer with Room and Retrofit were key takeaways that solidified my understanding of building feature-rich mobile applications.\n","projectType":"Android Project","developedAt":"2020-07-14","liveUrl":null,"repoUrl":"https://github.com/dettinjo/myfavlocation","tags":["Kotlin","Android","MVVM","Room DB","Retrofit","Google Places API","Android Jetpack","Glide","SQLite","REST API"],"createdAt":"2025-10-14T16:04:45.774Z","updatedAt":"2025-10-15T19:21:11.212Z","publishedAt":"2025-10-15T19:21:11.247Z","locale":"en"}}
{"type":"api::software-project.software-project","id":174,"data":{"documentId":"kev0svypi5eyle0zr5d7soeo","title":"Wettbewerbs-Webanwendung","slug":"wettbewerbs-webanwendung","description":"Full-Stack App für Programmierwettbewerbe mit rollenbasiertem Zugriff für User, Juroren & Admins. Ein Projekt der University of the West of Scotland.","longDescription":"### Projektübersicht\n\nDie Wettbewerbs-Webanwendung ist eine umfassende Plattform, die von Grund auf für die Verwaltung von Online-Programmier- oder Hacking-Wettbewerben entwickelt wurde. Sie bietet eine nahtlose Erfahrung für Teilnehmer, um ihre Arbeiten einzureichen, für Juroren, um Einreichungen zu bewerten, und für Administratoren, um das gesamte Ökosystem zu verwalten. Dieses Projekt wurde als Universitätsarbeit konzipiert und umgesetzt und demonstriert Full-Stack-Fähigkeiten durch die Integration eines modernen Frontends, einer robusten Backend-API und einer containerisierten Bereitstellung.\n\n### Die Herausforderung\n\nDie primäre Herausforderung bestand darin, eine sichere Multi-User-Anwendung mit unterschiedlichen Rollen und Berechtigungen zu entwerfen und zu implementieren. Dies erforderte die Erstellung eines widerstandsfähigen Backends, das Authentifizierung, Datenbeziehungen (Benutzer, Wettbewerbe, Einreichungen) und Geschäftslogik handhabt, sowie die Entwicklung einer intuitiven und responsiven Benutzeroberfläche für die Interaktion. Ein Hauptziel war es, den gesamten Stack zu containerisieren, um konsistente und reproduzierbare Entwicklungs- und Bereitstellungsumgebungen zu gewährleisten.\n\n### Hauptfunktionen\n\n*   **Rollenbasierte Zugriffskontrolle:** Unterschiedliche Benutzerrollen (USER, JUDGE, ADMIN) mit verschiedenen Berechtigungen und Ansichten.\n*   **Benutzerauthentifizierung:** Sichere Benutzerregistrierung und Anmeldung mittels JWT (JSON Web Tokens) für das Sitzungsmanagement und `bcryptjs` für das Passwort-Hashing.\n*   **Wettbewerbsmanagement:** Administratoren können Wettbewerbsdetails erstellen, aktualisieren und verwalten.\n*   **Einreichungssystem:** Authentifizierte Benutzer können ihre Beiträge zu aktiven Wettbewerben einreichen.\n*   **Bewertung und Jurierung:** Juroren haben Zugang zu einem dedizierten Portal, um alle Einreichungen für einen Wettbewerb anzusehen und zu bewerten.\n*   **Dynamisches Frontend:** Eine responsive und interaktive Benutzeroberfläche, die mit Next.js und Material-UI erstellt wurde.\n\n### Technischer Einblick\n\n**Frontend:**\n*   **Framework:** Erstellt mit **Next.js** wegen seiner leistungsstarken Funktionen wie serverseitigem Rendering und statischer Seitengenerierung, was eine schnelle und SEO-freundliche Benutzererfahrung bietet.\n*   **UI-Bibliothek:** **Material-UI (MUI)** wurde für ein sauberes, modernes und responsives Designsystem mit einer umfassenden Reihe vorgefertigter Komponenten verwendet.\n*   **GraphQL-Client:** **Apollo Client** wurde zur Verwaltung von Datenabruf, Caching und State-Management eingesetzt und integriert sich nahtlos in die GraphQL-API des Backends.\n*   **State-Management:** Die **React Context API** wurde genutzt, um globalen Zustand wie den Authentifizierungsstatus und Benutzerdetails über die gesamte Anwendung hinweg zu verwalten.\n\n**Backend:**\n*   **Laufzeitumgebung & Framework:** Entwickelt auf **Node.js** mit dem **Express.js**-Framework, um einen robusten und skalierbaren Server zu erstellen.\n*   **API-Schicht:** Implementierung einer **GraphQL**-API mit `express-graphql`, um eine flexible und effiziente Datenabfragesprache für das Frontend bereitzustellen und ein Überladen von Daten (Over-Fetching) zu vermeiden.\n*   **Datenbank:** **MongoDB** wurde als NoSQL-Datenbank verwendet, mit **Mongoose** als Object Data Modeling (ODM)-Bibliothek zur Definition von Schemas und zur Verwaltung der Beziehungen zwischen Wettbewerben, Benutzern und Einreichungen.\n*   **Authentifizierung:** Die API wurde mit einem tokenbasierten Authentifizierungssystem unter Verwendung von **JSON Web Tokens (JWT)** gesichert.\n\n**DevOps/Deployment:**\n*   **Containerisierung:** Der gesamte Anwendungsstack, einschließlich Frontend, Backend und einer MongoDB-Datenbankinstanz, ist mit **Docker** containerisiert und wird mit **Docker Compose** orchestriert. Dies gewährleistet eine konsistente, isolierte und leicht reproduzierbare Umgebung für Entwicklung und Bereitstellung.\n*   **Deployment:** Die Anwendung ist für die Bereitstellung auf Plattformen wie **Heroku** konfiguriert, wie durch das `Procfile` und die `heroku-postbuild`-Skripte angezeigt wird.\n\n### Persönliche Lernerfolge\n\nDieses Projekt war eine bedeutende Lernerfahrung in der Full-Stack-Entwicklung. Zu den wichtigsten Erkenntnissen gehören der Entwurf eines GraphQL-Schemas von Grund auf, die Implementierung eines sicheren, rollenbasierten Authentifizierungssystems mit JWT und die Orchestrierung einer Multi-Service-Anwendung mit Docker Compose. Es hat die Bedeutung der Trennung von Verantwortlichkeiten zwischen Client und Server sowie die Stärke der Containerisierung zur Vereinfachung komplexer Entwicklungsumgebungen untermauert.","projectType":"Full-Stack Web Application","developedAt":"2021-12-20","liveUrl":null,"repoUrl":"https://github.com/dettinjo/competition-web-app","tags":["React","Next.js","Node.js","Express.js","GraphQL","MongoDB","Mongoose","JWT","Docker","Docker Compose","Heroku","Material-UI","Apollo Client"],"createdAt":"2025-10-14T14:34:20.873Z","updatedAt":"2025-10-15T19:22:28.734Z","publishedAt":null,"locale":"de"}}
{"type":"api::software-project.software-project","id":175,"data":{"documentId":"kev0svypi5eyle0zr5d7soeo","title":"Wettbewerbs-Webanwendung","slug":"wettbewerbs-webanwendung","description":"Full-Stack App für Programmierwettbewerbe mit rollenbasiertem Zugriff für User, Juroren & Admins. Ein Projekt der University of the West of Scotland.","longDescription":"### Projektübersicht\n\nDie Wettbewerbs-Webanwendung ist eine umfassende Plattform, die von Grund auf für die Verwaltung von Online-Programmier- oder Hacking-Wettbewerben entwickelt wurde. Sie bietet eine nahtlose Erfahrung für Teilnehmer, um ihre Arbeiten einzureichen, für Juroren, um Einreichungen zu bewerten, und für Administratoren, um das gesamte Ökosystem zu verwalten. Dieses Projekt wurde als Universitätsarbeit konzipiert und umgesetzt und demonstriert Full-Stack-Fähigkeiten durch die Integration eines modernen Frontends, einer robusten Backend-API und einer containerisierten Bereitstellung.\n\n### Die Herausforderung\n\nDie primäre Herausforderung bestand darin, eine sichere Multi-User-Anwendung mit unterschiedlichen Rollen und Berechtigungen zu entwerfen und zu implementieren. Dies erforderte die Erstellung eines widerstandsfähigen Backends, das Authentifizierung, Datenbeziehungen (Benutzer, Wettbewerbe, Einreichungen) und Geschäftslogik handhabt, sowie die Entwicklung einer intuitiven und responsiven Benutzeroberfläche für die Interaktion. Ein Hauptziel war es, den gesamten Stack zu containerisieren, um konsistente und reproduzierbare Entwicklungs- und Bereitstellungsumgebungen zu gewährleisten.\n\n### Hauptfunktionen\n\n*   **Rollenbasierte Zugriffskontrolle:** Unterschiedliche Benutzerrollen (USER, JUDGE, ADMIN) mit verschiedenen Berechtigungen und Ansichten.\n*   **Benutzerauthentifizierung:** Sichere Benutzerregistrierung und Anmeldung mittels JWT (JSON Web Tokens) für das Sitzungsmanagement und `bcryptjs` für das Passwort-Hashing.\n*   **Wettbewerbsmanagement:** Administratoren können Wettbewerbsdetails erstellen, aktualisieren und verwalten.\n*   **Einreichungssystem:** Authentifizierte Benutzer können ihre Beiträge zu aktiven Wettbewerben einreichen.\n*   **Bewertung und Jurierung:** Juroren haben Zugang zu einem dedizierten Portal, um alle Einreichungen für einen Wettbewerb anzusehen und zu bewerten.\n*   **Dynamisches Frontend:** Eine responsive und interaktive Benutzeroberfläche, die mit Next.js und Material-UI erstellt wurde.\n\n### Technischer Einblick\n\n**Frontend:**\n*   **Framework:** Erstellt mit **Next.js** wegen seiner leistungsstarken Funktionen wie serverseitigem Rendering und statischer Seitengenerierung, was eine schnelle und SEO-freundliche Benutzererfahrung bietet.\n*   **UI-Bibliothek:** **Material-UI (MUI)** wurde für ein sauberes, modernes und responsives Designsystem mit einer umfassenden Reihe vorgefertigter Komponenten verwendet.\n*   **GraphQL-Client:** **Apollo Client** wurde zur Verwaltung von Datenabruf, Caching und State-Management eingesetzt und integriert sich nahtlos in die GraphQL-API des Backends.\n*   **State-Management:** Die **React Context API** wurde genutzt, um globalen Zustand wie den Authentifizierungsstatus und Benutzerdetails über die gesamte Anwendung hinweg zu verwalten.\n\n**Backend:**\n*   **Laufzeitumgebung & Framework:** Entwickelt auf **Node.js** mit dem **Express.js**-Framework, um einen robusten und skalierbaren Server zu erstellen.\n*   **API-Schicht:** Implementierung einer **GraphQL**-API mit `express-graphql`, um eine flexible und effiziente Datenabfragesprache für das Frontend bereitzustellen und ein Überladen von Daten (Over-Fetching) zu vermeiden.\n*   **Datenbank:** **MongoDB** wurde als NoSQL-Datenbank verwendet, mit **Mongoose** als Object Data Modeling (ODM)-Bibliothek zur Definition von Schemas und zur Verwaltung der Beziehungen zwischen Wettbewerben, Benutzern und Einreichungen.\n*   **Authentifizierung:** Die API wurde mit einem tokenbasierten Authentifizierungssystem unter Verwendung von **JSON Web Tokens (JWT)** gesichert.\n\n**DevOps/Deployment:**\n*   **Containerisierung:** Der gesamte Anwendungsstack, einschließlich Frontend, Backend und einer MongoDB-Datenbankinstanz, ist mit **Docker** containerisiert und wird mit **Docker Compose** orchestriert. Dies gewährleistet eine konsistente, isolierte und leicht reproduzierbare Umgebung für Entwicklung und Bereitstellung.\n*   **Deployment:** Die Anwendung ist für die Bereitstellung auf Plattformen wie **Heroku** konfiguriert, wie durch das `Procfile` und die `heroku-postbuild`-Skripte angezeigt wird.\n\n### Persönliche Lernerfolge\n\nDieses Projekt war eine bedeutende Lernerfahrung in der Full-Stack-Entwicklung. Zu den wichtigsten Erkenntnissen gehören der Entwurf eines GraphQL-Schemas von Grund auf, die Implementierung eines sicheren, rollenbasierten Authentifizierungssystems mit JWT und die Orchestrierung einer Multi-Service-Anwendung mit Docker Compose. Es hat die Bedeutung der Trennung von Verantwortlichkeiten zwischen Client und Server sowie die Stärke der Containerisierung zur Vereinfachung komplexer Entwicklungsumgebungen untermauert.","projectType":"Full-Stack Web Application","developedAt":"2021-12-20","liveUrl":null,"repoUrl":"https://github.com/dettinjo/competition-web-app","tags":["React","Next.js","Node.js","Express.js","GraphQL","MongoDB","Mongoose","JWT","Docker","Docker Compose","Heroku","Material-UI","Apollo Client"],"createdAt":"2025-10-14T14:34:20.873Z","updatedAt":"2025-10-15T19:22:28.734Z","publishedAt":"2025-10-15T19:22:28.821Z","locale":"de"}}
{"type":"api::software-project.software-project","id":176,"data":{"documentId":"kev0svypi5eyle0zr5d7soeo","title":"Competition Web App","slug":"competition-web-app","description":"A full-stack web app for hosting coding competitions with role-based access for users, judges, and admins. A University of the West of Scotland project.\n","longDescription":"### Project Overview\n\nThe Competition Web App is a comprehensive platform built from the ground up to manage online coding or hacking competitions. It provides a seamless experience for participants to submit their work, for judges to review and rate entries, and for administrators to manage the entire ecosystem. This project was conceived and developed as a university assignment, demonstrating a full-stack skill set by integrating a modern frontend, a robust backend API, and containerized deployment.\n\n### The Challenge\n\nThe primary challenge was to design and implement a secure, multi-user application with distinct roles and permissions. This required creating a resilient backend capable of handling authentication, data relationships (users, competitions, submissions), and business logic, while also building an intuitive and responsive user interface for interaction. A key goal was to containerize the entire stack to ensure consistent and reproducible development and deployment environments.\n\n### Key Features\n\n*   **Role-Based Access Control:** Distinct user roles (USER, JUDGE, ADMIN) with different permissions and views.\n*   **User Authentication:** Secure user registration and login using JWT (JSON Web Tokens) for session management and `bcryptjs` for password hashing.\n*   **Competition Management:** Administrators can create, update, and manage competition details.\n*   **Submission System:** Authenticated users can submit their entries to active competitions.\n*   **Rating and Judging:** Judges have access to a dedicated portal to view and rate all submissions for a competition.\n*   **Dynamic Frontend:** A responsive and interactive user interface built with Next.js and Material-UI.\n\n### Technical Deep Dive\n\n**Frontend:**\n*   **Framework:** Built with **Next.js** for its powerful features like server-side rendering and static site generation, providing a fast and SEO-friendly user experience.\n*   **UI Library:** Utilized **Material-UI (MUI)** for a clean, modern, and responsive design system with a comprehensive set of pre-built components.\n*   **GraphQL Client:** **Apollo Client** was used for managing data fetching, caching, and state management, seamlessly integrating with the backend GraphQL API.\n*   **State Management:** Leveraged **React Context API** for managing global state such as user authentication status and details across the application.\n\n**Backend:**\n*   **Runtime & Framework:** Developed on **Node.js** with the **Express.js** framework to create a robust and scalable server.\n*   **API Layer:** Implemented a **GraphQL** API using `express-graphql` to provide a flexible and efficient data querying language for the frontend, avoiding over-fetching of data.\n*   **Database:** Utilized **MongoDB** as the NoSQL database, with **Mongoose** as the Object Data Modeling (ODM) library to define schemas and manage relationships between competitions, users, and submissions.\n*   **Authentication:** Secured the API using a token-based authentication system with **JSON Web Tokens (JWT)**.\n\n**DevOps/Deployment:**\n*   **Containerization:** The entire application stack, including the frontend, backend, and a MongoDB database instance, is containerized using **Docker** and orchestrated with **Docker Compose**. This ensures a consistent, isolated, and easily reproducible environment for both development and deployment.\n*   **Deployment:** The application is configured for deployment on platforms like **Heroku**, as indicated by the `Procfile` and `heroku-postbuild` scripts.\n\n### Personal Learnings\n\nThis project was a significant learning experience in full-stack development. Key takeaways include designing a GraphQL schema from scratch, implementing a secure, role-based authentication system with JWT, and orchestrating a multi-service application using Docker Compose. It reinforced the importance of separating concerns between the client and server and the power of containerization in simplifying complex development environments.","projectType":"Full-Stack Web Application","developedAt":"2021-12-01","liveUrl":null,"repoUrl":"https://github.com/dettinjo/competition-web-app","tags":["React","Next.js","Node.js","Express.js","GraphQL","MongoDB","Mongoose","JWT","Docker","Docker Compose","Heroku","Full-Stack","Material-UI","Apollo Client"],"createdAt":"2025-10-14T14:35:40.975Z","updatedAt":"2025-10-15T19:22:46.603Z","publishedAt":null,"locale":"en"}}
{"type":"api::software-project.software-project","id":177,"data":{"documentId":"kev0svypi5eyle0zr5d7soeo","title":"Competition Web App","slug":"competition-web-app","description":"A full-stack web app for hosting coding competitions with role-based access for users, judges, and admins. A University of the West of Scotland project.\n","longDescription":"### Project Overview\n\nThe Competition Web App is a comprehensive platform built from the ground up to manage online coding or hacking competitions. It provides a seamless experience for participants to submit their work, for judges to review and rate entries, and for administrators to manage the entire ecosystem. This project was conceived and developed as a university assignment, demonstrating a full-stack skill set by integrating a modern frontend, a robust backend API, and containerized deployment.\n\n### The Challenge\n\nThe primary challenge was to design and implement a secure, multi-user application with distinct roles and permissions. This required creating a resilient backend capable of handling authentication, data relationships (users, competitions, submissions), and business logic, while also building an intuitive and responsive user interface for interaction. A key goal was to containerize the entire stack to ensure consistent and reproducible development and deployment environments.\n\n### Key Features\n\n*   **Role-Based Access Control:** Distinct user roles (USER, JUDGE, ADMIN) with different permissions and views.\n*   **User Authentication:** Secure user registration and login using JWT (JSON Web Tokens) for session management and `bcryptjs` for password hashing.\n*   **Competition Management:** Administrators can create, update, and manage competition details.\n*   **Submission System:** Authenticated users can submit their entries to active competitions.\n*   **Rating and Judging:** Judges have access to a dedicated portal to view and rate all submissions for a competition.\n*   **Dynamic Frontend:** A responsive and interactive user interface built with Next.js and Material-UI.\n\n### Technical Deep Dive\n\n**Frontend:**\n*   **Framework:** Built with **Next.js** for its powerful features like server-side rendering and static site generation, providing a fast and SEO-friendly user experience.\n*   **UI Library:** Utilized **Material-UI (MUI)** for a clean, modern, and responsive design system with a comprehensive set of pre-built components.\n*   **GraphQL Client:** **Apollo Client** was used for managing data fetching, caching, and state management, seamlessly integrating with the backend GraphQL API.\n*   **State Management:** Leveraged **React Context API** for managing global state such as user authentication status and details across the application.\n\n**Backend:**\n*   **Runtime & Framework:** Developed on **Node.js** with the **Express.js** framework to create a robust and scalable server.\n*   **API Layer:** Implemented a **GraphQL** API using `express-graphql` to provide a flexible and efficient data querying language for the frontend, avoiding over-fetching of data.\n*   **Database:** Utilized **MongoDB** as the NoSQL database, with **Mongoose** as the Object Data Modeling (ODM) library to define schemas and manage relationships between competitions, users, and submissions.\n*   **Authentication:** Secured the API using a token-based authentication system with **JSON Web Tokens (JWT)**.\n\n**DevOps/Deployment:**\n*   **Containerization:** The entire application stack, including the frontend, backend, and a MongoDB database instance, is containerized using **Docker** and orchestrated with **Docker Compose**. This ensures a consistent, isolated, and easily reproducible environment for both development and deployment.\n*   **Deployment:** The application is configured for deployment on platforms like **Heroku**, as indicated by the `Procfile` and `heroku-postbuild` scripts.\n\n### Personal Learnings\n\nThis project was a significant learning experience in full-stack development. Key takeaways include designing a GraphQL schema from scratch, implementing a secure, role-based authentication system with JWT, and orchestrating a multi-service application using Docker Compose. It reinforced the importance of separating concerns between the client and server and the power of containerization in simplifying complex development environments.","projectType":"Full-Stack Web Application","developedAt":"2021-12-01","liveUrl":null,"repoUrl":"https://github.com/dettinjo/competition-web-app","tags":["React","Next.js","Node.js","Express.js","GraphQL","MongoDB","Mongoose","JWT","Docker","Docker Compose","Heroku","Full-Stack","Material-UI","Apollo Client"],"createdAt":"2025-10-14T14:35:40.975Z","updatedAt":"2025-10-15T19:22:46.603Z","publishedAt":"2025-10-15T19:22:46.775Z","locale":"en"}}
{"type":"api::software-project.software-project","id":178,"data":{"documentId":"ktjfogua0dgtxsrm2339hfak","title":"CO2 Emission Tracker","slug":"co-2-emission-tracker","description":"Eine iOS-App für Porsche-Mitarbeiter, die CO₂-Emissionen erfasst und nachhaltige Mobilität durch Challenges und Ranglisten gamifiziert.\n","longDescription":"### Projektübersicht\nDer Porsche Emissions-Tracker ist eine umfassende iOS-Anwendung, die im Rahmen eines interdisziplinären Projekts zwischen der Hochschule der Medien Stuttgart und der Porsche AG entwickelt wurde. Das Hauptziel ist es, nachhaltige Transportentscheidungen unter den Porsche-Mitarbeitern zu fördern, indem ein größeres Bewusstsein für ihren täglichen CO₂-Fußabdruck geschaffen wird. Die App erfasst automatisch Pendel- und Geschäftsreisen, berechnet die entsprechenden CO₂-Emissionen und wandelt diese in ein punktbasiertes Gamification-System um.\n\n### Die Herausforderung\nDie zentrale Herausforderung bestand darin, eine nahtlose und motivierende Benutzererfahrung zu schaffen, die Verhaltensänderungen anstößt, ohne aufdringlich zu sein. Dies erforderte ein robustes Hintergrund-Tracking-System, das verschiedene Verkehrsmittel (Gehen, Radfahren, Auto, Zug) präzise erkennen und gleichzeitig den Akkuverbrauch minimieren konnte. Darüber hinaus benötigte die App ein skalierbares Backend zur Verwaltung von Benutzerdaten, Herausforderungen und Ranglisten, wobei Datenschutz und -sicherheit stets gewährleistet sein mussten.\n\n### Hauptmerkmale\n*   **Automatisches Fahrt-Tracking:** Nutzt CoreLocation und CoreMotion, um Fahrten im Hintergrund automatisch zu erkennen, aufzuzeichnen und zu klassifizieren, mit minimaler Benutzerinteraktion.\n*   **CO₂-Emissionsberechnung:** Berechnet präzise die CO₂-Emissionen für jede Fahrt basierend auf der zurückgelegten Strecke und dem erkannten Verkehrsmittel.\n*   **Gamification-Engine:** Beinhaltet ein durchdachtes Punktesystem, bei dem Benutzer für die Wahl nachhaltiger Optionen belohnt werden. Nutzer können an zeitlich begrenzten Herausforderungen teilnehmen (z. B. \"50 km Radfahren in einer Woche\"), um Bonuspunkte zu verdienen.\n*   **Interaktive Ranglisten:** Zeigt Ranglisten für Einzelpersonen und Teams (Abteilungen), um einen freundschaftlichen Wettbewerb zu fördern und die gemeinsame Anstrengung zu unterstützen.\n*   **Detaillierte Fahrtenhistorie:** Bietet den Nutzern ein umfassendes Protokoll ihrer vergangenen Fahrten, einschließlich Kartenansichten, Entfernungen und berechneten Emissionen, um ihren Fortschritt im Zeitverlauf zu verfolgen.\n*   **Benutzerprofil und Anpassung:** Ermöglicht es den Nutzern, ihr Profil zu verwalten, ihre Statistiken einzusehen und persönliche Nachhaltigkeitsziele festzulegen.\n*   **Klassifizierung von Geschäfts- und Privatfahrten:** Eine einfache Wisch-Geste ermöglicht es den Nutzern, Fahrten zu klassifizieren, sodass nur relevante Geschäftsreisen in die offiziellen Unternehmensmetriken einfließen.\n\n### Technischer Einblick\n**Frontend:**\nDie gesamte Benutzeroberfläche wurde nativ für iOS mit **SwiftUI**, dem modernen deklarativen UI-Framework von Apple, entwickelt. Dies ermöglichte eine schnelle Entwicklung einer sauberen, reaktionsschnellen und interaktiven Benutzeroberfläche, die sich nahtlos in die Plattform integriert. **MapKit** wurde integriert, um reichhaltige, interaktive Karten für die Visualisierung der Fahrtenhistorie bereitzustellen.\n\n**Backend & Daten:**\nAls Backend-as-a-Service wurde **CloudKit** gewählt, um die gesamte Datenpersistenz und -synchronisierung zu übernehmen. Dies bot eine sichere und skalierbare Lösung für die Speicherung von Benutzerprofilen, Fahrtdaten, Teams und Herausforderungen, ohne dass eine separate Serverinfrastruktur verwaltet werden musste. Repositories wurden strukturiert, um Datenmodelle für Benutzer, Fahrten, Fahrzeuge und Teams zu verwalten, was eine saubere Trennung der Verantwortlichkeiten gewährleistete.\n\n**DevOps/Deployment:**\nDas Projekt wurde in einer Standard-Xcode-Projektstruktur verwaltet und versioniert. Es wurde für die Bereitstellung auf iOS-Geräten konfiguriert, wobei die Berechtigungen für CloudKit-Dienste, Hintergrund-Standortaktualisierungen und den Zugriff auf Bewegungsaktivitäten eingerichtet wurden. Die App wurde für moderne iOS-Versionen entwickelt, um Kompatibilität und Leistung zu gewährleisten.\n\n### Persönliche Lernerfahrungen\nDieses Projekt war eine fantastische Gelegenheit, eine voll funktionsfähige, datengesteuerte Anwendung von Grund auf mit nativen iOS-Technologien zu entwickeln. Ich sammelte tiefgreifende Erfahrungen bei der Implementierung komplexer Funktionen wie Hintergrund-Standort- und Aktivitätstracking und der Sicherstellung einer effizienten Akkunutzung. Die Arbeit mit CloudKit vermittelte wertvolle Einblicke in das Design von Datenmodellen für ein cloudbasiertes Backend und die Verwaltung asynchroner Datenflüsse. Die Zusammenarbeit mit der Porsche AG lehrte mich außerdem, wie man Geschäftsanforderungen in technische Lösungen innerhalb eines Unternehmenskontexts umsetzt.","projectType":"iOS Application","developedAt":"2022-07-01","liveUrl":null,"repoUrl":"https://github.com/dettinjo/CO2_Tracker","tags":["Swift","SwiftUI","CloudKit","MapKit","CoreLocation","CoreMotion","Xcode"],"createdAt":"2025-10-14T15:19:33.937Z","updatedAt":"2025-10-15T19:10:24.381Z","publishedAt":null,"locale":"de"}}
{"type":"api::software-project.software-project","id":179,"data":{"documentId":"ktjfogua0dgtxsrm2339hfak","title":"CO2 Emission Tracker","slug":"co-2-emission-tracker","description":"Eine iOS-App für Porsche-Mitarbeiter, die CO₂-Emissionen erfasst und nachhaltige Mobilität durch Challenges und Ranglisten gamifiziert.\n","longDescription":"### Projektübersicht\nDer Porsche Emissions-Tracker ist eine umfassende iOS-Anwendung, die im Rahmen eines interdisziplinären Projekts zwischen der Hochschule der Medien Stuttgart und der Porsche AG entwickelt wurde. Das Hauptziel ist es, nachhaltige Transportentscheidungen unter den Porsche-Mitarbeitern zu fördern, indem ein größeres Bewusstsein für ihren täglichen CO₂-Fußabdruck geschaffen wird. Die App erfasst automatisch Pendel- und Geschäftsreisen, berechnet die entsprechenden CO₂-Emissionen und wandelt diese in ein punktbasiertes Gamification-System um.\n\n### Die Herausforderung\nDie zentrale Herausforderung bestand darin, eine nahtlose und motivierende Benutzererfahrung zu schaffen, die Verhaltensänderungen anstößt, ohne aufdringlich zu sein. Dies erforderte ein robustes Hintergrund-Tracking-System, das verschiedene Verkehrsmittel (Gehen, Radfahren, Auto, Zug) präzise erkennen und gleichzeitig den Akkuverbrauch minimieren konnte. Darüber hinaus benötigte die App ein skalierbares Backend zur Verwaltung von Benutzerdaten, Herausforderungen und Ranglisten, wobei Datenschutz und -sicherheit stets gewährleistet sein mussten.\n\n### Hauptmerkmale\n*   **Automatisches Fahrt-Tracking:** Nutzt CoreLocation und CoreMotion, um Fahrten im Hintergrund automatisch zu erkennen, aufzuzeichnen und zu klassifizieren, mit minimaler Benutzerinteraktion.\n*   **CO₂-Emissionsberechnung:** Berechnet präzise die CO₂-Emissionen für jede Fahrt basierend auf der zurückgelegten Strecke und dem erkannten Verkehrsmittel.\n*   **Gamification-Engine:** Beinhaltet ein durchdachtes Punktesystem, bei dem Benutzer für die Wahl nachhaltiger Optionen belohnt werden. Nutzer können an zeitlich begrenzten Herausforderungen teilnehmen (z. B. \"50 km Radfahren in einer Woche\"), um Bonuspunkte zu verdienen.\n*   **Interaktive Ranglisten:** Zeigt Ranglisten für Einzelpersonen und Teams (Abteilungen), um einen freundschaftlichen Wettbewerb zu fördern und die gemeinsame Anstrengung zu unterstützen.\n*   **Detaillierte Fahrtenhistorie:** Bietet den Nutzern ein umfassendes Protokoll ihrer vergangenen Fahrten, einschließlich Kartenansichten, Entfernungen und berechneten Emissionen, um ihren Fortschritt im Zeitverlauf zu verfolgen.\n*   **Benutzerprofil und Anpassung:** Ermöglicht es den Nutzern, ihr Profil zu verwalten, ihre Statistiken einzusehen und persönliche Nachhaltigkeitsziele festzulegen.\n*   **Klassifizierung von Geschäfts- und Privatfahrten:** Eine einfache Wisch-Geste ermöglicht es den Nutzern, Fahrten zu klassifizieren, sodass nur relevante Geschäftsreisen in die offiziellen Unternehmensmetriken einfließen.\n\n### Technischer Einblick\n**Frontend:**\nDie gesamte Benutzeroberfläche wurde nativ für iOS mit **SwiftUI**, dem modernen deklarativen UI-Framework von Apple, entwickelt. Dies ermöglichte eine schnelle Entwicklung einer sauberen, reaktionsschnellen und interaktiven Benutzeroberfläche, die sich nahtlos in die Plattform integriert. **MapKit** wurde integriert, um reichhaltige, interaktive Karten für die Visualisierung der Fahrtenhistorie bereitzustellen.\n\n**Backend & Daten:**\nAls Backend-as-a-Service wurde **CloudKit** gewählt, um die gesamte Datenpersistenz und -synchronisierung zu übernehmen. Dies bot eine sichere und skalierbare Lösung für die Speicherung von Benutzerprofilen, Fahrtdaten, Teams und Herausforderungen, ohne dass eine separate Serverinfrastruktur verwaltet werden musste. Repositories wurden strukturiert, um Datenmodelle für Benutzer, Fahrten, Fahrzeuge und Teams zu verwalten, was eine saubere Trennung der Verantwortlichkeiten gewährleistete.\n\n**DevOps/Deployment:**\nDas Projekt wurde in einer Standard-Xcode-Projektstruktur verwaltet und versioniert. Es wurde für die Bereitstellung auf iOS-Geräten konfiguriert, wobei die Berechtigungen für CloudKit-Dienste, Hintergrund-Standortaktualisierungen und den Zugriff auf Bewegungsaktivitäten eingerichtet wurden. Die App wurde für moderne iOS-Versionen entwickelt, um Kompatibilität und Leistung zu gewährleisten.\n\n### Persönliche Lernerfahrungen\nDieses Projekt war eine fantastische Gelegenheit, eine voll funktionsfähige, datengesteuerte Anwendung von Grund auf mit nativen iOS-Technologien zu entwickeln. Ich sammelte tiefgreifende Erfahrungen bei der Implementierung komplexer Funktionen wie Hintergrund-Standort- und Aktivitätstracking und der Sicherstellung einer effizienten Akkunutzung. Die Arbeit mit CloudKit vermittelte wertvolle Einblicke in das Design von Datenmodellen für ein cloudbasiertes Backend und die Verwaltung asynchroner Datenflüsse. Die Zusammenarbeit mit der Porsche AG lehrte mich außerdem, wie man Geschäftsanforderungen in technische Lösungen innerhalb eines Unternehmenskontexts umsetzt.","projectType":"iOS Application","developedAt":"2022-07-01","liveUrl":null,"repoUrl":"https://github.com/dettinjo/CO2_Tracker","tags":["Swift","SwiftUI","CloudKit","MapKit","CoreLocation","CoreMotion","Xcode"],"createdAt":"2025-10-14T15:19:33.937Z","updatedAt":"2025-10-15T19:10:24.381Z","publishedAt":"2025-10-15T19:10:24.421Z","locale":"de"}}
{"type":"api::software-project.software-project","id":180,"data":{"documentId":"ktjfogua0dgtxsrm2339hfak","title":"CO2 Emission Tracker","slug":"co-2-emission-tracker1","description":"An iOS app for Porsche employees that tracks CO₂ emissions, gamifying sustainable travel choices through challenges and leaderboards.\n","longDescription":"### Project Overview\nThe Porsche Emission Tracker is a comprehensive iOS application developed as part of an interdisciplinary project between the Media University Stuttgart and Porsche AG. Its primary goal is to encourage sustainable transportation choices among Porsche employees by making them more aware of their daily carbon footprint. The app automatically detects commutes and business trips, calculates the corresponding CO₂ emissions, and translates them into a point-based gamification system.\n\n### The Challenge\nThe core challenge was to create a seamless and engaging user experience that could motivate behavioral change without being intrusive. This required a robust background tracking system that could accurately identify different modes of transport (walking, cycling, car, train) while being mindful of battery consumption. Additionally, the app needed a scalable backend to manage user data, challenges, and leaderboards, all while ensuring data privacy and security.\n\n### Key Features\n*   **Automatic Trip Tracking:** Utilizes CoreLocation and CoreMotion to automatically detect, record, and classify trips in the background with minimal user intervention.\n*   **CO₂ Emission Calculation:** Accurately calculates carbon emissions for each trip based on the distance traveled and the detected mode of transport.\n*   **Gamification Engine:** Features a sophisticated points system where users are rewarded for choosing sustainable options. Users can participate in time-based challenges (e.g., \"cycle 50km in a week\") to earn bonus points.\n*   **Interactive Leaderboards:** Displays rankings for both individuals and teams (departments), fostering friendly competition and encouraging collective effort.\n*   **Detailed Trip History:** Provides users with a comprehensive log of their past trips, including map views, distances, and calculated emissions, allowing them to track their progress over time.\n*   **User Profile and Customization:** Allows users to manage their profile, view their statistics, and set personal sustainability goals.\n*   **Business vs. Private Trip Classification:** A simple swipe interface lets users classify trips, ensuring that only relevant business travel is counted towards official company metrics.\n\n### Technical Deep Dive\n**Frontend:**\nThe entire user interface was built natively for iOS using **SwiftUI**, Apple's modern declarative UI framework. This allowed for the rapid development of a clean, responsive, and interactive UI that feels at home on the platform. **MapKit** was integrated to provide rich, interactive maps for trip history visualization.\n\n**Backend & Data:**\n**CloudKit** was chosen as the backend-as-a-service to handle all data persistence and synchronization. This provided a secure and scalable solution for storing user profiles, trip data, teams, and challenges without the need to manage a separate server infrastructure. Repositories were structured to manage data models for Users, Trips, Vehicles, and Teams, ensuring a clean separation of concerns.\n\n**DevOps/Deployment:**\nThe project was managed and version-controlled within a standard Xcode project structure. It was configured for deployment on iOS devices, with entitlements set up for CloudKit services, background location updates, and motion activity access. The app was built to target modern iOS versions, ensuring compatibility and performance.\n\n### Personal Learnings\nThis project was a fantastic opportunity to build a full-featured, data-driven application from the ground up using native iOS technologies. I gained deep experience in implementing complex features like background location and activity tracking, ensuring efficient battery usage. Working with CloudKit provided valuable insights into designing data models for a cloud-based backend and managing asynchronous data flows. The collaboration with Porsche AG also taught me how to translate business requirements into technical solutions within a corporate context.","projectType":"iOS Application","developedAt":"2022-07-01","liveUrl":null,"repoUrl":"https://github.com/dettinjo/CO2_Tracker","tags":["Swift","SwiftUI","CloudKit","MapKit","CoreLocation","CoreMotion","Xcode"],"createdAt":"2025-10-14T15:29:11.947Z","updatedAt":"2025-10-15T19:10:05.009Z","publishedAt":null,"locale":"en"}}
{"type":"api::software-project.software-project","id":181,"data":{"documentId":"ktjfogua0dgtxsrm2339hfak","title":"CO2 Emission Tracker","slug":"co-2-emission-tracker1","description":"An iOS app for Porsche employees that tracks CO₂ emissions, gamifying sustainable travel choices through challenges and leaderboards.\n","longDescription":"### Project Overview\nThe Porsche Emission Tracker is a comprehensive iOS application developed as part of an interdisciplinary project between the Media University Stuttgart and Porsche AG. Its primary goal is to encourage sustainable transportation choices among Porsche employees by making them more aware of their daily carbon footprint. The app automatically detects commutes and business trips, calculates the corresponding CO₂ emissions, and translates them into a point-based gamification system.\n\n### The Challenge\nThe core challenge was to create a seamless and engaging user experience that could motivate behavioral change without being intrusive. This required a robust background tracking system that could accurately identify different modes of transport (walking, cycling, car, train) while being mindful of battery consumption. Additionally, the app needed a scalable backend to manage user data, challenges, and leaderboards, all while ensuring data privacy and security.\n\n### Key Features\n*   **Automatic Trip Tracking:** Utilizes CoreLocation and CoreMotion to automatically detect, record, and classify trips in the background with minimal user intervention.\n*   **CO₂ Emission Calculation:** Accurately calculates carbon emissions for each trip based on the distance traveled and the detected mode of transport.\n*   **Gamification Engine:** Features a sophisticated points system where users are rewarded for choosing sustainable options. Users can participate in time-based challenges (e.g., \"cycle 50km in a week\") to earn bonus points.\n*   **Interactive Leaderboards:** Displays rankings for both individuals and teams (departments), fostering friendly competition and encouraging collective effort.\n*   **Detailed Trip History:** Provides users with a comprehensive log of their past trips, including map views, distances, and calculated emissions, allowing them to track their progress over time.\n*   **User Profile and Customization:** Allows users to manage their profile, view their statistics, and set personal sustainability goals.\n*   **Business vs. Private Trip Classification:** A simple swipe interface lets users classify trips, ensuring that only relevant business travel is counted towards official company metrics.\n\n### Technical Deep Dive\n**Frontend:**\nThe entire user interface was built natively for iOS using **SwiftUI**, Apple's modern declarative UI framework. This allowed for the rapid development of a clean, responsive, and interactive UI that feels at home on the platform. **MapKit** was integrated to provide rich, interactive maps for trip history visualization.\n\n**Backend & Data:**\n**CloudKit** was chosen as the backend-as-a-service to handle all data persistence and synchronization. This provided a secure and scalable solution for storing user profiles, trip data, teams, and challenges without the need to manage a separate server infrastructure. Repositories were structured to manage data models for Users, Trips, Vehicles, and Teams, ensuring a clean separation of concerns.\n\n**DevOps/Deployment:**\nThe project was managed and version-controlled within a standard Xcode project structure. It was configured for deployment on iOS devices, with entitlements set up for CloudKit services, background location updates, and motion activity access. The app was built to target modern iOS versions, ensuring compatibility and performance.\n\n### Personal Learnings\nThis project was a fantastic opportunity to build a full-featured, data-driven application from the ground up using native iOS technologies. I gained deep experience in implementing complex features like background location and activity tracking, ensuring efficient battery usage. Working with CloudKit provided valuable insights into designing data models for a cloud-based backend and managing asynchronous data flows. The collaboration with Porsche AG also taught me how to translate business requirements into technical solutions within a corporate context.","projectType":"iOS Application","developedAt":"2022-07-01","liveUrl":null,"repoUrl":"https://github.com/dettinjo/CO2_Tracker","tags":["Swift","SwiftUI","CloudKit","MapKit","CoreLocation","CoreMotion","Xcode"],"createdAt":"2025-10-14T15:29:11.947Z","updatedAt":"2025-10-15T19:10:05.009Z","publishedAt":"2025-10-15T19:10:05.052Z","locale":"en"}}
{"type":"api::software-project.software-project","id":182,"data":{"documentId":"kuo24gwolnshgs9zdr5n18nk","title":"LLM-Fakten-Auditor","slug":"llm-fakten-auditor","description":"Eine Pipeline, die LLM-Antworten faktisch prüft, Entitäten verknüpft und KI-Halluzinationen bekämpft, um die Zuverlässigkeit zu erhöhen.","longDescription":"### Projektübersicht\nDer LLM-Fakten-Auditor ist ein anspruchsvolles NLP-System, das als entscheidende Verifizierungsschicht für Antworten dient, die von Large Language Models (LLMs) wie Llama 2 und 3 generiert werden. In einer Zeit, in der KI-generierte Inhalte allgegenwärtig werden, ist die Sicherstellung ihrer faktischen Richtigkeit von größter Bedeutung. Dieses Projekt begegnet der Herausforderung von LLM-„Halluzinationen“, indem es den abstrakten Text des Modells in strukturiertem Wissen verankert und so effektiv als Wächter gegen Fehlinformationen fungiert.\n\n### Die Herausforderung\nObwohl LLMs unglaublich leistungsfähig sind, können sie aufgrund ihrer generativen Natur plausibel klingende, aber sachlich falsche Aussagen produzieren. Die zentrale Herausforderung bestand darin, eine automatisierte Pipeline zu entwickeln, die die Antwort eines LLMs systematisch dekonstruieren, ihre Behauptungen mit einer zuverlässigen Wissensdatenbank validieren und sie mit verifizierbaren Links anreichern kann – alles ohne menschliches Eingreifen. Dies erforderte einen pragmatischen Ansatz, der das semantische Verständnis neuronaler Modelle mit der strukturierten Gewissheit eines Wissensgraphen wie Wikidata kombiniert.\n\n### Hauptmerkmale\n*   **Integration mehrerer LLM-Modelle:** Generiert nahtlos Antworten durch Wrapper für Llama 2 und Llama 3, was Flexibilität und Leistungsvergleiche ermöglicht.\n*   **Fortgeschrittenes Entity Linking:** Identifiziert benannte Entitäten im Text und disambiguiert sie durch Verknüpfung mit der korrekten Wikipedia-Seite über einen mehrstufigen Prozess, der Popularität, Kontextähnlichkeit und Inter-Entitäten-Kohärenz berücksichtigt.\n*   **Präzise Antwortextraktion:** Klassifiziert den Typ der Benutzeranfrage (boolesch, Entität oder Aussage) und destilliert die oft ausführliche LLM-Ausgabe zu einer direkten, prägnanten Antwort (z. B. „Ja“, „Nein“ oder der Name einer Entität).\n*   **Wissensbasierte Faktenprüfung:** Konstruiert ein semantisches Tripel (Subjekt-Relation-Objekt) aus Frage und Antwort und fragt dann Wikidata ab, um zu überprüfen, ob diese Beziehung existiert, was eine robuste Überprüfung der faktischen Grundlage der Antwort ermöglicht.\n*   **Vollständig containerisierte Umgebung:** Nutzt Docker, um die gesamte Anwendung einschließlich aller Modelle und Abhängigkeiten zu paketieren, was vollständige Reproduzierbarkeit und eine einfache Einrichtung gewährleistet.\n\n### Technischer Einblick\nDas Projekt ist als eine sequenzielle Pipeline aufgebaut, bei der die Ausgabe jeder Stufe zur Eingabe für die nächste wird.\n\n**Antwortgenerierung & NLP-Pipeline:**\nDer Prozess beginnt damit, eine Frage an ein LLM (Llama 2 oder 3) über die `llama_cpp_python`-Bibliothek zu senden. Der resultierende Text wird dann durch eine Reihe von NLP-Modellen verarbeitet. Die anfängliche Klassifizierung der Frage wird von spezialisierten Transformer-Modellen (`shahrukhx01/question-vs-statement-classifier` und `PrimeQA/tydiqa-boolean-question-classifier`) übernommen, um das erwartete Antwortformat zu bestimmen.\n\n**Entity Linking & Disambiguierung:**\nDies ist der Kern der Verankerungsfähigkeit des Systems.\n1.  **Erkennung:** Entitäten werden zunächst mit `spaCy` und dem `dslim/bert-base-NER`-Modell für hohe Genauigkeit identifiziert.\n2.  **Kandidatengenerierung:** Für jede Entitätsnennung wird der SPARQL-Endpunkt von Wikidata abgefragt, um potenzielle Kandidatenentitäten zu erhalten, die nach Popularität geordnet sind.\n3.  **Disambiguierung:** Ein `DistilBERT`-Modell berechnet die Kosinus-Ähnlichkeit zwischen dem Embedding des Kontexts der Entität und dem Embedding des ersten Absatzes der Wikipedia-Seite jedes Kandidaten. Diese semantische Prüfung, kombiniert mit einer Heuristik für exakte Übereinstimmungen, löst Mehrdeutigkeiten effektiv auf (z. B. die Unterscheidung zwischen dem Apfel als Frucht und Apple Inc.).\n\n**Faktenprüfung & Verifizierung:**\nZur Validierung der endgültigen Antwort wird Stanford CoreNLP (`Stanza`) verwendet, um eine offene Informationsextraktion durchzuführen und die endgültige Aussage in ein relationales Tripel umzuwandeln. Dieses strukturierte Tripel wird dann verwendet, um Wikidata abzufragen. Das System prüft, ob eine Eigenschaft existiert, die das Subjekt und das Objekt verbindet. Wenn die Beziehung in der Wissensdatenbank bestätigt wird, wird die Antwort als „korrekt“ markiert.\n\n**Containerisierung & Umgebung:**\nDie gesamte Anwendung ist in einem `Dockerfile` definiert, das `karmaresearch/wdps2` als Basis-Image verwendet. Ein `setup.py`-Skript lädt alle erforderlichen Modelle (von Hugging Face und Stanza) vorab herunter und speichert sie im Docker-Image zwischen. Dadurch wird sichergestellt, dass die Umgebung autark und ohne weitere Downloads lauffähig ist.\n\n### Persönliche Lernerfolge\nDieses Projekt war ein tiefer Einblick in die Entwicklung einer komplexen, realitätsnahen NLP-Anwendung. Eine zentrale Erkenntnis war die Stärke der Kombination verschiedener KI-Paradigmen: die Nutzung der kreativen Texterstellungsfähigkeiten von LLMs bei gleichzeitiger Auferlegung der starren, faktischen Beschränkungen einer symbolischen Wissensdatenbank wie Wikidata. Ich habe bedeutende Erfahrungen im Management mehrerer vortrainierter Modelle, in der Orchestrierung einer mehrstufigen Datenverarbeitungspipeline und im Entwurf von Heuristiken zur Lösung komplexer Disambiguierungsprobleme gesammelt. Darüber hinaus war die Containerisierung einer ressourcenintensiven, modellabhängigen Anwendung mit Docker eine wertvolle Lektion in der Erstellung reproduzierbarer und portabler Data-Science-Lösungen.","projectType":"Data Science & NLP","developedAt":"2024-10-14","liveUrl":null,"repoUrl":"https://github.com/dettinjo/LLM-Fact-Auditor","tags":["Python","Docker","PyTorch","Transformers","spaCy","NLTK","Stanza","CoreNLP","LLM","Llama","NLP","Entity Linking","Fact-Checking","Wikidata","Data Processing"],"createdAt":"2025-10-14T20:26:26.842Z","updatedAt":"2025-10-15T19:25:08.677Z","publishedAt":null,"locale":"de"}}
{"type":"api::software-project.software-project","id":183,"data":{"documentId":"kuo24gwolnshgs9zdr5n18nk","title":"LLM-Fakten-Auditor","slug":"llm-fakten-auditor","description":"Eine Pipeline, die LLM-Antworten faktisch prüft, Entitäten verknüpft und KI-Halluzinationen bekämpft, um die Zuverlässigkeit zu erhöhen.","longDescription":"### Projektübersicht\nDer LLM-Fakten-Auditor ist ein anspruchsvolles NLP-System, das als entscheidende Verifizierungsschicht für Antworten dient, die von Large Language Models (LLMs) wie Llama 2 und 3 generiert werden. In einer Zeit, in der KI-generierte Inhalte allgegenwärtig werden, ist die Sicherstellung ihrer faktischen Richtigkeit von größter Bedeutung. Dieses Projekt begegnet der Herausforderung von LLM-„Halluzinationen“, indem es den abstrakten Text des Modells in strukturiertem Wissen verankert und so effektiv als Wächter gegen Fehlinformationen fungiert.\n\n### Die Herausforderung\nObwohl LLMs unglaublich leistungsfähig sind, können sie aufgrund ihrer generativen Natur plausibel klingende, aber sachlich falsche Aussagen produzieren. Die zentrale Herausforderung bestand darin, eine automatisierte Pipeline zu entwickeln, die die Antwort eines LLMs systematisch dekonstruieren, ihre Behauptungen mit einer zuverlässigen Wissensdatenbank validieren und sie mit verifizierbaren Links anreichern kann – alles ohne menschliches Eingreifen. Dies erforderte einen pragmatischen Ansatz, der das semantische Verständnis neuronaler Modelle mit der strukturierten Gewissheit eines Wissensgraphen wie Wikidata kombiniert.\n\n### Hauptmerkmale\n*   **Integration mehrerer LLM-Modelle:** Generiert nahtlos Antworten durch Wrapper für Llama 2 und Llama 3, was Flexibilität und Leistungsvergleiche ermöglicht.\n*   **Fortgeschrittenes Entity Linking:** Identifiziert benannte Entitäten im Text und disambiguiert sie durch Verknüpfung mit der korrekten Wikipedia-Seite über einen mehrstufigen Prozess, der Popularität, Kontextähnlichkeit und Inter-Entitäten-Kohärenz berücksichtigt.\n*   **Präzise Antwortextraktion:** Klassifiziert den Typ der Benutzeranfrage (boolesch, Entität oder Aussage) und destilliert die oft ausführliche LLM-Ausgabe zu einer direkten, prägnanten Antwort (z. B. „Ja“, „Nein“ oder der Name einer Entität).\n*   **Wissensbasierte Faktenprüfung:** Konstruiert ein semantisches Tripel (Subjekt-Relation-Objekt) aus Frage und Antwort und fragt dann Wikidata ab, um zu überprüfen, ob diese Beziehung existiert, was eine robuste Überprüfung der faktischen Grundlage der Antwort ermöglicht.\n*   **Vollständig containerisierte Umgebung:** Nutzt Docker, um die gesamte Anwendung einschließlich aller Modelle und Abhängigkeiten zu paketieren, was vollständige Reproduzierbarkeit und eine einfache Einrichtung gewährleistet.\n\n### Technischer Einblick\nDas Projekt ist als eine sequenzielle Pipeline aufgebaut, bei der die Ausgabe jeder Stufe zur Eingabe für die nächste wird.\n\n**Antwortgenerierung & NLP-Pipeline:**\nDer Prozess beginnt damit, eine Frage an ein LLM (Llama 2 oder 3) über die `llama_cpp_python`-Bibliothek zu senden. Der resultierende Text wird dann durch eine Reihe von NLP-Modellen verarbeitet. Die anfängliche Klassifizierung der Frage wird von spezialisierten Transformer-Modellen (`shahrukhx01/question-vs-statement-classifier` und `PrimeQA/tydiqa-boolean-question-classifier`) übernommen, um das erwartete Antwortformat zu bestimmen.\n\n**Entity Linking & Disambiguierung:**\nDies ist der Kern der Verankerungsfähigkeit des Systems.\n1.  **Erkennung:** Entitäten werden zunächst mit `spaCy` und dem `dslim/bert-base-NER`-Modell für hohe Genauigkeit identifiziert.\n2.  **Kandidatengenerierung:** Für jede Entitätsnennung wird der SPARQL-Endpunkt von Wikidata abgefragt, um potenzielle Kandidatenentitäten zu erhalten, die nach Popularität geordnet sind.\n3.  **Disambiguierung:** Ein `DistilBERT`-Modell berechnet die Kosinus-Ähnlichkeit zwischen dem Embedding des Kontexts der Entität und dem Embedding des ersten Absatzes der Wikipedia-Seite jedes Kandidaten. Diese semantische Prüfung, kombiniert mit einer Heuristik für exakte Übereinstimmungen, löst Mehrdeutigkeiten effektiv auf (z. B. die Unterscheidung zwischen dem Apfel als Frucht und Apple Inc.).\n\n**Faktenprüfung & Verifizierung:**\nZur Validierung der endgültigen Antwort wird Stanford CoreNLP (`Stanza`) verwendet, um eine offene Informationsextraktion durchzuführen und die endgültige Aussage in ein relationales Tripel umzuwandeln. Dieses strukturierte Tripel wird dann verwendet, um Wikidata abzufragen. Das System prüft, ob eine Eigenschaft existiert, die das Subjekt und das Objekt verbindet. Wenn die Beziehung in der Wissensdatenbank bestätigt wird, wird die Antwort als „korrekt“ markiert.\n\n**Containerisierung & Umgebung:**\nDie gesamte Anwendung ist in einem `Dockerfile` definiert, das `karmaresearch/wdps2` als Basis-Image verwendet. Ein `setup.py`-Skript lädt alle erforderlichen Modelle (von Hugging Face und Stanza) vorab herunter und speichert sie im Docker-Image zwischen. Dadurch wird sichergestellt, dass die Umgebung autark und ohne weitere Downloads lauffähig ist.\n\n### Persönliche Lernerfolge\nDieses Projekt war ein tiefer Einblick in die Entwicklung einer komplexen, realitätsnahen NLP-Anwendung. Eine zentrale Erkenntnis war die Stärke der Kombination verschiedener KI-Paradigmen: die Nutzung der kreativen Texterstellungsfähigkeiten von LLMs bei gleichzeitiger Auferlegung der starren, faktischen Beschränkungen einer symbolischen Wissensdatenbank wie Wikidata. Ich habe bedeutende Erfahrungen im Management mehrerer vortrainierter Modelle, in der Orchestrierung einer mehrstufigen Datenverarbeitungspipeline und im Entwurf von Heuristiken zur Lösung komplexer Disambiguierungsprobleme gesammelt. Darüber hinaus war die Containerisierung einer ressourcenintensiven, modellabhängigen Anwendung mit Docker eine wertvolle Lektion in der Erstellung reproduzierbarer und portabler Data-Science-Lösungen.","projectType":"Data Science & NLP","developedAt":"2024-10-14","liveUrl":null,"repoUrl":"https://github.com/dettinjo/LLM-Fact-Auditor","tags":["Python","Docker","PyTorch","Transformers","spaCy","NLTK","Stanza","CoreNLP","LLM","Llama","NLP","Entity Linking","Fact-Checking","Wikidata","Data Processing"],"createdAt":"2025-10-14T20:26:26.842Z","updatedAt":"2025-10-15T19:25:08.677Z","publishedAt":"2025-10-15T19:25:08.805Z","locale":"de"}}
{"type":"api::software-project.software-project","id":184,"data":{"documentId":"kuo24gwolnshgs9zdr5n18nk","title":"LLM Fact Auditor","slug":"llm-fact-auditor","description":"A post-processing pipeline that fact-checks, entity-links, and verifies LLM answers to combat hallucinations and improve AI reliability.","longDescription":"### Project Overview\nThe LLM Fact Auditor is a sophisticated NLP system designed to act as a crucial verification layer for answers generated by Large Language Models (LLMs) like Llama 2 and 3. In an era where AI-generated content is becoming ubiquitous, ensuring its factual accuracy is paramount. This project addresses the challenge of LLM \"hallucinations\" by grounding the model's abstract text in structured knowledge, effectively serving as a sentinel against misinformation.\n\n### The Challenge\nWhile LLMs are incredibly powerful, their generative nature means they can produce plausible-sounding but factually incorrect statements. The core challenge was to build an automated pipeline that could systematically deconstruct an LLM's response, validate its claims against a reliable knowledge base, and enrich it with verifiable links, all without human intervention. This required a pragmatic approach, combining the semantic understanding of neural models with the structured certainty of a knowledge graph like Wikidata.\n\n### Key Features\n*   **Multi-Model LLM Integration:** Seamlessly generates answers using wrappers for both Llama 2 and Llama 3, allowing for flexibility and performance comparisons.\n*   **Advanced Entity Linking:** Identifies named entities in text and disambiguates them by linking to the correct Wikipedia page using a multi-step process involving popularity, context similarity, and inter-entity coherence.\n*   **Concise Answer Extraction:** Classifies the user's query type (boolean, entity, or statement) and distills the often verbose LLM output into a direct, concise answer (e.g., \"yes,\" \"no,\" or the name of an entity).\n*   **Knowledge-Based Fact-Checking:** Constructs a semantic triple (Subject-Relation-Object) from the question and answer, then queries Wikidata to verify if this relationship exists, providing a robust check on the answer's factual basis.\n*   **Fully Containerized Environment:** Utilizes Docker to package the entire application, including all models and dependencies, ensuring complete reproducibility and ease of setup.\n\n### Technical Deep Dive\nThe project is architected as a sequential pipeline where the output of each stage becomes the input for the next.\n\n**Answer Generation & NLP Pipeline:**\nThe process begins by feeding a question to an LLM (Llama 2 or 3) via the `llama_cpp_python` library. The resulting text is then processed through a series of NLP models. Initial question classification is handled by specialized Transformer models (`shahrukhx01/question-vs-statement-classifier` and `PrimeQA/tydiqa-boolean-question-classifier`) to determine the expected answer format.\n\n**Entity Linking & Disambiguation:**\nThis is the core of the system's grounding capability.\n1.  **Recognition:** Entities are first identified using `spaCy` and the `dslim/bert-base-NER` model for high accuracy.\n2.  **Candidate Generation:** For each entity mention, the Wikidata SPARQL endpoint is queried to retrieve potential candidate entities, ranked by popularity.\n3.  **Disambiguation:** A `DistilBERT` model calculates the cosine similarity between the embedding of the entity's context and the embedding of the first paragraph of each candidate's Wikipedia page. This semantic check, combined with an exact-match heuristic, effectively resolves ambiguity (e.g., distinguishing between Apple the fruit and Apple Inc.).\n\n**Fact-Checking & Verification:**\nTo validate the final answer, Stanford CoreNLP (`Stanza`) is used to perform open information extraction, converting the final statement into a relational triple. This structured triple is then used to query Wikidata. The system checks if a property linking the subject and object exists. If the relation is confirmed in the knowledge base, the answer is marked as \"correct.\"\n\n**Containerization & Environment:**\nThe entire application is defined in a `Dockerfile`, using `karmaresearch/wdps2` as a base image. A `setup.py` script pre-downloads and caches all required models (from Hugging Face and Stanza) into the Docker image, ensuring that the environment is self-contained and ready to run without requiring further downloads.\n\n### Personal Learnings\nThis project was a deep dive into building a complex, real-world NLP application. A key takeaway was the power of combining different AI paradigms: using the creative, text-generation capabilities of LLMs while imposing the rigid, factual constraints of a symbolic knowledge base like Wikidata. I gained significant experience in managing multiple pre-trained models, orchestrating a multi-stage data processing pipeline, and designing heuristics to solve complex disambiguation challenges. Furthermore, containerizing a heavy, model-dependent application with Docker was a valuable lesson in creating reproducible and portable data science solutions.\n","projectType":"Data Science & NLP","developedAt":"2024-10-14","liveUrl":null,"repoUrl":"https://github.com/dettinjo/LLM-Fact-Auditor","tags":["Python","Docker","PyTorch","Transformers","spaCy","NLTK","Stanza","CoreNLP","LLM","Llama","NLP","Entity Linking","Fact-Checking","Wikidata","Data Processing"],"createdAt":"2025-10-14T20:25:16.453Z","updatedAt":"2025-10-15T19:25:23.876Z","publishedAt":null,"locale":"en"}}
{"type":"api::software-project.software-project","id":185,"data":{"documentId":"kuo24gwolnshgs9zdr5n18nk","title":"LLM Fact Auditor","slug":"llm-fact-auditor","description":"A post-processing pipeline that fact-checks, entity-links, and verifies LLM answers to combat hallucinations and improve AI reliability.","longDescription":"### Project Overview\nThe LLM Fact Auditor is a sophisticated NLP system designed to act as a crucial verification layer for answers generated by Large Language Models (LLMs) like Llama 2 and 3. In an era where AI-generated content is becoming ubiquitous, ensuring its factual accuracy is paramount. This project addresses the challenge of LLM \"hallucinations\" by grounding the model's abstract text in structured knowledge, effectively serving as a sentinel against misinformation.\n\n### The Challenge\nWhile LLMs are incredibly powerful, their generative nature means they can produce plausible-sounding but factually incorrect statements. The core challenge was to build an automated pipeline that could systematically deconstruct an LLM's response, validate its claims against a reliable knowledge base, and enrich it with verifiable links, all without human intervention. This required a pragmatic approach, combining the semantic understanding of neural models with the structured certainty of a knowledge graph like Wikidata.\n\n### Key Features\n*   **Multi-Model LLM Integration:** Seamlessly generates answers using wrappers for both Llama 2 and Llama 3, allowing for flexibility and performance comparisons.\n*   **Advanced Entity Linking:** Identifies named entities in text and disambiguates them by linking to the correct Wikipedia page using a multi-step process involving popularity, context similarity, and inter-entity coherence.\n*   **Concise Answer Extraction:** Classifies the user's query type (boolean, entity, or statement) and distills the often verbose LLM output into a direct, concise answer (e.g., \"yes,\" \"no,\" or the name of an entity).\n*   **Knowledge-Based Fact-Checking:** Constructs a semantic triple (Subject-Relation-Object) from the question and answer, then queries Wikidata to verify if this relationship exists, providing a robust check on the answer's factual basis.\n*   **Fully Containerized Environment:** Utilizes Docker to package the entire application, including all models and dependencies, ensuring complete reproducibility and ease of setup.\n\n### Technical Deep Dive\nThe project is architected as a sequential pipeline where the output of each stage becomes the input for the next.\n\n**Answer Generation & NLP Pipeline:**\nThe process begins by feeding a question to an LLM (Llama 2 or 3) via the `llama_cpp_python` library. The resulting text is then processed through a series of NLP models. Initial question classification is handled by specialized Transformer models (`shahrukhx01/question-vs-statement-classifier` and `PrimeQA/tydiqa-boolean-question-classifier`) to determine the expected answer format.\n\n**Entity Linking & Disambiguation:**\nThis is the core of the system's grounding capability.\n1.  **Recognition:** Entities are first identified using `spaCy` and the `dslim/bert-base-NER` model for high accuracy.\n2.  **Candidate Generation:** For each entity mention, the Wikidata SPARQL endpoint is queried to retrieve potential candidate entities, ranked by popularity.\n3.  **Disambiguation:** A `DistilBERT` model calculates the cosine similarity between the embedding of the entity's context and the embedding of the first paragraph of each candidate's Wikipedia page. This semantic check, combined with an exact-match heuristic, effectively resolves ambiguity (e.g., distinguishing between Apple the fruit and Apple Inc.).\n\n**Fact-Checking & Verification:**\nTo validate the final answer, Stanford CoreNLP (`Stanza`) is used to perform open information extraction, converting the final statement into a relational triple. This structured triple is then used to query Wikidata. The system checks if a property linking the subject and object exists. If the relation is confirmed in the knowledge base, the answer is marked as \"correct.\"\n\n**Containerization & Environment:**\nThe entire application is defined in a `Dockerfile`, using `karmaresearch/wdps2` as a base image. A `setup.py` script pre-downloads and caches all required models (from Hugging Face and Stanza) into the Docker image, ensuring that the environment is self-contained and ready to run without requiring further downloads.\n\n### Personal Learnings\nThis project was a deep dive into building a complex, real-world NLP application. A key takeaway was the power of combining different AI paradigms: using the creative, text-generation capabilities of LLMs while imposing the rigid, factual constraints of a symbolic knowledge base like Wikidata. I gained significant experience in managing multiple pre-trained models, orchestrating a multi-stage data processing pipeline, and designing heuristics to solve complex disambiguation challenges. Furthermore, containerizing a heavy, model-dependent application with Docker was a valuable lesson in creating reproducible and portable data science solutions.\n","projectType":"Data Science & NLP","developedAt":"2024-10-14","liveUrl":null,"repoUrl":"https://github.com/dettinjo/LLM-Fact-Auditor","tags":["Python","Docker","PyTorch","Transformers","spaCy","NLTK","Stanza","CoreNLP","LLM","Llama","NLP","Entity Linking","Fact-Checking","Wikidata","Data Processing"],"createdAt":"2025-10-14T20:25:16.453Z","updatedAt":"2025-10-15T19:25:23.876Z","publishedAt":"2025-10-15T19:25:24.079Z","locale":"en"}}
{"type":"api::software-project.software-project","id":186,"data":{"documentId":"su97xkvo45rcwnl7u1cr2f9e","title":"Link24 - Full-Stack URL-Shortener","slug":"link24-full-stack-url-shortener1","description":"Full-Stack URL-Shortener mit Node.js API und Next.js Frontend. Bietet sichere Benutzer-Authentifizierung, Link-Management und eine vollständige CI/CD-Pipeline mit Docker.","longDescription":"### Projektübersicht\nLink24 ist ein umfassender Full-Stack-URL-Verkürzungsdienst, der sowohl anonymen als auch registrierten Benutzern eine nahtlose Verwaltung von Links ermöglicht. Während anonyme Benutzer schnell temporäre Kurzlinks erstellen können, schalten registrierte Benutzer eine Reihe leistungsstarker Funktionen frei, darunter ein persönliches Dashboard mit Link-Verlauf, benutzerdefinierte Slugs, die Verwaltung von Ablaufdaten und Klick-Tracking. Das Projekt ist als entkoppeltes System mit einem Next.js-Frontend, einem Node.js/Express-Backend-API und einer MongoDB-Datenbank aufgebaut, die alle für Skalierbarkeit und einfache Bereitstellung mit Docker containerisiert sind.\n\n### Die Herausforderung\nDie primäre Herausforderung bestand darin, eine sichere, skalierbare und vielseitige Webanwendung von Grund auf zu konzipieren und zu erstellen. Dies umfasste die Entwicklung einer zustandslosen REST-API mit sicherer JWT-basierter Authentifizierung, die Erstellung einer intuitiven und responsiven Benutzeroberfläche mit React und Next.js sowie die Etablierung eines robusten DevOps-Workflows. Ein zentrales architektonisches Ziel war es, die Unabhängigkeit der Dienste zu gewährleisten und die Test- und Build-Prozesse mithilfe einer CI/CD-Pipeline zu automatisieren.\n\n### Hauptmerkmale\n*   **Benutzerauthentifizierung:** Sicheres Registrierungs- und Anmeldesystem für Benutzer unter Verwendung von JWT und bcrypt zum Hashen von Passwörtern.\n*   **Öffentliche Link-Verkürzung:** Anonyme Benutzer können Kurzlinks mit einem zufällig generierten Slug und einer standardmäßigen Gültigkeitsdauer von 30 Tagen erstellen.\n*   **Dashboard für authentifizierte Benutzer:** Angemeldete Benutzer haben Zugriff auf einen Verlauf all ihrer erstellten Links.\n*   **Benutzerdefiniertes Link-Management:** Benutzer können benutzerdefinierte, lesbare Slugs für ihre Kurzlinks definieren.\n*   **Steuerung des Ablaufdatums:** Authentifizierte Benutzer können für jeden Link eine individuelle Gültigkeitsdauer festlegen.\n*   **CRUD-Operationen:** Umfassende Möglichkeiten zum Erstellen, Lesen, Aktualisieren und Löschen persönlicher Links.\n*   **Klick-Tracking:** Das System zählt und zeigt die Anzahl der Klicks an, die jeder Kurzlink erhält.\n\n### Technischer Einblick\n**Frontend**\nDie Benutzeroberfläche wurde mit **Next.js** und **React** erstellt, was eine schnelle, serverseitig gerenderte Anwendung ermöglicht. Die komponentenbasierte Architektur sorgt für eine wartbare und wiederverwendbare Codebasis. **Tailwind CSS** wurde für schnelles, Utility-First-Styling verwendet, was die Erstellung eines modernen und responsiven Designs ermöglichte. End-to-End-Tests wurden mit **Cypress** implementiert, um die Zuverlässigkeit kritischer Benutzerabläufe wie Registrierung, Anmeldung und Link-Erstellung zu gewährleisten.\n\n**Backend**\nDas Backend ist eine RESTful-API, die auf **Node.js** und **Express.js** basiert. Es folgt einer klaren, serviceorientierten Architektur, die Routing, Controller-Logik und Geschäftslogik für Übersichtlichkeit und Testbarkeit trennt. **Mongoose** dient als ODM zur Interaktion mit der **MongoDB**-Datenbank und modelliert Benutzer- und Link-Daten. Die Sicherheit der Benutzer hat höchste Priorität, wobei **JWT** für die Verwaltung der zustandslosen Authentifizierung und **bcrypt** für das sichere Hashen von Passwörtern verwendet wird. Eine clevere Nutzung des TTL (Time-To-Live)-Index von MongoDB für das `expiresAt`-Feld automatisiert das Löschen abgelaufener Links und sorgt für eine effiziente Datenverwaltung. Die API ist gründlich mit **Jest** und **Supertest** getestet.\n\n**DevOps/Deployment**\nDie gesamte Anwendung ist mit **Docker** containerisiert und wird mit **Docker Compose** orchestriert. Dieses Setup definiert drei unabhängige Dienste (`frontend`, `backend`, `database`), was die Entwicklungsumgebung vereinfacht und die Anwendung portabel und einfach bereitzustellen macht. Eine **GitLab CI**-Pipeline (`.gitlab-ci.yml`) automatisiert den gesamten CI/CD-Prozess. Bei jedem Push installiert die Pipeline automatisch Abhängigkeiten, führt die Backend- und Frontend-Testsuiten aus und erstellt die Anwendungen, wodurch sichergestellt wird, dass Codequalität und Integration kontinuierlich überprüft werden.\n\n### Persönliche Lernerfolge\nDieses Projekt war ein unglaublich tiefer Einblick in die Full-Stack-Entwicklung und moderne DevOps-Praktiken. Ich habe bedeutende Erfahrungen in der Konzeption und Erstellung sicherer REST-APIs mit Node.js gesammelt, einschließlich der Implementierung robuster Authentifizierungs- und Datenvalidierungsmechanismen. Die Arbeit mit Next.js und React festigte meine Frontend-Fähigkeiten, insbesondere im State Management und im Aufbau responsiver UIs. Der wertvollste Lernerfolg war die Implementierung eines vollständigen CI/CD-Workflows mit Docker und GitLab CI, was mir die Bedeutung von Containerisierung und Automatisierung beim Erstellen zuverlässiger und skalierbarer Software verdeutlichte.\n","projectType":"Full-Stack Web Application","developedAt":"2022-06-14","liveUrl":null,"repoUrl":"https://github.com/dettinjo/Link24","tags":["Node.js","React","Next.js","MongoDB","Docker","Full-Stack","REST API","CI/CD","Express.js","JWT"],"createdAt":"2025-10-14T17:35:41.527Z","updatedAt":"2025-10-15T19:18:31.255Z","publishedAt":null,"locale":"de"}}
{"type":"api::software-project.software-project","id":187,"data":{"documentId":"su97xkvo45rcwnl7u1cr2f9e","title":"Link24 - Full-Stack URL-Shortener","slug":"link24-full-stack-url-shortener1","description":"Full-Stack URL-Shortener mit Node.js API und Next.js Frontend. Bietet sichere Benutzer-Authentifizierung, Link-Management und eine vollständige CI/CD-Pipeline mit Docker.","longDescription":"### Projektübersicht\nLink24 ist ein umfassender Full-Stack-URL-Verkürzungsdienst, der sowohl anonymen als auch registrierten Benutzern eine nahtlose Verwaltung von Links ermöglicht. Während anonyme Benutzer schnell temporäre Kurzlinks erstellen können, schalten registrierte Benutzer eine Reihe leistungsstarker Funktionen frei, darunter ein persönliches Dashboard mit Link-Verlauf, benutzerdefinierte Slugs, die Verwaltung von Ablaufdaten und Klick-Tracking. Das Projekt ist als entkoppeltes System mit einem Next.js-Frontend, einem Node.js/Express-Backend-API und einer MongoDB-Datenbank aufgebaut, die alle für Skalierbarkeit und einfache Bereitstellung mit Docker containerisiert sind.\n\n### Die Herausforderung\nDie primäre Herausforderung bestand darin, eine sichere, skalierbare und vielseitige Webanwendung von Grund auf zu konzipieren und zu erstellen. Dies umfasste die Entwicklung einer zustandslosen REST-API mit sicherer JWT-basierter Authentifizierung, die Erstellung einer intuitiven und responsiven Benutzeroberfläche mit React und Next.js sowie die Etablierung eines robusten DevOps-Workflows. Ein zentrales architektonisches Ziel war es, die Unabhängigkeit der Dienste zu gewährleisten und die Test- und Build-Prozesse mithilfe einer CI/CD-Pipeline zu automatisieren.\n\n### Hauptmerkmale\n*   **Benutzerauthentifizierung:** Sicheres Registrierungs- und Anmeldesystem für Benutzer unter Verwendung von JWT und bcrypt zum Hashen von Passwörtern.\n*   **Öffentliche Link-Verkürzung:** Anonyme Benutzer können Kurzlinks mit einem zufällig generierten Slug und einer standardmäßigen Gültigkeitsdauer von 30 Tagen erstellen.\n*   **Dashboard für authentifizierte Benutzer:** Angemeldete Benutzer haben Zugriff auf einen Verlauf all ihrer erstellten Links.\n*   **Benutzerdefiniertes Link-Management:** Benutzer können benutzerdefinierte, lesbare Slugs für ihre Kurzlinks definieren.\n*   **Steuerung des Ablaufdatums:** Authentifizierte Benutzer können für jeden Link eine individuelle Gültigkeitsdauer festlegen.\n*   **CRUD-Operationen:** Umfassende Möglichkeiten zum Erstellen, Lesen, Aktualisieren und Löschen persönlicher Links.\n*   **Klick-Tracking:** Das System zählt und zeigt die Anzahl der Klicks an, die jeder Kurzlink erhält.\n\n### Technischer Einblick\n**Frontend**\nDie Benutzeroberfläche wurde mit **Next.js** und **React** erstellt, was eine schnelle, serverseitig gerenderte Anwendung ermöglicht. Die komponentenbasierte Architektur sorgt für eine wartbare und wiederverwendbare Codebasis. **Tailwind CSS** wurde für schnelles, Utility-First-Styling verwendet, was die Erstellung eines modernen und responsiven Designs ermöglichte. End-to-End-Tests wurden mit **Cypress** implementiert, um die Zuverlässigkeit kritischer Benutzerabläufe wie Registrierung, Anmeldung und Link-Erstellung zu gewährleisten.\n\n**Backend**\nDas Backend ist eine RESTful-API, die auf **Node.js** und **Express.js** basiert. Es folgt einer klaren, serviceorientierten Architektur, die Routing, Controller-Logik und Geschäftslogik für Übersichtlichkeit und Testbarkeit trennt. **Mongoose** dient als ODM zur Interaktion mit der **MongoDB**-Datenbank und modelliert Benutzer- und Link-Daten. Die Sicherheit der Benutzer hat höchste Priorität, wobei **JWT** für die Verwaltung der zustandslosen Authentifizierung und **bcrypt** für das sichere Hashen von Passwörtern verwendet wird. Eine clevere Nutzung des TTL (Time-To-Live)-Index von MongoDB für das `expiresAt`-Feld automatisiert das Löschen abgelaufener Links und sorgt für eine effiziente Datenverwaltung. Die API ist gründlich mit **Jest** und **Supertest** getestet.\n\n**DevOps/Deployment**\nDie gesamte Anwendung ist mit **Docker** containerisiert und wird mit **Docker Compose** orchestriert. Dieses Setup definiert drei unabhängige Dienste (`frontend`, `backend`, `database`), was die Entwicklungsumgebung vereinfacht und die Anwendung portabel und einfach bereitzustellen macht. Eine **GitLab CI**-Pipeline (`.gitlab-ci.yml`) automatisiert den gesamten CI/CD-Prozess. Bei jedem Push installiert die Pipeline automatisch Abhängigkeiten, führt die Backend- und Frontend-Testsuiten aus und erstellt die Anwendungen, wodurch sichergestellt wird, dass Codequalität und Integration kontinuierlich überprüft werden.\n\n### Persönliche Lernerfolge\nDieses Projekt war ein unglaublich tiefer Einblick in die Full-Stack-Entwicklung und moderne DevOps-Praktiken. Ich habe bedeutende Erfahrungen in der Konzeption und Erstellung sicherer REST-APIs mit Node.js gesammelt, einschließlich der Implementierung robuster Authentifizierungs- und Datenvalidierungsmechanismen. Die Arbeit mit Next.js und React festigte meine Frontend-Fähigkeiten, insbesondere im State Management und im Aufbau responsiver UIs. Der wertvollste Lernerfolg war die Implementierung eines vollständigen CI/CD-Workflows mit Docker und GitLab CI, was mir die Bedeutung von Containerisierung und Automatisierung beim Erstellen zuverlässiger und skalierbarer Software verdeutlichte.\n","projectType":"Full-Stack Web Application","developedAt":"2022-06-14","liveUrl":null,"repoUrl":"https://github.com/dettinjo/Link24","tags":["Node.js","React","Next.js","MongoDB","Docker","Full-Stack","REST API","CI/CD","Express.js","JWT"],"createdAt":"2025-10-14T17:35:41.527Z","updatedAt":"2025-10-15T19:18:31.255Z","publishedAt":"2025-10-15T19:18:31.313Z","locale":"de"}}
{"type":"api::software-project.software-project","id":188,"data":{"documentId":"su97xkvo45rcwnl7u1cr2f9e","title":"Link24 - Full-Stack URL Shortener","slug":"link24-full-stack-url-shortener","description":"A full-stack URL shortener with a Node.js API and Next.js frontend. Features secure user authentication, custom link management, and a complete CI/CD pipeline using Docker.","longDescription":"### Project Overview\nLink24 is a comprehensive, full-stack URL shortening service designed to provide both anonymous and registered users with a seamless link management experience. While anonymous users can quickly generate temporary short links, registered users unlock a suite of powerful features, including a personal dashboard with link history, custom slugs, expiration date management, and click tracking. The project is architected as a decoupled system with a Next.js frontend, a Node.js/Express backend API, and a MongoDB database, all containerized with Docker for scalability and ease of deployment.\n\n### The Challenge\nThe primary challenge was to design and build a secure, scalable, and multi-featured web application from the ground up. This involved creating a stateless REST API with secure JWT-based authentication, developing an intuitive and responsive user interface with React and Next.js, and establishing a robust DevOps workflow. A key architectural goal was to ensure service independence and automate the testing and build processes using a CI/CD pipeline.\n\n### Key Features\n*   **User Authentication:** Secure user registration and login system using JWT and bcrypt for password hashing.\n*   **Public Link Shortening:** Anonymous users can create short links with a randomly generated slug and a default 30-day expiration.\n*   **Authenticated User Dashboard:** Logged-in users have access to a history of all their created links.\n*   **Custom Link Management:** Users can define custom, human-readable slugs for their short links.\n*   **Expiration Date Control:** Authenticated users can set a custom expiration period for each link.\n*   **CRUD Operations:** Full capabilities to create, read, update, and delete personal links.\n*   **Click Tracking:** The system counts and displays the number of clicks each short link receives.\n\n### Technical Deep Dive\n**Frontend**\nThe user interface was built with **Next.js** and **React**, creating a fast, server-rendered application. The component-based architecture ensures a maintainable and reusable codebase. **Tailwind CSS** was utilized for rapid, utility-first styling, enabling the creation of a modern and responsive design. End-to-end testing was implemented with **Cypress** to guarantee the reliability of critical user flows like registration, login, and link creation.\n\n**Backend**\nThe backend is a RESTful API powered by **Node.js** and **Express.js**. It follows a clean, service-oriented architecture, separating routing, controller logic, and business logic for clarity and testability. **Mongoose** serves as the ODM to interact with the **MongoDB** database, modeling user and link data. User security is paramount, with **JWT** for managing stateless authentication and **bcrypt** for securely hashing passwords. A clever use of MongoDB's TTL (Time-To-Live) index on the `expiresAt` field automates the deletion of expired links, ensuring efficient data management. The API is thoroughly tested with **Jest** and **Supertest**.\n\n**DevOps/Deployment**\nThe entire application is containerized using **Docker** and orchestrated with **Docker Compose**. This setup defines three independent services (`frontend`, `backend`, `database`), simplifying the development environment and making the application portable and easy to deploy. A **GitLab CI** pipeline (`.gitlab-ci.yml`) automates the entire CI/CD process. On every push, the pipeline automatically installs dependencies, runs the backend and frontend test suites, and builds the applications, ensuring code quality and integration are continuously verified.\n\n### Personal Learnings\nThis project was an incredible deep dive into full-stack development and modern DevOps practices. I gained significant experience in designing and building secure REST APIs with Node.js, including implementing robust authentication and data validation. Working with Next.js and React solidified my frontend skills, particularly in state management and building responsive UIs. The most valuable takeaway was implementing a complete CI/CD workflow with Docker and GitLab CI, which taught me the importance of containerization and automation in building reliable and scalable software.","projectType":"Full-Stack Web Application","developedAt":"2022-06-01","liveUrl":null,"repoUrl":"https://github.com/dettinjo/Link24","tags":["Node.js","React","Next.js","MongoDB","Docker","Full-Stack","REST API","CI/CD","Express.js","JWT"],"createdAt":"2025-10-14T17:33:01.463Z","updatedAt":"2025-10-15T19:18:16.324Z","publishedAt":null,"locale":"en"}}
{"type":"api::software-project.software-project","id":189,"data":{"documentId":"su97xkvo45rcwnl7u1cr2f9e","title":"Link24 - Full-Stack URL Shortener","slug":"link24-full-stack-url-shortener","description":"A full-stack URL shortener with a Node.js API and Next.js frontend. Features secure user authentication, custom link management, and a complete CI/CD pipeline using Docker.","longDescription":"### Project Overview\nLink24 is a comprehensive, full-stack URL shortening service designed to provide both anonymous and registered users with a seamless link management experience. While anonymous users can quickly generate temporary short links, registered users unlock a suite of powerful features, including a personal dashboard with link history, custom slugs, expiration date management, and click tracking. The project is architected as a decoupled system with a Next.js frontend, a Node.js/Express backend API, and a MongoDB database, all containerized with Docker for scalability and ease of deployment.\n\n### The Challenge\nThe primary challenge was to design and build a secure, scalable, and multi-featured web application from the ground up. This involved creating a stateless REST API with secure JWT-based authentication, developing an intuitive and responsive user interface with React and Next.js, and establishing a robust DevOps workflow. A key architectural goal was to ensure service independence and automate the testing and build processes using a CI/CD pipeline.\n\n### Key Features\n*   **User Authentication:** Secure user registration and login system using JWT and bcrypt for password hashing.\n*   **Public Link Shortening:** Anonymous users can create short links with a randomly generated slug and a default 30-day expiration.\n*   **Authenticated User Dashboard:** Logged-in users have access to a history of all their created links.\n*   **Custom Link Management:** Users can define custom, human-readable slugs for their short links.\n*   **Expiration Date Control:** Authenticated users can set a custom expiration period for each link.\n*   **CRUD Operations:** Full capabilities to create, read, update, and delete personal links.\n*   **Click Tracking:** The system counts and displays the number of clicks each short link receives.\n\n### Technical Deep Dive\n**Frontend**\nThe user interface was built with **Next.js** and **React**, creating a fast, server-rendered application. The component-based architecture ensures a maintainable and reusable codebase. **Tailwind CSS** was utilized for rapid, utility-first styling, enabling the creation of a modern and responsive design. End-to-end testing was implemented with **Cypress** to guarantee the reliability of critical user flows like registration, login, and link creation.\n\n**Backend**\nThe backend is a RESTful API powered by **Node.js** and **Express.js**. It follows a clean, service-oriented architecture, separating routing, controller logic, and business logic for clarity and testability. **Mongoose** serves as the ODM to interact with the **MongoDB** database, modeling user and link data. User security is paramount, with **JWT** for managing stateless authentication and **bcrypt** for securely hashing passwords. A clever use of MongoDB's TTL (Time-To-Live) index on the `expiresAt` field automates the deletion of expired links, ensuring efficient data management. The API is thoroughly tested with **Jest** and **Supertest**.\n\n**DevOps/Deployment**\nThe entire application is containerized using **Docker** and orchestrated with **Docker Compose**. This setup defines three independent services (`frontend`, `backend`, `database`), simplifying the development environment and making the application portable and easy to deploy. A **GitLab CI** pipeline (`.gitlab-ci.yml`) automates the entire CI/CD process. On every push, the pipeline automatically installs dependencies, runs the backend and frontend test suites, and builds the applications, ensuring code quality and integration are continuously verified.\n\n### Personal Learnings\nThis project was an incredible deep dive into full-stack development and modern DevOps practices. I gained significant experience in designing and building secure REST APIs with Node.js, including implementing robust authentication and data validation. Working with Next.js and React solidified my frontend skills, particularly in state management and building responsive UIs. The most valuable takeaway was implementing a complete CI/CD workflow with Docker and GitLab CI, which taught me the importance of containerization and automation in building reliable and scalable software.","projectType":"Full-Stack Web Application","developedAt":"2022-06-01","liveUrl":null,"repoUrl":"https://github.com/dettinjo/Link24","tags":["Node.js","React","Next.js","MongoDB","Docker","Full-Stack","REST API","CI/CD","Express.js","JWT"],"createdAt":"2025-10-14T17:33:01.463Z","updatedAt":"2025-10-15T19:18:16.324Z","publishedAt":"2025-10-15T19:18:16.394Z","locale":"en"}}
{"type":"api::software-project.software-project","id":190,"data":{"documentId":"ws6tkh7iwt99vl26obky3c1p","title":"Dynamic Dual-Portfolio Website","slug":"dynamic-dual-portfolio-website","description":"A complete portfolio platform built as a monorepo. It features distinct, multi-domain sites for software and photography, with all content dynamically managed by a headless Strapi CMS.","longDescription":"### Project Overview\n\nThis project is the very portfolio you are browsing now. It was conceived as a \"hub-and-spoke\" platform to professionally showcase two distinct skill sets—software development and photography—under a single, cohesive brand. The architecture is a modern monorepo containing a headless Strapi backend and a multi-domain Next.js frontend.\n\n### Core Features\n\n*   **Multi-Domain Routing:** The application intelligently serves different content based on the domain name (`codeby.joeldettinger.de` for software, `photosby.joeldettinger.de` for photography) using Next.js Middleware.\n*   **Headless CMS Integration:** All project details, skill listings, photo albums, and testimonials are dynamically fetched from a self-hosted Strapi CMS, allowing for easy content updates without code changes.\n*   **Full Internationalization (i18n):** The entire user interface, including all content from the CMS, is available in both English and German, with locale detection based on browser settings and a manual language switcher.\n*   **Custom Strapi Controllers:** The backend features custom controllers, such as for the testimonial submission form, which integrates Google reCAPTCHA for spam protection and custom logic for organizing file uploads into specific media library folders.\n*   **Dynamic Theming:** A \"Paper-like\" design with full support for system, light, and dark modes, built with Tailwind CSS and `next-themes`.\n\n### Technical Challenges & Solutions\n\nOne of the main challenges was creating a seamless local development experience that could accurately simulate the multi-domain production environment. This was solved by implementing a `DEV_FORCE_DOMAIN` environment variable that instructs the Next.js Middleware to route `localhost` traffic as if it were coming from a specific subdomain.\n\nAnother challenge was handling file uploads from a public-facing form. This required careful configuration of Strapi's user roles, permissions for the upload plugin, and a custom controller to validate the request before passing the file to Strapi's upload service.","projectType":"Full-Stack Web Application","developedAt":"2025-10-10","liveUrl":"https://joeldettinger.de","repoUrl":"https://github.com/dettinjo/portfolio-landing","tags":["Next.js","React","Strapi","TypeScript","Tailwind CSS","next-intl","Framer Motion"],"createdAt":"2025-10-10T16:12:12.511Z","updatedAt":"2025-11-18T12:51:59.396Z","publishedAt":null,"locale":"en"}}
{"type":"api::software-project.software-project","id":191,"data":{"documentId":"wter97phm86awuqqfbpfnnvh","title":"Automatisierte Wiederherstellung der IT-Infrastruktur mit Terraform","slug":"automatisierte-wiederherstellung-der-it-infrastruktur-mit-terraform","description":"Ein IaC-Projekt mit Terraform zur automatisierten Notfallwiederherstellung von Cloud-Infrastruktur auf Azure und GitLab, mit modularem Design für schnelles Deployment.","longDescription":"### Projektübersicht\nDieses Projekt war das Thema einer Bachelorarbeit, die sich auf die Evaluierung und Implementierung einer automatisierten Disaster-Recovery-Lösung für IT-Infrastruktur mittels Infrastructure as Code (IaC) konzentrierte. Das Hauptziel war, einen Prototyp zu entwerfen und zu bauen, der eine grundlegende Cloud-Umgebung nach einem vollständigen Systemausfall schnell und zuverlässig wiederherstellen kann. Die Lösung nutzt Terraform, um den gesamten Bereitstellungs- und Konfigurationsprozess zu automatisieren, was Konsistenz gewährleistet und manuelle Eingriffe während eines kritischen Wiederherstellungsprozesses erheblich reduziert.\n\n### Die Herausforderung\nDas Projekt befasste sich mit einem komplexen „Henne-Ei-Problem“, das auf den hohen Sicherheitsstandards eines Kundenprojekts basierte, welches einem Zero-Trust-Sicherheitsmodell folgte. Den bestehenden CI/CD-Runnern war es nicht gestattet, die Wiederherstellungsinfrastruktur von außerhalb der Umgebung bereitzustellen, da dies vertrauliche Daten und Endpunkte exponieren würde. Dies führte zu einer Blockade: Um die sichere, interne Infrastruktur aufzubauen, wurde ein interner GitLab Runner benötigt, aber um diesen Runner zu erstellen, musste zuerst die Infrastruktur aufgebaut werden. Die Herausforderung bestand darin, einen vollständig automatisierten Bootstrapping-Prozess zu entwickeln, der dieses initiale, sichere Fundament – einschließlich des GitLab Runners selbst – von einem lokalen Rechner aus erstellen konnte, um so die prozedurale Sackgasse zu lösen und den sicheren Aufbau der restlichen Infrastruktur von innen heraus zu ermöglichen.\n\n### Hauptmerkmale\n*   **Automatisierte Infrastrukturbereitstellung:** Nutzt Terraform zur deklarativen Definition und Erstellung aller notwendigen Azure-Ressourcen, einschließlich eines virtuellen Netzwerks (VNet) in einer Hub-and-Spoke-Topologie, Subnetzen, einer virtuellen Maschine und eines sicheren Bastion-Hosts.\n*   **Dynamische GitLab-Runner-Konfiguration:** Verwendet `cloud-init`, um die bereitgestellte VM beim ersten Start automatisch zu konfigurieren. Dies umfasst die Installation von Docker und des GitLab Runners, die Registrierung des neuen Runners bei der angegebenen GitLab-Gruppe unter Verwendung dynamischer Anmeldeinformationen sowie die Einrichtung von systemd-Diensten zur automatisierten Wartung und Bereinigung.\n*   **GitLab-Integration:** Der Terraform-Plan erstellt automatisch eine neue GitLab-Gruppe und füllt sie mit Projekten, indem lokale Repositories gepusht werden. Dadurch stehen der Infrastruktur- und Anwendungscode dem neu erstellten Runner sofort zur Verfügung, um seine Pipelines auszuführen.\n*   **Modulare und wiederverwendbare Architektur:** Der Terraform-Code ist in drei Schichten strukturiert: Core (grundlegende Ressourcendefinitionen), Standard Building Blocks (SBBs – Kombination von Core-Modulen zur Einhaltung von Richtlinien) und Exposed Modules (die endgültige, bereitstellbare Lösung). Dieses Muster fördert Wiederverwendbarkeit, Wartbarkeit und die strikte Einhaltung von Unternehmensstandards.\n*   **Zwei Bereitstellungsmodi:** Das System ist flexibel gestaltet. Es unterstützt die lokale Ausführung über einfache Shell-Skripte (`apply.sh`, `destroy.sh`) für das initiale Disaster-Recovery-Szenario. Zusätzlich enthält es eine vollständig konfigurierte GitLab CI/CD-Pipeline für die Remote-Ausführung, die die Validierung, das Testen und die laufende Verwaltung der Infrastruktur ermöglicht.\n*   **Sicherheit durch Design:** Implementiert den sicheren Zugriff auf die Runner-VM über Azure Bastion, wodurch öffentliche IP-Adressen und exponierte SSH-Ports vermieden werden. Netzwerksicherheitsgruppen (NSGs) werden verwendet, um strikte Firewall-Regeln für ein- und ausgehenden Verkehr durchzusetzen und so eine gehärtete Umgebung vom ersten Moment an zu gewährleisten.\n\n### Technischer Einblick\n*   **Infrastructure as Code (IaC):** Die gesamte Cloud-Umgebung wird mit **Terraform** definiert, wobei **Terragrunt** als schlanker Wrapper dient, um die Konfiguration DRY (Don't Repeat Yourself) zu halten und den Remote State zu verwalten. Dieser deklarative Ansatz stellt sicher, dass die Infrastruktur in Git versioniert, wiederholbar und leicht überprüfbar ist. Das modulare Design ermöglicht es Entwicklern, komplexe Infrastrukturen einfach aus vorab genehmigten, konformen Bausteinen zusammenzusetzen.\n\n*   **Automatisierung & Bereitstellung:** Für den primären Disaster-Recovery-Anwendungsfall bieten einfache **Shell-Skripte** eine Ein-Befehl-Schnittstelle zur Bereitstellung des gesamten Fundaments. Für die kontinuierliche Integration und Validierung orchestriert eine umfassende `.gitlab-ci.yml`-Datei den Prozess remote. Diese Pipeline umfasst Stufen für Linting, Validierung, Planung und Anwendung von Änderungen, mit manuellen Freigaben für destruktive Aktionen, um eine versehentliche Entfernung der Infrastruktur zu verhindern.\n\n*   **Konfigurationsmanagement:** Die virtuelle Maschine für den GitLab Runner wird mithilfe einer `cloud-init`-Konfigurationsdatei gebootstrappt. Terraform füllt diese Datei dynamisch mit Variablen (wie GitLab-Registrierungstoken und Runner-Tags), bevor sie an die Azure-API übergeben wird. Diese leistungsstarke Technik stellt sicher, dass die VM bei ihrem ersten Start vollständig konfiguriert und betriebsbereit ist, ohne dass ein manueller SSH-Zugriff oder eine Konfiguration erforderlich ist.\n\n### Persönliche Lernerfolge\nDiese Bachelorarbeit bot eine tiefgreifende, praxisnahe Erfahrung bei der Lösung einer kritischen, realen DevOps-Herausforderung in einem hochsicheren Unternehmenskontext. Ich ging über grundlegende IaC-Prinzipien hinaus, um eine anspruchsvolle, mehrschichtige Terraform-Architektur zu entwerfen, die Wiederverwendbarkeit und Konformität in den Vordergrund stellt. Die zentrale Herausforderung lehrte mich, Lösungen zu entwickeln, die prozedurale Blockaden elegant überwinden und einen manuellen, fehleranfälligen Prozess in ein vollautomatisches, zuverlässiges System verwandeln. Zudem vertiefte ich meine Expertise in der Erstellung von CI/CD-Pipelines, cloud-init und Shell-Scripting und lieferte letztlich eine umfassende Lösung, die als robuster Entwurf für die Automatisierung der Notfallwiederherstellung dient.","projectType":"DevOps & IaC","developedAt":"2023-07-24","liveUrl":null,"repoUrl":null,"tags":["Terraform","Terragrunt","Infrastructure as Code (IaC)","Microsoft Azure","GitLab","GitLab CI/CD","Shell Scripting","DevOps","Cloud Infrastructure","Automation"],"createdAt":"2025-10-14T17:51:14.405Z","updatedAt":"2025-10-15T19:07:01.589Z","publishedAt":null,"locale":"de"}}
{"type":"api::software-project.software-project","id":192,"data":{"documentId":"wter97phm86awuqqfbpfnnvh","title":"Automatisierte Wiederherstellung der IT-Infrastruktur mit Terraform","slug":"automatisierte-wiederherstellung-der-it-infrastruktur-mit-terraform","description":"Ein IaC-Projekt mit Terraform zur automatisierten Notfallwiederherstellung von Cloud-Infrastruktur auf Azure und GitLab, mit modularem Design für schnelles Deployment.","longDescription":"### Projektübersicht\nDieses Projekt war das Thema einer Bachelorarbeit, die sich auf die Evaluierung und Implementierung einer automatisierten Disaster-Recovery-Lösung für IT-Infrastruktur mittels Infrastructure as Code (IaC) konzentrierte. Das Hauptziel war, einen Prototyp zu entwerfen und zu bauen, der eine grundlegende Cloud-Umgebung nach einem vollständigen Systemausfall schnell und zuverlässig wiederherstellen kann. Die Lösung nutzt Terraform, um den gesamten Bereitstellungs- und Konfigurationsprozess zu automatisieren, was Konsistenz gewährleistet und manuelle Eingriffe während eines kritischen Wiederherstellungsprozesses erheblich reduziert.\n\n### Die Herausforderung\nDas Projekt befasste sich mit einem komplexen „Henne-Ei-Problem“, das auf den hohen Sicherheitsstandards eines Kundenprojekts basierte, welches einem Zero-Trust-Sicherheitsmodell folgte. Den bestehenden CI/CD-Runnern war es nicht gestattet, die Wiederherstellungsinfrastruktur von außerhalb der Umgebung bereitzustellen, da dies vertrauliche Daten und Endpunkte exponieren würde. Dies führte zu einer Blockade: Um die sichere, interne Infrastruktur aufzubauen, wurde ein interner GitLab Runner benötigt, aber um diesen Runner zu erstellen, musste zuerst die Infrastruktur aufgebaut werden. Die Herausforderung bestand darin, einen vollständig automatisierten Bootstrapping-Prozess zu entwickeln, der dieses initiale, sichere Fundament – einschließlich des GitLab Runners selbst – von einem lokalen Rechner aus erstellen konnte, um so die prozedurale Sackgasse zu lösen und den sicheren Aufbau der restlichen Infrastruktur von innen heraus zu ermöglichen.\n\n### Hauptmerkmale\n*   **Automatisierte Infrastrukturbereitstellung:** Nutzt Terraform zur deklarativen Definition und Erstellung aller notwendigen Azure-Ressourcen, einschließlich eines virtuellen Netzwerks (VNet) in einer Hub-and-Spoke-Topologie, Subnetzen, einer virtuellen Maschine und eines sicheren Bastion-Hosts.\n*   **Dynamische GitLab-Runner-Konfiguration:** Verwendet `cloud-init`, um die bereitgestellte VM beim ersten Start automatisch zu konfigurieren. Dies umfasst die Installation von Docker und des GitLab Runners, die Registrierung des neuen Runners bei der angegebenen GitLab-Gruppe unter Verwendung dynamischer Anmeldeinformationen sowie die Einrichtung von systemd-Diensten zur automatisierten Wartung und Bereinigung.\n*   **GitLab-Integration:** Der Terraform-Plan erstellt automatisch eine neue GitLab-Gruppe und füllt sie mit Projekten, indem lokale Repositories gepusht werden. Dadurch stehen der Infrastruktur- und Anwendungscode dem neu erstellten Runner sofort zur Verfügung, um seine Pipelines auszuführen.\n*   **Modulare und wiederverwendbare Architektur:** Der Terraform-Code ist in drei Schichten strukturiert: Core (grundlegende Ressourcendefinitionen), Standard Building Blocks (SBBs – Kombination von Core-Modulen zur Einhaltung von Richtlinien) und Exposed Modules (die endgültige, bereitstellbare Lösung). Dieses Muster fördert Wiederverwendbarkeit, Wartbarkeit und die strikte Einhaltung von Unternehmensstandards.\n*   **Zwei Bereitstellungsmodi:** Das System ist flexibel gestaltet. Es unterstützt die lokale Ausführung über einfache Shell-Skripte (`apply.sh`, `destroy.sh`) für das initiale Disaster-Recovery-Szenario. Zusätzlich enthält es eine vollständig konfigurierte GitLab CI/CD-Pipeline für die Remote-Ausführung, die die Validierung, das Testen und die laufende Verwaltung der Infrastruktur ermöglicht.\n*   **Sicherheit durch Design:** Implementiert den sicheren Zugriff auf die Runner-VM über Azure Bastion, wodurch öffentliche IP-Adressen und exponierte SSH-Ports vermieden werden. Netzwerksicherheitsgruppen (NSGs) werden verwendet, um strikte Firewall-Regeln für ein- und ausgehenden Verkehr durchzusetzen und so eine gehärtete Umgebung vom ersten Moment an zu gewährleisten.\n\n### Technischer Einblick\n*   **Infrastructure as Code (IaC):** Die gesamte Cloud-Umgebung wird mit **Terraform** definiert, wobei **Terragrunt** als schlanker Wrapper dient, um die Konfiguration DRY (Don't Repeat Yourself) zu halten und den Remote State zu verwalten. Dieser deklarative Ansatz stellt sicher, dass die Infrastruktur in Git versioniert, wiederholbar und leicht überprüfbar ist. Das modulare Design ermöglicht es Entwicklern, komplexe Infrastrukturen einfach aus vorab genehmigten, konformen Bausteinen zusammenzusetzen.\n\n*   **Automatisierung & Bereitstellung:** Für den primären Disaster-Recovery-Anwendungsfall bieten einfache **Shell-Skripte** eine Ein-Befehl-Schnittstelle zur Bereitstellung des gesamten Fundaments. Für die kontinuierliche Integration und Validierung orchestriert eine umfassende `.gitlab-ci.yml`-Datei den Prozess remote. Diese Pipeline umfasst Stufen für Linting, Validierung, Planung und Anwendung von Änderungen, mit manuellen Freigaben für destruktive Aktionen, um eine versehentliche Entfernung der Infrastruktur zu verhindern.\n\n*   **Konfigurationsmanagement:** Die virtuelle Maschine für den GitLab Runner wird mithilfe einer `cloud-init`-Konfigurationsdatei gebootstrappt. Terraform füllt diese Datei dynamisch mit Variablen (wie GitLab-Registrierungstoken und Runner-Tags), bevor sie an die Azure-API übergeben wird. Diese leistungsstarke Technik stellt sicher, dass die VM bei ihrem ersten Start vollständig konfiguriert und betriebsbereit ist, ohne dass ein manueller SSH-Zugriff oder eine Konfiguration erforderlich ist.\n\n### Persönliche Lernerfolge\nDiese Bachelorarbeit bot eine tiefgreifende, praxisnahe Erfahrung bei der Lösung einer kritischen, realen DevOps-Herausforderung in einem hochsicheren Unternehmenskontext. Ich ging über grundlegende IaC-Prinzipien hinaus, um eine anspruchsvolle, mehrschichtige Terraform-Architektur zu entwerfen, die Wiederverwendbarkeit und Konformität in den Vordergrund stellt. Die zentrale Herausforderung lehrte mich, Lösungen zu entwickeln, die prozedurale Blockaden elegant überwinden und einen manuellen, fehleranfälligen Prozess in ein vollautomatisches, zuverlässiges System verwandeln. Zudem vertiefte ich meine Expertise in der Erstellung von CI/CD-Pipelines, cloud-init und Shell-Scripting und lieferte letztlich eine umfassende Lösung, die als robuster Entwurf für die Automatisierung der Notfallwiederherstellung dient.","projectType":"DevOps & IaC","developedAt":"2023-07-24","liveUrl":null,"repoUrl":null,"tags":["Terraform","Terragrunt","Infrastructure as Code (IaC)","Microsoft Azure","GitLab","GitLab CI/CD","Shell Scripting","DevOps","Cloud Infrastructure","Automation"],"createdAt":"2025-10-14T17:51:14.405Z","updatedAt":"2025-10-15T19:07:01.589Z","publishedAt":"2025-10-15T19:07:01.637Z","locale":"de"}}
{"type":"api::software-project.software-project","id":193,"data":{"documentId":"wter97phm86awuqqfbpfnnvh","title":"Automated IT Infrastructure Recovery with Terraform","slug":"automated-it-infrastructure-recovery-with-terraform","description":"An IaC project using Terraform for automated disaster recovery of cloud infrastructure on Azure and GitLab, featuring a secure, modular design for rapid deployment.","longDescription":"### Project Overview\nThis project was the subject of a bachelor thesis focused on evaluating and implementing an automated disaster recovery solution for IT infrastructure using Infrastructure as Code (IaC). The primary objective was to design and build a prototype that could rapidly and reliably restore a foundational cloud environment following a total system failure. The solution leverages Terraform to automate the entire provisioning and configuration process, ensuring consistency and significantly reducing manual intervention during a critical recovery event.\n\n### The Challenge\nThe project addressed a complex \"chicken-and-egg\" problem rooted in the high-security standards of a customer project, which followed a Zero-Trust security model. The existing CI/CD runners were not permitted to provision the recovery infrastructure from outside the environment, as this would expose confidential data and endpoints. This created a deadlock: to build the secure, internal infrastructure, an internal GitLab Runner was needed, but to create that runner, the infrastructure had to be built first. The challenge was to develop a fully automated bootstrapping process that could create this initial, secure foundation—including the GitLab Runner itself—from a local machine, thereby solving the procedural impasse and enabling the rest of the infrastructure to be built out securely from within.\n\n### Key Features\n*   **Automated Infrastructure Provisioning:** Leverages Terraform to declaratively define and create all necessary Azure resources, including a virtual network (VNet) in a hub-and-spoke topology, subnets, a virtual machine, and a secure Bastion Host.\n*   **Dynamic GitLab Runner Configuration:** Utilizes `cloud-init` to automatically configure the provisioned VM on its first boot. This includes installing Docker and the GitLab Runner, registering the new runner with the specified GitLab group using dynamic credentials, and setting up systemd services for automated maintenance and cleanup.\n*   **GitLab Integration:** The Terraform plan automatically creates a new GitLab group and populates it with projects by pushing local repositories. This makes the infrastructure and application code immediately available for the newly created runner to execute its pipelines.\n*   **Modular and Reusable Architecture:** The Terraform code is structured into three distinct layers: Core (basic resource definitions), Standard Building Blocks (SBBs - combining core modules to meet compliance), and Exposed Modules (the final deployable solution). This pattern promotes reusability, maintainability, and strict adherence to organizational standards.\n*   **Dual Deployment Modes:** The system is designed for flexibility. It supports local execution via simple shell scripts (`apply.sh`, `destroy.sh`) for the initial disaster recovery scenario. Additionally, it includes a fully configured GitLab CI/CD pipeline for remote execution, enabling validation, testing, and ongoing management of the infrastructure.\n*   **Secure by Design:** Implements secure access to the runner VM via Azure Bastion, eliminating the need for public IP addresses and exposed SSH ports. Network Security Groups (NSGs) are used to enforce strict firewall rules for both inbound and outbound traffic, ensuring a hardened environment from the moment of creation.\n\n### Technical Deep Dive\n*   **Infrastructure as Code (IaC):** The entire cloud environment is defined using **Terraform**, with **Terragrunt** acting as a thin wrapper to keep the configuration DRY (Don't Repeat Yourself) and manage remote state. This declarative approach ensures that the infrastructure is version-controlled in Git, repeatable, and easily auditable. The modular design allows developers to easily compose complex infrastructure from pre-approved, compliant building blocks.\n\n*   **Automation & Deployment:** For the primary disaster recovery use case, simple **Shell Scripts** provide a one-command interface to provision the entire foundation. For continuous integration and validation, a comprehensive `.gitlab-ci.yml` file orchestrates the process remotely. This pipeline includes stages for linting, validation, planning, and applying changes, with manual approvals for destructive actions to prevent accidental infrastructure removal.\n\n*   **Configuration Management:** The virtual machine for the GitLab Runner is bootstrapped using a `cloud-init` configuration file. Terraform dynamically populates this file with variables (like GitLab registration tokens and runner tags) before passing it to the Azure API. This powerful technique ensures the VM is fully configured and operational on its first boot, without any manual SSH access or configuration required.\n\n### Personal Learnings\nThis thesis project provided a profound, hands-on experience in solving a critical, real-world DevOps challenge within a high-security corporate context. I moved beyond basic IaC principles to design a sophisticated, multi-layered Terraform architecture that emphasizes reusability and compliance. The core challenge taught me how to architect solutions that elegantly overcome procedural deadlocks, transforming a manual, error-prone process into a fully automated, reliable system. I also deepened my expertise in CI/CD pipeline construction, cloud-init, and shell scripting, ultimately delivering a comprehensive solution that serves as a robust blueprint for disaster recovery automation.","projectType":"DevOps & IaC","developedAt":"2023-07-24","liveUrl":null,"repoUrl":null,"tags":["Terraform","Terragrunt","Infrastructure as Code (IaC)","Microsoft Azure","GitLab","GitLab CI/CD","Shell Scripting","DevOps","Cloud Infrastructure","Automation"],"createdAt":"2025-10-14T17:50:11.948Z","updatedAt":"2025-10-15T19:07:16.179Z","publishedAt":null,"locale":"en"}}
{"type":"api::software-project.software-project","id":194,"data":{"documentId":"wter97phm86awuqqfbpfnnvh","title":"Automated IT Infrastructure Recovery with Terraform","slug":"automated-it-infrastructure-recovery-with-terraform","description":"An IaC project using Terraform for automated disaster recovery of cloud infrastructure on Azure and GitLab, featuring a secure, modular design for rapid deployment.","longDescription":"### Project Overview\nThis project was the subject of a bachelor thesis focused on evaluating and implementing an automated disaster recovery solution for IT infrastructure using Infrastructure as Code (IaC). The primary objective was to design and build a prototype that could rapidly and reliably restore a foundational cloud environment following a total system failure. The solution leverages Terraform to automate the entire provisioning and configuration process, ensuring consistency and significantly reducing manual intervention during a critical recovery event.\n\n### The Challenge\nThe project addressed a complex \"chicken-and-egg\" problem rooted in the high-security standards of a customer project, which followed a Zero-Trust security model. The existing CI/CD runners were not permitted to provision the recovery infrastructure from outside the environment, as this would expose confidential data and endpoints. This created a deadlock: to build the secure, internal infrastructure, an internal GitLab Runner was needed, but to create that runner, the infrastructure had to be built first. The challenge was to develop a fully automated bootstrapping process that could create this initial, secure foundation—including the GitLab Runner itself—from a local machine, thereby solving the procedural impasse and enabling the rest of the infrastructure to be built out securely from within.\n\n### Key Features\n*   **Automated Infrastructure Provisioning:** Leverages Terraform to declaratively define and create all necessary Azure resources, including a virtual network (VNet) in a hub-and-spoke topology, subnets, a virtual machine, and a secure Bastion Host.\n*   **Dynamic GitLab Runner Configuration:** Utilizes `cloud-init` to automatically configure the provisioned VM on its first boot. This includes installing Docker and the GitLab Runner, registering the new runner with the specified GitLab group using dynamic credentials, and setting up systemd services for automated maintenance and cleanup.\n*   **GitLab Integration:** The Terraform plan automatically creates a new GitLab group and populates it with projects by pushing local repositories. This makes the infrastructure and application code immediately available for the newly created runner to execute its pipelines.\n*   **Modular and Reusable Architecture:** The Terraform code is structured into three distinct layers: Core (basic resource definitions), Standard Building Blocks (SBBs - combining core modules to meet compliance), and Exposed Modules (the final deployable solution). This pattern promotes reusability, maintainability, and strict adherence to organizational standards.\n*   **Dual Deployment Modes:** The system is designed for flexibility. It supports local execution via simple shell scripts (`apply.sh`, `destroy.sh`) for the initial disaster recovery scenario. Additionally, it includes a fully configured GitLab CI/CD pipeline for remote execution, enabling validation, testing, and ongoing management of the infrastructure.\n*   **Secure by Design:** Implements secure access to the runner VM via Azure Bastion, eliminating the need for public IP addresses and exposed SSH ports. Network Security Groups (NSGs) are used to enforce strict firewall rules for both inbound and outbound traffic, ensuring a hardened environment from the moment of creation.\n\n### Technical Deep Dive\n*   **Infrastructure as Code (IaC):** The entire cloud environment is defined using **Terraform**, with **Terragrunt** acting as a thin wrapper to keep the configuration DRY (Don't Repeat Yourself) and manage remote state. This declarative approach ensures that the infrastructure is version-controlled in Git, repeatable, and easily auditable. The modular design allows developers to easily compose complex infrastructure from pre-approved, compliant building blocks.\n\n*   **Automation & Deployment:** For the primary disaster recovery use case, simple **Shell Scripts** provide a one-command interface to provision the entire foundation. For continuous integration and validation, a comprehensive `.gitlab-ci.yml` file orchestrates the process remotely. This pipeline includes stages for linting, validation, planning, and applying changes, with manual approvals for destructive actions to prevent accidental infrastructure removal.\n\n*   **Configuration Management:** The virtual machine for the GitLab Runner is bootstrapped using a `cloud-init` configuration file. Terraform dynamically populates this file with variables (like GitLab registration tokens and runner tags) before passing it to the Azure API. This powerful technique ensures the VM is fully configured and operational on its first boot, without any manual SSH access or configuration required.\n\n### Personal Learnings\nThis thesis project provided a profound, hands-on experience in solving a critical, real-world DevOps challenge within a high-security corporate context. I moved beyond basic IaC principles to design a sophisticated, multi-layered Terraform architecture that emphasizes reusability and compliance. The core challenge taught me how to architect solutions that elegantly overcome procedural deadlocks, transforming a manual, error-prone process into a fully automated, reliable system. I also deepened my expertise in CI/CD pipeline construction, cloud-init, and shell scripting, ultimately delivering a comprehensive solution that serves as a robust blueprint for disaster recovery automation.","projectType":"DevOps & IaC","developedAt":"2023-07-24","liveUrl":null,"repoUrl":null,"tags":["Terraform","Terragrunt","Infrastructure as Code (IaC)","Microsoft Azure","GitLab","GitLab CI/CD","Shell Scripting","DevOps","Cloud Infrastructure","Automation"],"createdAt":"2025-10-14T17:50:11.948Z","updatedAt":"2025-10-15T19:07:16.179Z","publishedAt":"2025-10-15T19:07:16.224Z","locale":"en"}}
{"type":"api::testimonial.testimonial","id":112,"data":{"documentId":"scppg3z52usipwoxaa3x9pds","quote":"Thats a English Review","name":"Joel","communication":3,"creativity":4,"professionalism":5,"value":4,"createdAt":"2025-09-30T00:05:41.091Z","updatedAt":"2025-10-02T20:07:45.717Z","publishedAt":null,"locale":"en","event":"Hochzeit"}}
{"type":"api::testimonial.testimonial","id":113,"data":{"documentId":"scppg3z52usipwoxaa3x9pds","quote":"Thats a English Review","name":"Joel","communication":3,"creativity":4,"professionalism":5,"value":4,"createdAt":"2025-09-30T00:05:41.091Z","updatedAt":"2025-10-02T20:07:45.717Z","publishedAt":"2025-10-02T20:07:45.806Z","locale":"en","event":"Hochzeit"}}